{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1y2iMvqy6aizDYdWo2ZvOzXl9NrpdvSHO",
      "authorship_tag": "ABX9TyPc/25u3hMVupLEQZIZVU30",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoyen1122/solar_rag/blob/main/final_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1s12M0bW7rh",
        "outputId": "0670bb57-d1e2-4c61-e463-647948a1d8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -qU python-dotenv langchain langchain-community langchain-core langchain-text-splitters langchain_upstage oracledb faiss-cpu langchain-classic openai pandas camelot-py[cv] PyMuPDF wikipedia_api sentence-transformers rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-M0HMFSXPfX",
        "outputId": "56c99b40-c50a-44a4-f96b-4ac06aa9d472"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: camelot-py 1.0.9 does not provide the extra 'cv'\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m130.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m114.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia_api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall -y transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbRQC1Ibix4N",
        "outputId": "bce78f23-d164-407a-e847-a08a5e89dc39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.46.3\n",
            "Uninstalling transformers-4.46.3:\n",
            "  Successfully uninstalled transformers-4.46.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --no-cache-dir \"transformers>=4.45.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "huQ3hUMyi3Pw",
        "outputId": "5758db85-4f52-4148-bb42-d151d846bcf8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers>=4.45.0\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (2.32.5)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.45.0)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (2025.11.12)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m203.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m311.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-upstage 0.7.5 requires tokenizers<0.21.0,>=0.20.0, but you have tokenizers 0.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.22.1 transformers-4.57.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              },
              "id": "22716cc8984b4dc09a93a44e35b823c2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "import wikipediaapi\n",
        "\n",
        "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "from langchain_classic.retrievers import EnsembleRetriever\n",
        "from openai import OpenAI\n",
        "\n",
        "import camelot\n",
        "import fitz\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_upstage import UpstageDocumentParseLoader\n",
        "\n",
        "import uuid\n",
        "from langchain_classic.retrievers import ParentDocumentRetriever\n",
        "from langchain_core.stores import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "c-_Mnzd18MR3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
        "No module named 'transformers.modeling_layers'\n",
        "이런 에러뜨면 밑에 트랜스포머 지우고 다시깔기"
      ],
      "metadata": {
        "id": "3tAJipE4jAiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/2025_2/nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mIe_4RTAUbQ",
        "outputId": "6fe5e256-0db6-4ea6-f140-5e489937685a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/2025_2/nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TESTSET_PATH = \"./dataset/testset.csv\"\n",
        "\n",
        "UPSTAGE_API_KEY = \"up_g7T2cQoLKZH6Oi2n4MHOW706XAdSs\""
      ],
      "metadata": {
        "id": "q8LGYcrtBVwO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EWHA 학칙"
      ],
      "metadata": {
        "id": "-uQ2U4M2LZo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EWHA_PDF_PATH = \"./ewha.pdf\""
      ],
      "metadata": {
        "id": "EAdUtZa_gSfg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VYtEEEQpZAvo"
      },
      "outputs": [],
      "source": [
        "upstage_embeddings = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UpstageDocumentParseLoader(\n",
        "    EWHA_PDF_PATH,\n",
        "    api_key=UPSTAGE_API_KEY\n",
        ")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "nSjmR03bLQbc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_texts = []\n",
        "\n",
        "for doc in docs:\n",
        "    text = doc.page_content\n",
        "\n",
        "    text = text.strip()\n",
        "    clean_texts.append(text)\n",
        "\n",
        "\n",
        "full_text = \"\\n\".join(clean_texts)"
      ],
      "metadata": {
        "id": "efG9CsIdLnQp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match = re.search(r\"부칙\", full_text)\n",
        "\n",
        "if not match:\n",
        "        raise ValueError(\"부칙 문구를 찾을 수 없습니다.\")\n",
        "\n",
        "addendum_start = match.start()\n",
        "\n",
        "main_text = text[:addendum_start]\n",
        "extra_text = text[addendum_start:]"
      ],
      "metadata": {
        "id": "I3Z1L0bpLrcc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_text(html_text):\n",
        "    # 테이블 삭제\n",
        "    cleaned = re.sub(r'<table.*?>.*?</table>', '', html_text, flags=re.DOTALL)\n",
        "    return cleaned\n",
        "\n",
        "cleaned_extra_text = extract_main_text(extra_text)"
      ],
      "metadata": {
        "id": "kcgGy-Q3LtsP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    base_url=\"https://api.upstage.ai/v1\"\n",
        ")"
      ],
      "metadata": {
        "id": "f6mAmJaTLxLH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are an expert in Korean legal document analysis and Markdown formatting.\n",
        "\n",
        "Your task:\n",
        "Convert the given Ewha University regulation texts (in HTML text) into a clean Markdown document with correctly assigned heading levels.\n",
        "You are given a main text:\n",
        "1) MAIN TEXT: the main university regulations\n",
        "\n",
        "Process BOTH texts together and apply the same rules.\n",
        "\n",
        "=================================================================\n",
        "MARKDOWN HEADING RULES\n",
        "=================================================================\n",
        "\n",
        "**Main Body Chapters (e.g., “제1장 총칙”)**:\n",
        "- Top-level header: `# [Chapter Title]`\n",
        "- Articles within chapters: `## [Article Title]`\n",
        "\n",
        "=================================================================\n",
        "ADDITIONAL RULES\n",
        "=================================================================\n",
        "- Remove ALL page numbers (e.g., “2-2-1”).\n",
        "- Remove HTML tags, styles, tables, or formatting artifacts from the PDF conversion.\n",
        "- Preserve all meaningful text content, but organize it strictly under the specified Markdown headings.\n",
        "- Do NOT hallucinate any content not present in the text.\n",
        "- Do NOT output explanations or any text outside the markdown.\n",
        "- Output MUST be clean markdown and ONLY markdown.\n",
        "\n",
        "Below are the two raw texts:\n",
        "\n",
        "---------------- MAIN TEXT START ----------------\n",
        "{main_text}\n",
        "---------------- MAIN TEXT END ----------------\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert in hierarchical legal information extraction and Markdown document structuring.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt.format(main_text=main_text)\n",
        "    }\n",
        "]\n",
        "\n",
        "md_response = client.chat.completions.create(\n",
        "    model=\"solar-pro2\",\n",
        "    messages=messages\n",
        "    # response_format=response_format\n",
        ")"
      ],
      "metadata": {
        "id": "SlWkV5iOL0AG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_prompt = \"\"\"\n",
        "You are an expert in Korean legal document analysis and Markdown formatting.\n",
        "\n",
        "Your task:\n",
        "Convert the given text into a clean Markdown document with correctly assigned heading levels.\n",
        "\n",
        "=================================================================\n",
        "MARKDOWN HEADING RULES\n",
        "=================================================================\n",
        "\n",
        "**Main Body Chapters (e.g., “제1장 총칙”)**:\n",
        "- Top-level header: `# [Chapter Title]`\n",
        "- Articles within chapters: `## [Article Title]`\n",
        "\n",
        "=================================================================\n",
        "SPECIFIC INSTRUCTIONS FOR THIS TEXT\n",
        "=================================================================\n",
        "- The overall title for this section should be `# 이화여자대학교 학칙`. This should be the first line of the output.\n",
        "- Every instance of '부칙' that introduces a new addendum should be formatted as a second-level Markdown header, '## 부칙'. Ensure its associated content follows immediately under this header.\n",
        "- Remove ALL page numbers (e.g., “2-2-1”).\n",
        "- Remove HTML tags, styles, tables, or formatting artifacts from the PDF conversion.\n",
        "- Preserve all meaningful text content, but organize it strictly under the specified Markdown headings.\n",
        "- Do NOT hallucinate any content not present in the text.\n",
        "- Do NOT output explanations or any text outside the markdown.\n",
        "- Output MUST be clean markdown and ONLY markdown.\n",
        "\n",
        "Below is the raw text:\n",
        "\n",
        "---------------- ADDENDUM TEXT START ----------------\n",
        "{extra_text}\n",
        "---------------- ADDENDUM TEXT END ----------------\n",
        "\"\"\"\n",
        "\n",
        "extra_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert in hierarchical legal information extraction and Markdown document structuring.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": extra_prompt.format(extra_text=cleaned_extra_text)\n",
        "    }\n",
        "]\n",
        "\n",
        "md_extra_response = client.chat.completions.create(\n",
        "    model=\"solar-pro2\",\n",
        "    messages=extra_messages\n",
        ")\n",
        "\n",
        "print(md_extra_response.choices[0].message.content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uYrglxscMCiD",
        "outputId": "943e6b58-969c-4ec6-a42c-f74b28cd536b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 이화여자대학교 학칙\n",
            "\n",
            "## 부칙(1946. 8. 15 제정)\n",
            "본 학칙은 1946년 3월 1일부터 시행한다.\n",
            "\n",
            "## 부칙\n",
            "① 본 학칙은 1961년 3월 1일부터 시행한다.\n",
            "② 본 학칙 시행에 관한 세칙은 총장이 정한다.\n",
            "\n",
            "## 부칙(문관행 1040.1-1549, 1963. 12. 16 개정)\n",
            "본 학칙은 1964년 3월 1일부터 시행한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-16, 1965. 1. 5 개정)\n",
            "① 이 학칙은 1965년 1월 10일부터 시행한다.\n",
            "② 이 학칙 시행 당시 문리과대학에 소속하는 가정학과와 사범대학에 소속하는 가정학과는\n",
            "폐과하되 그 재적 학생의 졸업년도까지 존치한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-89, 1966. 2. 1 개정)\n",
            "본 학칙은 1966년 2월 1일부터 시행한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-89, 1966. 2. 1 개정)\n",
            "본 학칙은 1966년 2월 1일부터 시행한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-171, 1967. 1. 24 개정)\n",
            "본 학\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers_to_split_on = [(\"##\", \"Header 2\")]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
        "\n",
        "md_header_splits = markdown_splitter.split_text(md_response.choices[0].message.content)\n",
        "extra_splits = markdown_splitter.split_text(md_extra_response.choices[0].message.content)\n",
        "md_header_splits.extend(extra_splits)"
      ],
      "metadata": {
        "id": "98pdsyl8MErt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_headers_to_split_on = [\n",
        "    (\"##\", \"Header 2\"),\n",
        "     (\"###\", \"Header 3\")\n",
        "]\n",
        "small_md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=small_headers_to_split_on, strip_headers=False)\n",
        "small_headers_splits = small_md_splitter.split_text(md_response.choices[0].message.content)\n",
        "small_headers_splits.extend(small_md_splitter.split_text(md_extra_response.choices[0].message.content))"
      ],
      "metadata": {
        "id": "xEeooDJmMIcM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = EWHA_PDF_PATH\n",
        "\n",
        "# Step 1: lattice 모드로 테이블 bbox만 추출\n",
        "lattice_tables = camelot.read_pdf(pdf_path, pages=\"all\", flavor=\"lattice\")\n",
        "\n",
        "final_tables = []\n",
        "\n",
        "for tbl in lattice_tables:\n",
        "    page_num = tbl.page\n",
        "    bbox = tbl._bbox  # (x1, y1, x2, y2)\n",
        "\n",
        "    # Step 2: PyMuPDF로 페이지 crop\n",
        "    doc = fitz.open(pdf_path)\n",
        "    page = doc[page_num - 1]\n",
        "\n",
        "    rect = fitz.Rect(bbox)\n",
        "    clipped = page.get_pixmap(clip=rect)\n",
        "    tmp_img = f\"tmp_page_{page_num}.png\"\n",
        "    clipped.save(tmp_img)\n",
        "\n",
        "    # Step 3: stream 모드로 crop된 이미지 분석\n",
        "    stream_tbls = camelot.read_pdf(\n",
        "        pdf_path,\n",
        "        pages=str(page_num),\n",
        "        flavor=\"stream\",\n",
        "        table_areas=[\",\".join(map(str, bbox))]  # bbox로 영역 제한\n",
        "    )\n",
        "\n",
        "    # Step 4: 이 테이블들만 최종 저장\n",
        "    for s in stream_tbls:\n",
        "        final_tables.append(s.df)\n",
        "\n",
        "# 출력 예시\n",
        "for i, df in enumerate(final_tables):\n",
        "    # print(f\"=== Final Table {i+1} ===\")\n",
        "    # print(df.to_markdown(index=False))\n",
        "    df.to_csv(f'table{i}.csv', index=False)\n",
        "    print(f'Table {i} extracted')\n",
        "\n",
        "cleaned_df = []\n",
        "\n",
        "for _, df in enumerate(final_tables):\n",
        "  headers_raw = [str(item).strip().replace(' ', '').replace('\\n', '').replace('\\u3000', '') for item in df.iloc[1]]\n",
        "\n",
        "  for col in df.columns:\n",
        "      df[col] = df[col].astype(str).str.strip().str.replace(' ', '').str.replace('\\n', '').str.replace('\\u3000', '')\n",
        "      df[col] = df[col].ffill()\n",
        "      cleaned_df.append(df)\n",
        "\n",
        "for df in cleaned_df[:3]:\n",
        "  print(df)\n",
        "  print('==========================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V68pDICEXLm_",
        "outputId": "0b2bd7d9-262f-4a9b-9f52-2854657ea1a8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 0 extracted\n",
            "Table 1 extracted\n",
            "Table 2 extracted\n",
            "Table 3 extracted\n",
            "Table 4 extracted\n",
            "Table 5 extracted\n",
            "Table 6 extracted\n",
            "Table 7 extracted\n",
            "Table 8 extracted\n",
            "Table 9 extracted\n",
            "Table 10 extracted\n",
            "Table 11 extracted\n",
            "Table 12 extracted\n",
            "Table 13 extracted\n",
            "Table 14 extracted\n",
            "Table 15 extracted\n",
            "Table 16 extracted\n",
            "Table 17 extracted\n",
            "         0      1         2\n",
            "0       대학  학위의종류    학과또는전공\n",
            "1   사회과학대학    문학사     사회복지학\n",
            "2   자연과학대학    이학사    분자생명과학\n",
            "3     공과대학    공학사      컴퓨터학\n",
            "4                     정보통신학\n",
            "5                  건축학(4년제)\n",
            "6            건축학사  건축학(5년제)\n",
            "7             공학사       환경학\n",
            "8     음악대학   음악학사      건반악기\n",
            "9                       관현악\n",
            "10                       성악\n",
            "11                     교회음악\n",
            "12                       작곡\n",
            "13                     한국음악\n",
            "14  조형예술대학   미술학사       한국화\n",
            "15                    회화․판화\n",
            "16                       조소\n",
            "17                    환경디자인\n",
            "18                  시각정보디자인\n",
            "19                    산업디자인\n",
            "20                    패션디자인\n",
            "21                     섬유예술\n",
            "22                     도자예술\n",
            "23  체육과학대학    이학사       체육학\n",
            "24                    사회체육학\n",
            "==========================\n",
            "         0      1         2\n",
            "0       대학  학위의종류    학과또는전공\n",
            "1   사회과학대학    문학사     사회복지학\n",
            "2   자연과학대학    이학사    분자생명과학\n",
            "3     공과대학    공학사      컴퓨터학\n",
            "4                     정보통신학\n",
            "5                  건축학(4년제)\n",
            "6            건축학사  건축학(5년제)\n",
            "7             공학사       환경학\n",
            "8     음악대학   음악학사      건반악기\n",
            "9                       관현악\n",
            "10                       성악\n",
            "11                     교회음악\n",
            "12                       작곡\n",
            "13                     한국음악\n",
            "14  조형예술대학   미술학사       한국화\n",
            "15                    회화․판화\n",
            "16                       조소\n",
            "17                    환경디자인\n",
            "18                  시각정보디자인\n",
            "19                    산업디자인\n",
            "20                    패션디자인\n",
            "21                     섬유예술\n",
            "22                     도자예술\n",
            "23  체육과학대학    이학사       체육학\n",
            "24                    사회체육학\n",
            "==========================\n",
            "         0      1         2\n",
            "0       대학  학위의종류    학과또는전공\n",
            "1   사회과학대학    문학사     사회복지학\n",
            "2   자연과학대학    이학사    분자생명과학\n",
            "3     공과대학    공학사      컴퓨터학\n",
            "4                     정보통신학\n",
            "5                  건축학(4년제)\n",
            "6            건축학사  건축학(5년제)\n",
            "7             공학사       환경학\n",
            "8     음악대학   음악학사      건반악기\n",
            "9                       관현악\n",
            "10                       성악\n",
            "11                     교회음악\n",
            "12                       작곡\n",
            "13                     한국음악\n",
            "14  조형예술대학   미술학사       한국화\n",
            "15                    회화․판화\n",
            "16                       조소\n",
            "17                    환경디자인\n",
            "18                  시각정보디자인\n",
            "19                    산업디자인\n",
            "20                    패션디자인\n",
            "21                     섬유예술\n",
            "22                     도자예술\n",
            "23  체육과학대학    이학사       체육학\n",
            "24                    사회체육학\n",
            "==========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_documents = []\n",
        "\n",
        "for i, df in enumerate(cleaned_df):\n",
        "  table_doc = Document(page_content=df.to_markdown(index=False),\n",
        "                       metadata={'Header 2': '별표'+str(i)})\n",
        "  table_documents.append(table_doc)"
      ],
      "metadata": {
        "id": "RVfvPE9iXSV5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "doc = text_splitter.create_documents([full_text])\n",
        "simple_vectorstore = FAISS.from_documents(doc, upstage_embeddings)"
      ],
      "metadata": {
        "id": "CnaeVQg9XV1A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 장 내부에 텍스트가 너무 긴 경우 (chunk size 1500 이상) 추가 split\n",
        "fine_grained_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=3000,\n",
        "    chunk_overlap=100\n",
        ")"
      ],
      "metadata": {
        "id": "ss7gYcKzXcLT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_docs = []\n",
        "\n",
        "# 메인 조항 % 부칙 필요 시 split 후 append\n",
        "for doc in md_header_splits:\n",
        "    sub_chunks_content = fine_grained_splitter.split_text(doc.page_content)\n",
        "    for chunk_content in sub_chunks_content:\n",
        "        # 기존 metadata 유지\n",
        "        new_metadata = doc.metadata.copy()\n",
        "        big_docs.append(Document(page_content=chunk_content, metadata=new_metadata))\n",
        "\n",
        "for table in table_documents:\n",
        "  big_docs.append(Document(page_content=table.page_content, metadata=table.metadata))\n",
        "\n",
        "# Now create the vector store from the fine_grained_documents\n",
        "big_vectorstore = FAISS.from_documents(big_docs, upstage_embeddings)\n",
        "\n",
        "for doc in big_docs[:3]:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)\n",
        "    print('----------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jIkrJdRiXdlZ",
        "outputId": "138878a4-5ade-43ea-9851-82d3ef922d5b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 이화여자대학교 학칙  \n",
            "1946. 8. 15. 제정\n",
            "2017. 8. 16. 개정\n",
            "{}\n",
            "----------------------\n",
            "## 제1장 총칙  \n",
            "### 제1조(목적)\n",
            "본교는 대한민국의 교육이념과 기독교정신을 바탕으로 하여 학술의 깊은 이론과\n",
            "그 광범하고 정밀한 응용방법을 교수․연구하며, 인격을 도야하여 국가와 인류사회의 발전에\n",
            "공헌할 수 있는 지도여성을 양성함을 목적으로 한다.  \n",
            "### 제2조(명칭)\n",
            "본교는 이화여자대학교라 부른다.  \n",
            "### 제3조(위치)\n",
            "본교는 서울특별시 서대문구 이화여대길 52에 둔다. (개정 2013.2.25.)\n",
            "{'Header 2': '제1장 총칙'}\n",
            "----------------------\n",
            "## 제2장 편제  \n",
            "### 제4조(대학 및 대학원)\n",
            "① 본교에는 다음 각 호의 대학을 둔다.\n",
            "1. 인문과학대학, 사회과학대학, 자연과학대학, 엘텍공과대학, 음악대학, 조형예술대학, 사범\n",
            "대학, 경영대학, 신산업융합대학, 의과대학, 간호대학, 약학대학, 스크랜튼대학(이하 “각\n",
            "대학”이라 한다) (개정 2016.6.16.)\n",
            "2. 호크마(HOKMA)교양대학\n",
            "② 본교에는 대학원, 국제대학원, 통역번역대학원, 경영전문대학원, 법학전문대학원, 교육대\n",
            "학원, 디자인대학원, 사회복지대학원, 신학대학원, 정책과학대학원, 공연예술대학원, 임상보\n",
            "건융합대학원, 임상치의학대학원, 외국어교육특수대학원을 둔다(이하 “각 대학원”이라 한다).\n",
            "(개정 2016.6.16., 2017.5.15.)\n",
            "[전문개정 2015.11.27.]  \n",
            "### 제5조(학부․학과․전공 및 정원)\n",
            "① 각 대학, 학부, 학과, 전공 및 모집단위별 입학정원은 별표 1과 같다. (개정 2015.5.8., 2016.2.16., 2016.2.26., 2016.5.19., 2017.5.4., 2017.5.1.)\n",
            "② 모집단위별 입학정원의 일부는 입학전형에 따라 2개 이상의 모집단위를 통합하여 모집\n",
            "할 수 있다. (개정 1999.2.9., 2017.5.15.)\n",
            "③ 제2항에 따라 통합된 모집단위로 입학한 학생과 대학 또는 학부 등 광역화된 모집단위\n",
            "로 입학한 학생에 대하여는 일정한 학기와 학점을 이수한 후에 총장의 승인을 얻어 이수할\n",
            "전공을 결정하게 하되 이에 필요한 사항은 총장이 따로 정한다. (개정 2016.2.16., 2017.\n",
            "5.15.)\n",
            "④ 삭제 (2000.2.1.)  \n",
            "⑤ 전공별 선발로 입학한 학생은 전공별 신청자격 및 승인요건을 충족하면 지정한 전공으\n",
            "로 진입한다. (신설 2015.9.18.)\n",
            "⑥ 전공변경 또는 전과 제한이 있는 전형으로 입학한 학생은 전공변경 또는 전과할 수 없\n",
            "다. (신설 2015.9.18.)\n",
            "⑦ 스크랜튼학부 자유전공 입학생의 전공결정 신청 절차는 총장이 따로 정한다. (신설\n",
            "2015.9.18.)\n",
            "[제목개정 2017.5.15.]  \n",
            "### 제5조의2(입학정원의 예외)\n",
            "「고등교육법 시행령」 제29조제2항 각 호(제3호 제외)에 해당하는\n",
            "자의 입학의 경우에는 제5조의 규정에 불구하고 그 정원이 따로 있는 것으로 본다. (개정\n",
            "1998.5.22)  \n",
            "### 제5조의3(계약학과)\n",
            "① 「산업교육진흥 및 산학연협력촉진에 관한 법률」에 의하여 국가, 지방자\n",
            "치단체 또는 산업체 등과 계약에 의한 학과 및 학부(이하 “계약학과”)를 설치․운영할 수 있\n",
            "다. (개정 2016.6.16.)\n",
            "② 제1항에 의하여 설치․운영하는 계약학과는 별표 3과 같다. (개정 2014.5.15., 2016.\n",
            "6.16)\n",
            "③ 계약학과에 관한 세부사항은 별도로 정한다.\n",
            "[본조신설 2011.4.15.]  \n",
            "### 제6조(대학원 학칙 등)\n",
            "각 대학원의 학칙은 따로 정한다. (개정 2000.2.1)  \n",
            "### 제6조의2(글로벌미래평생교육원)\n",
            "① 본교에 글로벌미래평생교육원을 둔다. (개정 2015.11.\n",
            "27.)\n",
            "② 글로벌미래평생교육원의 학칙은 따로 정한다. (개정 2015.11.27.)\n",
            "[본조신설 1986.1.7.]\n",
            "[제목개정 2015.11.27.]  \n",
            "### 제6조의3 삭제 (2016.2.26.)\n",
            "{'Header 2': '제2장 편제'}\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_docs = []\n",
        "\n",
        "for doc in small_headers_splits:\n",
        "  new_metadata = doc.metadata.copy()\n",
        "  small_docs.append(Document(page_content=doc.page_content, metadata=new_metadata))\n",
        "\n",
        "for table in table_documents:\n",
        "  small_docs.append(Document(page_content=table.page_content, metadata=table.metadata))\n",
        "\n",
        "small_vectorstore = FAISS.from_documents(small_docs, upstage_embeddings)"
      ],
      "metadata": {
        "id": "pc7lOWZSXif9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatUpstage(api_key = UPSTAGE_API_KEY, model=\"solar-pro2\")"
      ],
      "metadata": {
        "id": "NAemdG4aXwK9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are a quiz taker about Ewha Womans University's regulation.\n",
        "    Please provide most correct answer for the given context in the response format below.\n",
        "\n",
        "    Response Format:\n",
        "    [Answer]: (A) answer <OR> (X) The information is not present in the context.\n",
        "    [Reason]: Brief reason for your answer\n",
        "    [Final Answer]: THE final answer to the question following your given reason. Answer in this format: (A) answer\n",
        "\n",
        "    If the answer is not present in the context, please answer as \"(X) The information is not present in the context.\"\n",
        "\n",
        "    Example:\n",
        "    QUESTION) 영어 및 정보 등에 관하여 일정한 기준의 능력이나 자격을 취득한 경우 인정 받는 학점은 몇점인가?\n",
        "    (A) 인정 안됨\n",
        "    (B) 1학점\n",
        "    (C) 2학점\n",
        "    (D) 3학점\n",
        "\n",
        "    Answer)\n",
        "    [Answer]: (D) 3학점\n",
        "    [Reason]: The context explicitly states in 제48조의2(영어 및 정보인증) ①: \"영어 및 정보 등에 관하여 일정한 기준의 능력이나 자격을 취득한 경우 이를 각 3학점으로 인정하고 인증서를 교부할 수 있다.\" This directly answers the question by specifying that 3 credits are recognized for such certifications.\n",
        "    [Final Answer]: (D) 3학점\n",
        "\n",
        "    Here is the question and context:\n",
        "    ---\n",
        "    Question: {question}\n",
        "    ---\n",
        "    Context: {context}\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "3_xmQdcxXxUF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(TESTSET_PATH)\n",
        "prompts = df['prompts']\n",
        "answers = df['answers']\n",
        "\n",
        "ewha_prompts = prompts[:25]\n",
        "ewha_answers = answers[:25]"
      ],
      "metadata": {
        "id": "VuiZAF22XzZk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(response):\n",
        "    \"\"\"\n",
        "    extracts the answer from the response using a regular expression.\n",
        "    expected format: \"[ANSWER]: (A) convolutional networks\"\n",
        "\n",
        "    if there are no answers formatted like the format, it returns None.\n",
        "    \"\"\"\n",
        "    pattern = r\"\\[Final Answer\\]:\\s\\(([A-J])\\)[^)]*\"\n",
        "\n",
        "    # Readjustment로 인해 dinal answer가 여러 번 등장할 수 있으므로 findall 사용\n",
        "    matches = re.findall(pattern, response)\n",
        "\n",
        "    if matches:\n",
        "        print(f'Matched answer: {matches}')  # debug\n",
        "        # 가장 마지막 final answer만 선택\n",
        "        return matches[-1].strip()\n",
        "    else:\n",
        "        return extract_again(response)\n",
        "\n",
        "def extract_again(response):\n",
        "    pattern = r\"\\b[A-J]\\b(?!.*\\b[A-J]\\b)\"\n",
        "    match = re.search(pattern, response)\n",
        "    if match:\n",
        "        print(f'Re-matched answer: {match}')  # debug\n",
        "        return match.group(0)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "ARUobU--X1aZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_responses(qa, prompts):\n",
        "  responses = []\n",
        "\n",
        "  for prompt in prompts:\n",
        "  # for prompt in ewha_prompts:\n",
        "      response = qa.invoke(prompt)\n",
        "      # responses.append(response.content)\n",
        "      print(response['result'])  # debuggiing\n",
        "\n",
        "      final_answer = extract_answer(response['result'])\n",
        "      print(final_answer)\n",
        "      print('************************')\n",
        "      responses.append(final_answer)\n",
        "\n",
        "  return responses"
      ],
      "metadata": {
        "id": "yS2B6ygwYGnM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(responses, answers):\n",
        "  cnt = 0\n",
        "\n",
        "  for answer, response in zip(answers, responses):\n",
        "      print(\"-\"*10)\n",
        "      # generated_answer = extract_answer(response)\n",
        "      # print(response)\n",
        "      # check\n",
        "      if response:\n",
        "          print(f\"generated answer: {response}, answer: {answer}\")\n",
        "      else:\n",
        "          print(f\"extraction fail, answer: {answer}\")\n",
        "\n",
        "\n",
        "      if response == None:\n",
        "          continue\n",
        "      if response in answer:\n",
        "          cnt += 1\n",
        "\n",
        "  # print()\n",
        "  # print(f\"acc: {(cnt/len(ewha_prompts))*100}%\")\n",
        "\n",
        "  accuracy = (cnt/len(ewha_prompts))*100\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "2bgRsKvxYH9-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_voting(qa, prompt):\n",
        "  majority_voted_answers = []\n",
        "  num_iterations = 5\n",
        "\n",
        "  for idx, prompt in enumerate(prompt):\n",
        "      answers_for_current_prompt = []\n",
        "      for _ in range(num_iterations):\n",
        "          response = qa.invoke(prompt)\n",
        "          final_answer = extract_answer(response['result'])\n",
        "          if final_answer:\n",
        "              answers_for_current_prompt.append(final_answer)\n",
        "\n",
        "      if answers_for_current_prompt:\n",
        "          answer_counts = collections.Counter(answers_for_current_prompt)\n",
        "          most_common_answer = answer_counts.most_common(1)[0][0]\n",
        "          majority_voted_answers.append(most_common_answer)\n",
        "          print(f\"Prompt {idx+1}: Majority voted answer = {most_common_answer}\")\n",
        "      else:\n",
        "          majority_voted_answers.append(None)\n",
        "          print(f\"Prompt {idx+1}: No valid answers extracted.\")\n",
        "\n",
        "  return majority_voted_answers"
      ],
      "metadata": {
        "id": "jDhCcKwLYKQs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_retriever = big_vectorstore.as_retriever(search_kwargs={\"k\": 3}) #top 3 문서반환\n",
        "big_qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 retriever=big_retriever,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 chain_type_kwargs={\n",
        "                                     \"prompt\":prompt_template,\n",
        "                                     \"document_variable_name\": \"context\",\n",
        "                                 })"
      ],
      "metadata": {
        "id": "P26X5yKSNE2p"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_retriever = small_vectorstore.as_retriever(search_kwargs={\"k\": 5}) #top 5 문서반환\n",
        "small_qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 retriever=small_retriever,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 chain_type_kwargs={\n",
        "                                     \"prompt\":prompt_template,\n",
        "                                     \"document_variable_name\": \"context\",\n",
        "                                 })"
      ],
      "metadata": {
        "id": "E-QJEvuwNHO9"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 retriever의 결과를 ensemble\n",
        "retriever = EnsembleRetriever(\n",
        "    retrievers=[big_retriever, small_retriever],\n",
        "    weights=[0.3, 0.7]    # small chunk의 정확도가 더 높을 때 small에 가중치↑\n",
        ")\n",
        "\n",
        "ensemble_qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 retriever=retriever,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 chain_type_kwargs={\n",
        "                                     \"prompt\":prompt_template,\n",
        "                                     \"document_variable_name\": \"context\",\n",
        "                                 })"
      ],
      "metadata": {
        "id": "HE1K5aT4NIjw"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMLU_Pro1"
      ],
      "metadata": {
        "id": "M_4y12K_EE3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_classifier = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "4lm64PD2ER1-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solver = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1,\n",
        ")"
      ],
      "metadata": {
        "id": "xmYHm7TBESd-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solar_pro = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "doO_rczaEUQK"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = {\n",
        "    \"law\":        \"./mmlu_category/law\",\n",
        "    \"psychology\": \"./mmlu_category/psychology\",\n",
        "    \"business\":   \"./mmlu_category/business\",\n",
        "    \"philosophy\": \"./mmlu_category/philosophy\",\n",
        "    \"history\":    \"./mmlu_category/history\",\n",
        "}\n",
        "\n",
        "categories = list(category_index.keys())"
      ],
      "metadata": {
        "id": "M80hT4SJEVZD"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large-passage\")\n",
        "\n",
        "# 카테고리별 faiss 한번에 로드해서 캐시\n",
        "vectorstore = {}\n",
        "for cat, path in category_index.items():\n",
        "    vectorstore[cat] = FAISS.load_local(\n",
        "        folder_path=path,\n",
        "        embeddings=emb,\n",
        "        allow_dangerous_deserialization=True,\n",
        "    )\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(user_agent= \"NLP-RAG/1.0\", language = 'en')"
      ],
      "metadata": {
        "id": "peSTOaMsEcuv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import json\n",
        "\n",
        "# 질문 분석을 위한 전용 프롬프트\n",
        "P_ANALYZE_TMPL = \"\"\"\n",
        "You are an expert Question Analyst for MMLU-Pro.\n",
        "Your task is NOT to answer the question, but to dissect it so that a researcher can find the best evidence.\n",
        "\n",
        "[Available Categories]\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "- other\n",
        "\n",
        "[Task]\n",
        "Analyze the question and options to provide a structured JSON output.\n",
        "You must differentiate between search strategies for **Textbooks** (Vector DB) and **Wikipedia** (Keyword Match).\n",
        "\n",
        "[Output Fields]\n",
        "1. \"category\": Choose ONE from the list above.\n",
        "2. \"core_intent\": Summarize what the question is asking in 1 sentence.\n",
        "3. \"constraints\": List strict conditions (time period, specific person, negation 'NOT', location).\n",
        "4. \"search_queries\": Generate 3-5 **sentence-style** queries for vector search.\n",
        "   - **CRITICAL**: Translate specific scenarios into **Professional/Legal/Academic Terminology**.\n",
        "   - Example: \"Man hit neighbor\" -> \"Tort law battery elements\"\n",
        "5. \"wiki_keywords\": Extract 3-5 **specific entities or nouns** for Wikipedia title search.\n",
        "   - Example: [\"Battery (tort)\", \"Common law\", \"Trespass\"]\n",
        "\n",
        "[Example Shot]\n",
        "Question: \"According to Jean Piaget, at which stage of cognitive development do children begin to think logically about abstract concepts and hypothetical situations?\"\n",
        "Options: (A) Sensorimotor (B) Preoperational (C) Concrete operational (D) Formal operational\n",
        "\n",
        "Output:\n",
        "{{\n",
        "  \"category\": \"psychology\",\n",
        "  \"core_intent\": \"Identify the Piagetian stage associated with abstract and hypothetical reasoning.\",\n",
        "  \"constraints\": [\"Jean Piaget's theory\", \"Abstract concepts\", \"Hypothetical situations\", \"Logic\"],\n",
        "  \"search_queries\": [\n",
        "    \"Piaget cognitive development stages abstract reasoning\",\n",
        "    \"Characteristics of formal operational stage\",\n",
        "    \"Difference between concrete and formal operational stages\"\n",
        "  ],\n",
        "  \"wiki_keywords\": [\n",
        "    \"Jean Piaget\",\n",
        "    \"Cognitive development\",\n",
        "    \"Formal operational stage\",\n",
        "    \"Theory of cognitive development\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "[Real Input]\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Options:\n",
        "{options_text}\n",
        "\n",
        "Return ONLY the valid JSON object.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_analyze_prompt = ChatPromptTemplate.from_template(P_ANALYZE_TMPL)\n",
        "\n",
        "def run_p_analyze(question_text: str, options: dict, llm=None) -> dict:\n",
        "    \"\"\"\n",
        "    질문을 분석하여 검색 쿼리와 제약 조건을 추출합니다.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        llm = llm_solver  # 기존에 정의된 llm 객체 사용\n",
        "\n",
        "    # 옵션 텍스트화\n",
        "    options_str = \"\\n\".join([f\"({k}) {v}\" for k, v in options.items()])\n",
        "\n",
        "    messages = p_analyze_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        options_text=options_str\n",
        "    )\n",
        "\n",
        "    resp = llm.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # JSON 파싱 (실패 시 기본값 반환 처리 포함)\n",
        "    try:\n",
        "        # 마크다운 코드 블록 제거 등 기본적인 정제\n",
        "        if \"```json\" in raw:\n",
        "            raw = raw.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in raw:\n",
        "            raw = raw.split(\"```\")[0].strip()\n",
        "\n",
        "        analysis = json.loads(raw)\n",
        "        return analysis\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] p_analyze failed: {e}\")\n",
        "        # 실패 시 기본값: 검색어는 질문 그대로\n",
        "        return {\n",
        "            \"core_intent\": \"Unknown\",\n",
        "            \"constraints\": [],\n",
        "            \"search_queries\": [question_text]\n",
        "        }"
      ],
      "metadata": {
        "id": "O2WxIK7YEgfX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wiki_context(keywords, window_size=2000):\n",
        "    snippets = []\n",
        "    seen_titles = set()\n",
        "\n",
        "    for kw in keywords:\n",
        "        kw = (kw or \"\").strip()\n",
        "        if not kw: continue\n",
        "\n",
        "        candidates = [kw, kw.title()]\n",
        "        # 괄호 제거 등 추가 처리\n",
        "        if \"(\" in kw: candidates.append(kw.split(\"(\")[0].strip())\n",
        "\n",
        "        found_flag = False\n",
        "        for cand in candidates:\n",
        "            if cand in seen_titles: continue\n",
        "\n",
        "            try:\n",
        "                page = wiki.page(cand)\n",
        "                if page.exists():\n",
        "                    seen_titles.add(cand)\n",
        "                    full_text = page.text\n",
        "\n",
        "                    # [개선] 단순히 앞부분만 자르는 게 아니라, 키워드가 등장하는 위치를 찾음\n",
        "                    # 키워드가 텍스트 내에 있으면 그 주변을 가져옴. 없으면 앞부분 가져옴.\n",
        "                    lower_text = full_text.lower()\n",
        "                    lower_kw = kw.lower()\n",
        "                    start_idx = lower_text.find(lower_kw)\n",
        "\n",
        "                    if start_idx == -1:\n",
        "                        # 키워드 못 찾으면 그냥 앞부분\n",
        "                        display_text = full_text[:window_size]\n",
        "                    else:\n",
        "                        # 키워드 주변부 (앞으로 500자, 뒤로 1500자 정도)\n",
        "                        start_pos = max(0, start_idx - 500)\n",
        "                        end_pos = min(len(full_text), start_idx + window_size)\n",
        "                        display_text = full_text[start_pos:end_pos]\n",
        "\n",
        "                    clean_text = display_text.replace('\\n', ' ')\n",
        "                    snippets.append(f\"[Wikipedia: {page.title}]\\n...{clean_text}...\")\n",
        "                    found_flag = True\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    if not snippets:\n",
        "        return \"\"\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ],
      "metadata": {
        "id": "77x_yybnEhsQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 0. 상수 & 기본 설정\n",
        "############################################\n",
        "\n",
        "TOP_K_TEXTBOOK = 5\n",
        "TOP_K_WIKI = 5"
      ],
      "metadata": {
        "id": "QXhBT4G3Ei2k"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 1. 질문 + 옵션(A~I) 파싱\n",
        "############################################\n",
        "\n",
        "# 1. 질문 + 옵션(A~J) 파싱\n",
        "def parse_question_and_options(prompt: str):\n",
        "    \"\"\"\n",
        "    prompt: QUESTION + (A) ~ (J) 옵션이 한 문자열에 들어있는 형태\n",
        "    return: question_text(str), options(dict: 'A'~'J' -> str)\n",
        "    \"\"\"\n",
        "    pattern = r\"\\(([A-J])\\)\\s*\"\n",
        "    matches = list(re.finditer(pattern, prompt))\n",
        "\n",
        "    if not matches:\n",
        "        return prompt.strip(), {}\n",
        "\n",
        "    first = matches[0]\n",
        "    question_text = prompt[:first.start()].strip()\n",
        "\n",
        "    options: Dict[str, str] = {}\n",
        "    for idx, m in enumerate(matches):\n",
        "        letter = m.group(1)  # 'A'~'J'\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(prompt)\n",
        "        opt_text = prompt[start:end].strip()\n",
        "        options[letter] = opt_text\n",
        "\n",
        "    return question_text, options"
      ],
      "metadata": {
        "id": "yAfT1M4ZEssD"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 2. \"Final Answer: X\" 파서\n",
        "############################################\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    p_ans 출력에서 'Final Answer: X' 의 X(A~J)를 뽑기.\n",
        "    \"\"\"\n",
        "    m = re.search(r\"Final Answer:\\s*([A-J])\\s*$\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if m:\n",
        "        return m.group(1).upper()\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "C_JNmk8yEuVA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################\n",
        "# 3. Memory p_gen (INTERNAL 문서 생성)\n",
        "############################################\n",
        "\n",
        "P_MEM_TMPL = \"\"\"\n",
        "You are a knowledgeable expert in {category}.\n",
        "\n",
        "Task: Using ONLY your own internal knowledge (without seeing any external documents),\n",
        "generate a short document that provides accurate and relevant information to help\n",
        "answer the given exam question.\n",
        "\n",
        "If you truly do not know the answer or lack enough information, explicitly state\n",
        "\"I don't know\" rather than hallucinating facts.\n",
        "\n",
        "Exam Question:\n",
        "{question_text}\n",
        "\n",
        "Write ONE coherent document that:\n",
        "- Focuses only on concepts, definitions, and relations that are relevant to the question.\n",
        "- Is self-contained and clear enough to help another model answer the question.\n",
        "- Avoids unnecessary details.\n",
        "\n",
        "Document:\n",
        "\"\"\".strip()\n",
        "\n",
        "p_mem_prompt = ChatPromptTemplate.from_template(P_MEM_TMPL)\n",
        "\n",
        "\n",
        "def run_p_mem(category: str, question_text: str, llm=None) -> str:\n",
        "    if llm is None:\n",
        "        llm = llm_solver\n",
        "    msgs = p_mem_prompt.format_messages(\n",
        "        category=category,\n",
        "        question_text=question_text,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()"
      ],
      "metadata": {
        "id": "7_LTpOwxEzFv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_p_gen_for_docs(\n",
        "    category: str,             # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    source_type: str,          # \"TEXTBOOK\" or \"WIKIPEDIA\"\n",
        "    question_text: str,        # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    raw_passages: List[str],   # 검색된 원본 텍스트 리스트\n",
        "    start_doc_idx: int = 1,\n",
        "    llm=None,                  # 사용 안 함 (호환성 위해 남겨둠)\n",
        ") -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    [수정됨] LLM을 통한 요약/재작성을 수행하지 않습니다.\n",
        "    검색된 Raw Passage를 그대로 포맷팅하여 반환합니다.\n",
        "    이렇게 해야 정보 손실(Information Loss) 없이 p_con이나 p_ans 단계로 넘어갑니다.\n",
        "    \"\"\"\n",
        "    doc_blocks = []\n",
        "    cur_idx = start_doc_idx\n",
        "\n",
        "    for k, passage in enumerate(raw_passages, start=1):\n",
        "        # 빈 텍스트 무시\n",
        "        if not passage or not passage.strip():\n",
        "            continue\n",
        "\n",
        "        # [중요] LLM 호출(invoke) 없이 원본 텍스트를 그대로 넣습니다.\n",
        "        # 필요하다면 너무 긴 문단만 파이썬 문자열 슬라이싱으로 자르세요 (예: [:2000])\n",
        "        clean_passage = passage.strip()\n",
        "\n",
        "        block = (\n",
        "            f\"[Doc {cur_idx} | SOURCE=EXTERNAL({source_type}) | ORIG_ID={source_type}_{k}]\\n\"\n",
        "            f\"{clean_passage}\"\n",
        "        )\n",
        "        doc_blocks.append(block)\n",
        "        cur_idx += 1\n",
        "\n",
        "    return \"\\n\\n\".join(doc_blocks), cur_idx"
      ],
      "metadata": {
        "id": "OXCu16TyE0Xp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################\n",
        "# 5. Retrieval helpers (Hybrid: Vector + BM25)\n",
        "############################################\n",
        "\n",
        "# 전역 캐시 (BM25 인덱스를 매번 만들지 않기 위해 저장)\n",
        "bm25_store = {}   # {category: BM25Okapi_object}\n",
        "doc_store = {}    # {category: [text_list]}\n",
        "\n",
        "def init_bm25_for_category(category: str):\n",
        "    \"\"\"\n",
        "    [초기화] 해당 카테고리의 모든 문서를 로드하여 BM25 인덱스를 생성\n",
        "    \"\"\"\n",
        "    if category in bm25_store:\n",
        "        return\n",
        "\n",
        "    if category not in vectorstore:\n",
        "        return\n",
        "\n",
        "    print(f\"[Init] Building BM25 index for: {category}...\")\n",
        "    vs = vectorstore[category]\n",
        "\n",
        "    try:\n",
        "        # FAISS 메모리에서 모든 문서 텍스트 추출\n",
        "        # (주의: FAISS 로드 시 데이터가 메모리에 있어야 함)\n",
        "        all_docs = list(vs.docstore._dict.values())\n",
        "        texts = [d.page_content for d in all_docs]\n",
        "\n",
        "        if not texts:\n",
        "            print(f\"[Warn] No texts found in docstore for {category}.\")\n",
        "            return\n",
        "\n",
        "        # 토크나이징 (단순 띄어쓰기 기준)\n",
        "        tokenized_corpus = [doc.lower().split() for doc in texts]\n",
        "\n",
        "        # 저장\n",
        "        bm25_store[category] = BM25Okapi(tokenized_corpus)\n",
        "        doc_store[category] = texts\n",
        "        print(f\"[Init] BM25 ready for {category} ({len(texts)} docs)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Warn] Failed to init BM25 for {category} (Pure Vector mode will be used): {e}\")\n",
        "\n",
        "\n",
        "def reciprocal_rank_fusion(results_list: List[List[str]], k=60) -> List[str]:\n",
        "    \"\"\"\n",
        "    [RRF 알고리즘] 여러 검색 결과의 순위를 합산하여 재정렬\n",
        "    \"\"\"\n",
        "    fused_scores = {}\n",
        "\n",
        "    for docs in results_list:\n",
        "        for rank, doc_text in enumerate(docs):\n",
        "            if doc_text not in fused_scores:\n",
        "                fused_scores[doc_text] = 0\n",
        "            # 순위가 높을수록(rank가 작을수록) 높은 점수 부여\n",
        "            fused_scores[doc_text] += 1 / (rank + k)\n",
        "\n",
        "    # 점수 높은 순 정렬\n",
        "    reranked = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [text for text, score in reranked]\n",
        "\n",
        "\n",
        "def get_textbook_passages(category: str, query: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    [수정된 함수] Hybrid Search 적용\n",
        "    1. Vector Search (의미 검색) -> 10개\n",
        "    2. BM25 Search (키워드 검색) -> 10개\n",
        "    3. RRF Fusion -> 상위 5개 반환\n",
        "    \"\"\"\n",
        "    if category not in vectorstore:\n",
        "        return []\n",
        "\n",
        "    # 0. BM25 준비\n",
        "    if category not in bm25_store:\n",
        "        init_bm25_for_category(category)\n",
        "\n",
        "    # 1. Vector Search (Semantic)\n",
        "    vs = vectorstore[category]\n",
        "    # 후보를 10개 정도 가져옴\n",
        "    vec_candidates = vs.similarity_search(query, k=10)\n",
        "    vec_results = [d.page_content for d in vec_candidates]\n",
        "\n",
        "    # 2. BM25 Search (Keyword) - 만약 준비 안됐으면 생략\n",
        "    bm25_results = []\n",
        "    if category in bm25_store:\n",
        "        bm25 = bm25_store[category]\n",
        "        docs = doc_store[category]\n",
        "\n",
        "        tokenized_query = query.lower().split()\n",
        "        # 키워드 매칭 상위 10개\n",
        "        bm25_results = bm25.get_top_n(tokenized_query, docs, n=10)\n",
        "\n",
        "    # 3. Fusion (하나만 있으면 그것만 반환)\n",
        "    if not bm25_results:\n",
        "        final_passages = vec_results\n",
        "    else:\n",
        "        # 두 결과를 섞음\n",
        "        final_passages = reciprocal_rank_fusion([vec_results, bm25_results], k=60)\n",
        "\n",
        "    # 최종 TOP_K 개수만큼 자르기\n",
        "    return final_passages[:TOP_K_TEXTBOOK]\n",
        "\n",
        "\n",
        "def get_wiki_passages(keywords: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    (기존 유지)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        raw = fetch_wiki_context(keywords)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Wikipedia retrieval failed: {e}\")\n",
        "        return []\n",
        "\n",
        "    raw = (raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return []\n",
        "    return [raw]"
      ],
      "metadata": {
        "id": "P6A1usHqFCXf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P_CON_TMPL = \"\"\"\n",
        "You are a Knowledge Integrator for MMLU-Pro dataset.\n",
        "\n",
        "Task: Consolidate information from both your own memorized documents (INTERNAL)\n",
        "and externally retrieved documents (EXTERNAL) in response to the given exam question.\n",
        "\n",
        "Guidelines:\n",
        "* For documents that provide consistent information, cluster them together and\n",
        "  summarize the key details into a single, concise document.\n",
        "* For documents with conflicting information, separate them into distinct documents,\n",
        "  ensuring each document captures the unique perspective or data.\n",
        "* Exclude any information that is irrelevant to the question.\n",
        "* For each NEW document you create, clearly indicate:\n",
        "  - Whether the source was INTERNAL(MEMORY) or EXTERNAL(TEXTBOOK/WIKIPEDIA).\n",
        "  - The original document numbers that contributed to it (e.g., FROM=1,3,4).\n",
        "\n",
        "[Examples]\n",
        "\n",
        "<Example 1: Conflict Resolution>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=INTERNAL(MEMORY)]\n",
        "The Treaty of Versailles was signed in 1918.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "The Treaty of Versailles was signed on June 28, 1919, officially ending WWI.\n",
        "\n",
        "Question: When was the Treaty of Versailles signed?\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(TEXTBOOK) | FROM=2]\n",
        "The Treaty of Versailles was signed on June 28, 1919.\n",
        "(Correction: Internal memory incorrectly stated 1918, which was the armistice year, not the treaty signing.)\n",
        "</Example 1>\n",
        "\n",
        "<Example 2: Merging Consistent Info>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(WIKIPEDIA)]\n",
        "Classical conditioning involves a neutral stimulus becoming a conditioned stimulus.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "Pavlov's dog experiment demonstrated classical conditioning by pairing a bell with food.\n",
        "\n",
        "Question: Explain the mechanism of classical conditioning.\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=MERGED(EXTERNAL) | FROM=1,2]\n",
        "Classical conditioning is a learning process where a neutral stimulus (like a bell) becomes a conditioned stimulus after being paired with an unconditioned stimulus (like food). This was demonstrated in Pavlov's dog experiment.\n",
        "</Example 2>\n",
        "\n",
        "[Real Task]\n",
        "\n",
        "Initial Context (numbered documents):\n",
        "{context_init}\n",
        "\n",
        "Last Context (may be empty):\n",
        "{last_context}\n",
        "\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Now produce your New Context following the examples.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_con_prompt = ChatPromptTemplate.from_template(P_CON_TMPL)\n",
        "\n",
        "def run_p_con(\n",
        "    question_text: str,\n",
        "    context_init: str,\n",
        "    last_context: str = \"\",\n",
        "    llm=None,\n",
        ") -> str:\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    msgs = p_con_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        context_init=context_init,\n",
        "        last_context=last_context,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()\n"
      ],
      "metadata": {
        "id": "mbYgqEqGFEfb"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 7. Knowledge Consolidation + Answer Finalization p_ans (10-Option Optimized)\n",
        "############################################\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    모델이 내뱉는 다양한 형식을 모두 잡아내는 강력한 추출 함수\n",
        "    \"\"\"\n",
        "    if not text: return \"\"\n",
        "\n",
        "    # 1순위: \"Final Answer\" 뒤에 오는 첫 번째 영문자 (A-J) 찾기\n",
        "    # 예: \"**Final Answer:** (A)\", \"Final Answer: Option A\", \"Final Answer is [A]\"\n",
        "    # [^\\nA-J]* : 줄바꿈이나 A-J가 나오기 전까지의 모든 특수문자(:, *, 공백 등)를 무시\n",
        "    match = re.search(r\"Final Answer[^\\nA-J]*([A-J])\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if match:\n",
        "        return match.group(1).upper()\n",
        "\n",
        "    # 2순위: <ANSWER> 태그 (프롬프트에서 지시한 경우)\n",
        "    match_tag = re.search(r\"<ANSWER>\\s*\\(?([A-J])\\)?\", text, flags=re.IGNORECASE)\n",
        "    if match_tag:\n",
        "        return match_tag.group(1).upper()\n",
        "\n",
        "    # 3순위: 최후의 수단 - 문장 맨 끝에 있는 (A) 형태 찾기\n",
        "    fallback = re.findall(r\"\\(?([A-J])\\)?\", text.split(\"\\n\")[-1])\n",
        "    if fallback:\n",
        "        return fallback[-1].upper()\n",
        "\n",
        "    return \"\" # 정말 답이 없는 경우\n"
      ],
      "metadata": {
        "id": "UzHMcemxFFuh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY_META = {\n",
        "    \"law\": {\n",
        "        \"role\": (\n",
        "            \"You are a distinguished Law Professor and Bar Exam Grader. \"\n",
        "            \"You specialize in applying strict legal doctrines to complex fact patterns. \"\n",
        "            \"Your expertise covers Contracts, Torts, Criminal Law, Property, Constitutional Law, and Evidence.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Spot the precise legal issue (e.g., specific crime, tort, contract doctrine).\\n\"\n",
        "            \"- Apply traditional common-law elements unless a statute in the context clearly overrides them.\\n\"\n",
        "            \"- For crimes, require that ALL elements are satisfied; if one element is missing, that crime is wrong.\\n\"\n",
        "            \"- For 'best defense' or 'most likely' questions, prefer options that directly attack missing elements or raise strong procedural bars \"\n",
        "            \"(e.g., Statute of Frauds, Statute of Limitations).\"\n",
        "        ),\n",
        "    },\n",
        "    \"business\": {\n",
        "        \"role\": (\n",
        "            \"You are a CPA (Certified Public Accountant) and Economics Professor. \"\n",
        "            \"You excel at financial accounting, managerial accounting, corporate finance, and micro/macroeconomics.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Carefully extract all numerical data and relationships before computing.\\n\"\n",
        "            \"- Show each calculation step explicitly (no guessing): check signs, totals, and units.\\n\"\n",
        "            \"- For finance questions, check if time value of money (PV/FV, discounting) is implied by dates or interest rates.\\n\"\n",
        "            \"- For conceptual items, ground answers in standard models (supply/demand, elasticity, basic game theory) rather than intuition.\"\n",
        "        ),\n",
        "    },\n",
        "    \"history\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert Historian specializing in primary source analysis. \"\n",
        "            \"You handle World, U.S., European, and Asian history with a focus on chronology and causality.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- First fix the time period and region using names, events, or terminology.\\n\"\n",
        "            \"- Eliminate options that are anachronistic (wrong century, wrong ruler, wrong war).\\n\"\n",
        "            \"- Distinguish short-term triggers from long-term structural causes when evaluating explanations.\\n\"\n",
        "            \"- When reading passages, consider author, audience, and purpose to match the most plausible interpretation.\"\n",
        "        ),\n",
        "    },\n",
        "    \"philosophy\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert Philosopher specializing in Ethics, Metaphysics, and Epistemology. \"\n",
        "            \"You are precise with terminology and familiar with canonical arguments (Kant, Mill, Aristotle, etc.).\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Identify the relevant school or author first (e.g., Kantian deontology vs. Millian utilitarianism).\\n\"\n",
        "            \"- Pay close attention to technical terms (e.g., validity vs. truth, necessary vs. sufficient, a priori vs. a posteriori).\\n\"\n",
        "            \"- Reject options that contradict the core commitments of the view (e.g., utilitarianism ignoring consequences).\\n\"\n",
        "            \"- Prefer options that match the exact formulation of the principle, not just something that sounds reasonable.\"\n",
        "        ),\n",
        "    },\n",
        "    \"psychology\": {\n",
        "        \"role\": (\n",
        "            \"You are a Clinical and Research Psychologist. \"\n",
        "            \"You specialize in DSM-5 criteria, developmental stages, cognitive psychology, and experimental design.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- For diagnosis, match symptoms strictly to DSM-5 criteria, especially duration, severity, and exclusion conditions.\\n\"\n",
        "            \"- For development/theory items, map behaviors to the correct named theory and precise stage (e.g., Piaget, Kohlberg, Erikson).\\n\"\n",
        "            \"- In research design questions, clearly identify IV, DV, and likely confounds; distinguish correlation from causation.\\n\"\n",
        "            \"- For ethics scenarios, prioritize APA principles such as informed consent, confidentiality, and minimizing harm.\"\n",
        "        ),\n",
        "    },\n",
        "}\n",
        "\n",
        "DEFAULT_CATEGORY_META = {\n",
        "    \"role\": (\n",
        "        \"You are an expert exam solver for MMLU-Pro. You are careful, analytical, and precise.\"\n",
        "    ),\n",
        "    \"guidelines\": (\n",
        "        \"- Read the QUESTION carefully and respect all stated constraints.\\n\"\n",
        "        \"- Use the provided Context as primary evidence and avoid unsupported assumptions.\\n\"\n",
        "        \"- Eliminate options that conflict with the facts, definitions, or chronology in the Context.\\n\"\n",
        "        \"- Choose the single best-supported option, even if other options seem partially plausible.\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "dyOzljkKFGqQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_ANS_TMPL = \"\"\"\n",
        "You are an expert multiple-choice exam solver for MMLU-Pro, using an Astute-RAG style reasoning process.\n",
        "\n",
        "[Role]\n",
        "{category_role}\n",
        "\n",
        "[Category-Specific Guidelines]\n",
        "{category_guidelines}\n",
        "\n",
        "You are given:\n",
        "[Initial Context]  (short, noisy, or partial)\n",
        "{context_init}\n",
        "\n",
        "[Consolidated Context]  (higher-quality, filtered evidence)\n",
        "{context_con}\n",
        "\n",
        "[QUESTION]\n",
        "{question_with_options}\n",
        "\n",
        "Your job is to carefully combine your INTERNAL knowledge with the given EXTERNAL context,\n",
        "and then follow the **three-stage Astute-RAG reasoning** below.\n",
        "\n",
        "--------------------------------\n",
        "Stage 1 – Evidence Aggregation (Astute Step 1)\n",
        "--------------------------------\n",
        "1. From the QUESTION ONLY (ignore context for now), extract 3–5 key clues:\n",
        "   - important concepts, time periods, entities, relationships, or definitions.\n",
        "2. Using the CONTEXT (Initial + Consolidated), list 3–7 **relevant evidence statements**:\n",
        "   - each statement should be short (1 sentence),\n",
        "   - include only facts that help discriminate between the options.\n",
        "3. If the context contradicts itself, give higher trust to the **Consolidated Context**,\n",
        "   but never violate explicit constraints stated in the QUESTION.\n",
        "\n",
        "--------------------------------\n",
        "Stage 2 – Option-wise Diagnosis with Score & Confidence (Astute Step 2)\n",
        "--------------------------------\n",
        "For each option (A, B, C, D, ...), do the following:\n",
        "\n",
        "1. In 1–2 sentences, compare the option with the key clues + evidence:\n",
        "   - Explain how it is supported or contradicted.\n",
        "   - Check whether it satisfies all critical constraints in the QUESTION.\n",
        "\n",
        "2. Assign three evaluations to this option:\n",
        "   - A **Label**: one of\n",
        "     * \"CLEARLY SUPPORTED\"\n",
        "     * \"PARTIALLY SUPPORTED / DUBIOUS\"\n",
        "     * \"CLEARLY CONTRADICTED\"\n",
        "   - A numerical **Score** between 0 and 1:\n",
        "     * 0.0 ≈ completely wrong, 1.0 ≈ very strongly supported.\n",
        "   - A short **Confidence** phrase: one of [\"high\", \"medium\", \"low\"].\n",
        "\n",
        "Use the following format for each option:\n",
        "\n",
        "Option A:\n",
        "- Reasoning: ...\n",
        "- Label: CLEARLY SUPPORTED\n",
        "- Score: 0.82\n",
        "- Confidence: high\n",
        "\n",
        "(Repeat this exact structure for options B, C, D, ...)\n",
        "\n",
        "--------------------------------\n",
        "Stage 3 – Global Consistency Check & Final Decision (Astute Step 3)\n",
        "--------------------------------\n",
        "1. Look at ALL options, their Labels, and Scores together.\n",
        "2. Eliminate every option that is:\n",
        "   - labeled \"CLEARLY CONTRADICTED\", or\n",
        "   - has Score < 0.30 (unless every option is very low-scoring).\n",
        "3. Among the remaining options, choose **one single BEST** answer by asking:\n",
        "   - Which option is most strongly and directly supported by the evidence and key clues?\n",
        "   - Does any option rely on extra assumptions not justified by the context?\n",
        "4. If two options have similar Scores, briefly explain why the higher one\n",
        "   is still better given the QUESTION wording and constraints.\n",
        "\n",
        "Finally, on the last line of your response, output the answer in the format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "(where X is a single capital letter such as A, B, C, D, ...).\n",
        "Do NOT output anything after this line.\n",
        "\"\"\".strip()\n",
        "p_ans_prompt = ChatPromptTemplate.from_template(P_ANS_TMPL)"
      ],
      "metadata": {
        "id": "WkLpd6V4FHoY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 살짝 변경\n",
        "def run_p_ans(\n",
        "    context_init: str,\n",
        "    context_con: str,\n",
        "    full_question: str,\n",
        "    category: str,\n",
        "    llm=None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    p_gen/p_con으로 만들어진 context를 기반으로,\n",
        "    astute-RAG 방식(INTERNAL vs EXTERNAL, Step 1~4)을 그대로 따르되,\n",
        "    category별 역할/전략 텍스트를 추가하여 특화된 solver로 동작하게 함.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    meta = CATEGORY_META.get(category, DEFAULT_CATEGORY_META)\n",
        "\n",
        "    msgs = p_ans_prompt.format_messages(\n",
        "        category_role=meta[\"role\"],\n",
        "        category_guidelines=meta[\"guidelines\"],\n",
        "        context_init=context_init,\n",
        "        context_con=context_con,\n",
        "        question_with_options=full_question,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    raw = resp.content.strip()\n",
        "    letter = extract_final_answer_letter(raw)\n",
        "    return {\"final_answer\": letter, \"raw_reasoning\": raw}"
      ],
      "metadata": {
        "id": "J8-0wWMCFIpv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_astute_style(\n",
        "    full_prompt: str,\n",
        "    use_wiki: bool = True,\n",
        "    n_vote: int = 5\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1. 통합 분석 (One-Shot Prompt 적용된 run_p_analyze 사용)\n",
        "    # ---------------------------------------------------------\n",
        "    question_text, options = parse_question_and_options(full_prompt)\n",
        "\n",
        "    try:\n",
        "        # [변경] 여기서 Category, Textbook Query, Wiki Keywords를 한 번에 다 가져옴\n",
        "        analysis = run_p_analyze(question_text, options, llm=llm_solver)\n",
        "    except NameError:\n",
        "        print(\"[Error] run_p_analyze not defined. Using fallback.\")\n",
        "        analysis = {}\n",
        "\n",
        "    # 결과 추출 (안전하게 get 사용)\n",
        "    # 1) 카테고리 (구버전 함수 classify_... 삭제됨)\n",
        "    category = analysis.get(\"category\", \"business\")\n",
        "\n",
        "    # 2) 제약조건\n",
        "    constraints = analysis.get(\"constraints\", [])\n",
        "\n",
        "    # 3) 검색어 분리\n",
        "    # 교과서용 (문장형)\n",
        "    textbook_queries = analysis.get(\"search_queries\", [question_text])\n",
        "    # 위키용 (명사형)\n",
        "    wiki_keywords = analysis.get(\"wiki_keywords\", [])\n",
        "\n",
        "    # [Fallback] 만약 위키 키워드가 비었으면 교과서 쿼리라도 씀\n",
        "    if not wiki_keywords:\n",
        "        wiki_keywords = textbook_queries\n",
        "\n",
        "    print(f\"   -> [Analysis] Category: {category}\")\n",
        "    print(f\"   -> [Textbook Query] {textbook_queries[:1]}...\")\n",
        "    print(f\"   -> [Wiki Keywords] {wiki_keywords}\")\n",
        "\n",
        "    # 벡터 DB 확인\n",
        "    if category not in vectorstore:\n",
        "        print(f\"   -> [Warn] Category '{category}' not found. Fallback to 'business'.\")\n",
        "        category = \"business\"\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2. 검색 (Dual-Track: Hybrid Vector + Wiki)\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # Track A: Textbook (Vector + BM25 Hybrid)\n",
        "    # 문장형 쿼리에 제약조건을 더해서 문맥 강화\n",
        "    combined_textbook_query = \" \".join(textbook_queries) + \" \" + \" \".join(constraints)\n",
        "    tb_passages = get_textbook_passages(category, combined_textbook_query)\n",
        "\n",
        "    # Track B: Wikipedia (Entity Search)\n",
        "    # 명사형 키워드로 정확한 표제어 매칭\n",
        "    wiki_passages = []\n",
        "    if use_wiki:\n",
        "        wiki_passages = get_wiki_passages(wiki_keywords)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. Context 생성 (p_mem -> p_gen -> p_con)\n",
        "    # ---------------------------------------------------------\n",
        "    doc_blocks = []\n",
        "    next_doc_idx = 1\n",
        "\n",
        "    # Internal Memory\n",
        "    mem_doc_text = run_p_mem(category, question_text)\n",
        "    if mem_doc_text.strip():\n",
        "        doc_blocks.append(f\"[Doc {next_doc_idx} | SOURCE=INTERNAL(MEMORY)]\\n{mem_doc_text}\")\n",
        "        next_doc_idx += 1\n",
        "\n",
        "    # Textbook Docs (LLM 요약 없이 Pass-through)\n",
        "    if tb_passages:\n",
        "        tb_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category, \"TEXTBOOK\", question_text, tb_passages, next_doc_idx, None\n",
        "        )\n",
        "        if tb_block.strip(): doc_blocks.append(tb_block)\n",
        "\n",
        "    # Wiki Docs (LLM 요약 없이 Pass-through)\n",
        "    if wiki_passages:\n",
        "        wiki_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category, \"WIKIPEDIA\", question_text, wiki_passages, next_doc_idx, None\n",
        "        )\n",
        "        if wiki_block.strip(): doc_blocks.append(wiki_block)\n",
        "\n",
        "    context_init = \"\\n\\n\".join(doc_blocks)\n",
        "\n",
        "    # Consolidation\n",
        "    context_con = run_p_con(question_text=question_text, context_init=context_init)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. Voting (Self-Consistency)\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # Voting용 질문 구성 (제약조건 명시)\n",
        "    constraints_str = \"\\n\".join([f\"- {c}\" for c in constraints])\n",
        "    augmented_question = f\"{full_prompt}\\n\\n[CRITICAL CONSTRAINTS]\\n{constraints_str}\"\n",
        "\n",
        "    # 다양성을 위한 Temperature 설정\n",
        "    llm_voter = ChatUpstage(api_key=UPSTAGE_API_KEY, model=\"solar-pro2\", temperature=0.7)\n",
        "\n",
        "    votes = []\n",
        "    reasonings = []\n",
        "\n",
        "    print(f\"   -> [Voting] Running {n_vote} iterations...\")\n",
        "    for i in range(n_vote):\n",
        "        try:\n",
        "            ans = run_p_ans(\n",
        "                context_init=context_init,\n",
        "                context_con=context_con,\n",
        "                full_question=augmented_question,\n",
        "                category=category,\n",
        "                llm=llm_voter\n",
        "            )\n",
        "            letter = ans[\"final_answer\"]\n",
        "\n",
        "            # 유효한 답만 투표\n",
        "            if letter and letter in \"ABCDEFGHIJ\":\n",
        "                votes.append(letter)\n",
        "\n",
        "            reasonings.append(f\"[Run {i+1} Answer: {letter}]\\n{ans['raw_reasoning']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [Vote Error]: {e}\")\n",
        "            continue\n",
        "\n",
        "    # 최종 결과 집계\n",
        "    if not votes:\n",
        "        final_ans = \"A\" # Fallback\n",
        "        vote_summary = \"None\"\n",
        "    else:\n",
        "        # 최빈값 선택\n",
        "        count = Counter(votes)\n",
        "        final_ans = count.most_common(1)[0][0]\n",
        "        vote_summary = str(dict(count))\n",
        "        print(f\"   -> [Result] Winner: {final_ans} | Votes: {vote_summary}\")\n",
        "\n",
        "    full_log = \"\\n\" + \"=\"*40 + \"\\n\".join(reasonings)\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": category,\n",
        "        \"analysis\": analysis,\n",
        "        \"keywords\": wiki_keywords, # 변경됨: extracted_keywords -> wiki_keywords\n",
        "        \"context_init\": context_init,\n",
        "        \"context_con\": context_con,\n",
        "        \"raw_reasoning\": full_log,\n",
        "        \"vote_summary\": vote_summary\n",
        "    }"
      ],
      "metadata": {
        "id": "WA6NwCGJFJlY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMLU_Pro2"
      ],
      "metadata": {
        "id": "wcaJzXRbGWUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_prompt_template = \"\"\"\n",
        "You are an expert exam question category classifier and expert at extracting essential keywords from Question that helps a QA system to retrieve the most relevant context from reference materials.\n",
        "\n",
        "\n",
        "There are 5 possible categories:\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "\n",
        "[Task]\n",
        "Given a multiple-choice exam question (including all options),\n",
        "1. Choose one best category from the list above.\n",
        "2. Extract exactly 3 important keywords (one noun that consists of single word or short phrase)\n",
        "   that will be useful to search textbooks and Wikipedia.\n",
        "   Keywords should be as specific and accurate as possible (e.g., \"consent\",\n",
        "   \"cognitive dissonance\", \"Keynesian economics\").\n",
        "\n",
        "[Output format]\n",
        "Return a valid JSON with the following fields:\n",
        "- \"category\": one of [\"law\",\"psychology\",\"business\",\"philosophy\",\"history\"]\n",
        "- \"keywords\": a list of exactly 3 strings\n",
        "\n",
        "This is an output example:\n",
        "{{\n",
        "  \"category\": \"psychology\",\n",
        "  \"keywords\": [\"informed consent\", \"assent\", \"child counseling\"]\n",
        "}}\n",
        "\n",
        "[Question]\n",
        "{question}\n",
        "\"\"\".strip()\n",
        "\n",
        "category_prompt = ChatPromptTemplate.from_template(category_prompt_template)"
      ],
      "metadata": {
        "id": "rT-pgyZJGl0P"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_and_extract_keywords(question_text: str):\n",
        "    messages = category_prompt.format_messages(question=question_text)\n",
        "    resp = llm_classifier.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    if not raw:\n",
        "        # 완전 빈 응답이면 기본값으로 대충 처리 (죽지 않게)\n",
        "        print(\"[WARN] Empty LLM output for category, fallback to 'history'\")\n",
        "        return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    # 1차 시도: 전체를 JSON으로 해석\n",
        "    try:\n",
        "        data = json.loads(raw)\n",
        "    except json.JSONDecodeError:\n",
        "        # 2차 시도: 문자열 안에서 {...} 구간만 잘라서 해석\n",
        "        start = raw.find(\"{\")\n",
        "        end = raw.rfind(\"}\")\n",
        "        if start == -1 or end == -1:\n",
        "            print(\"[WARN] No JSON object found in output, fallback to 'history'\")\n",
        "            return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "        json_str = raw[start:end+1]\n",
        "        try:\n",
        "            data = json.loads(json_str)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"[WARN] JSON parse failed again:\", e)\n",
        "            return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    category = data.get(\"category\", \"history\").strip().lower()\n",
        "    keywords = data.get(\"keywords\", [])\n",
        "    keywords = [str(k).strip() for k in keywords][:3]\n",
        "\n",
        "    if not keywords:\n",
        "        keywords = [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    return category, keywords"
      ],
      "metadata": {
        "id": "PgBjr99vGbTN"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wiki_context(keywords, max_chars_per_page=1200):\n",
        "    snippets = []\n",
        "    for kw in keywords:\n",
        "        try:\n",
        "            page = wiki.page(kw)\n",
        "            if not page.exists():\n",
        "                print(f\"[WARN] page for '{kw}' does not exist\")\n",
        "                continue\n",
        "            text = page.text[:max_chars_per_page]\n",
        "            snippets.append(f\"[Wikipedia: {page.title}]\\n{text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] wikipediaapi fetch failed for '{kw}': {e}\")\n",
        "            continue\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ],
      "metadata": {
        "id": "ylBEZUlNGo0o"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_K_TEXTBOOK = 5\n",
        "\n",
        "def build_context_for_solver(question_text: str, category: str, keywords):\n",
        "    # 1) 카테고리별 textbook RAG\n",
        "    vs = vectorstore[category]\n",
        "    docs = vs.similarity_search(question_text, k=TOP_K_TEXTBOOK)\n",
        "    textbook_context = \"\\n\\n\".join(\n",
        "        f\"[Textbook Doc {i+1}] {d.page_content}\" for i, d in enumerate(docs)\n",
        "    )\n",
        "\n",
        "    # 2) Wikipedia context\n",
        "    wiki_context = fetch_wiki_context(keywords)\n",
        "\n",
        "    full_context = f\"\"\"\\\n",
        "=== TEXTBOOK CONTEXT ({category}) ===\n",
        "{textbook_context}\n",
        "\n",
        "=== WIKIPEDIA CONTEXT (keywords: {', '.join(keywords)}) ===\n",
        "{wiki_context}\n",
        "\"\"\"\n",
        "    return full_context"
      ],
      "metadata": {
        "id": "KvjvK1llGp_0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_LAW_TMPL = \"\"\"\n",
        "You are a U.S. law professor helping a legal QA system retrieve the most relevant authority.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "Use the CONTEXT as textbook + Wikipedia support, but ALWAYS follow these principles:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION FACT PATTERN\n",
        "- First, read the QUESTION (including facts and answer options) very carefully.\n",
        "- Treat the facts and wording in the QUESTION as the primary authority.\n",
        "- Do NOT contradict the facts as stated in the QUESTION.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY LEGAL CLUES FROM THE QUESTION\n",
        "Before judging the options, silently identify 3–5 essential legal clues from the QUESTION itself, such as:\n",
        "- relevant area of law (e.g., common-law robbery, larceny, attempt, accomplice liability, defenses),\n",
        "- key facts about timing, knowledge, intent (mens rea), consent, force, or possession,\n",
        "- jurisdiction assumptions (assume standard U.S. common law / majority rule unless the CONTEXT clearly says otherwise).\n",
        "\n",
        "Base your reasoning on these clues.\n",
        "\n",
        "3) USE CONTEXT CAREFULLY (TEXTBOOK > WIKIPEDIA)\n",
        "- Use the CONTEXT to recall or confirm black-letter rules, elements, and standard doctrines.\n",
        "- If textbook material and Wikipedia conflict, trust the textbook-style explanation in the CONTEXT.\n",
        "- Do NOT narrow or expand a rule beyond what is normally accepted in standard common law / majority doctrine,\n",
        "  unless the CONTEXT explicitly tells you to use a specific variant.\n",
        "\n",
        "4) APPLY BLACK-LETTER LAW PRECISELY\n",
        "- Identify the relevant rule(s) (e.g., elements of common-law larceny, robbery, burglary, receiving stolen property,\n",
        "  attempt, conspiracy, self-defense, etc.).\n",
        "- Apply every element to the facts in the QUESTION.\n",
        "- Pay careful attention to:\n",
        "  - timing of force or threats,\n",
        "  - whether the defendant knew property was stolen,\n",
        "  - whether there was a trespassory taking,\n",
        "  - whether possession was obtained by fraud, trick, or without consent,\n",
        "  - whether any required mental state (intent, knowledge, recklessness, negligence) is clearly present.\n",
        "\n",
        "5) COMPARE EACH OPTION STRICTLY\n",
        "For EACH answer choice:\n",
        "- Explain briefly (in your own reasoning) why it is correct or incorrect,\n",
        "  always referencing specific facts from the QUESTION and the applicable legal rule.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the precise legal definition and all elements,\n",
        "    - correctly reflects the timing and mental state required by the rule,\n",
        "    - does NOT add extra facts not in the QUESTION,\n",
        "    - fits both the QUESTION facts and the CONTEXT.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume extra premises, background facts, or historical claims that are not stated or strongly implied.\n",
        "- Do NOT change the content of a doctrine to make an option fit better; respect standard textbook interpretations.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences.\n",
        "- Write the source you retrived specifically\n",
        "- Do NOT use Markdown formatting (no bullet points, no headings, no **bold**, no code blocks).\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_law = ChatPromptTemplate.from_template(SOLVER_PROMPT_LAW_TMPL)"
      ],
      "metadata": {
        "id": "Hv9VMsw2GrE4"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_PHILOSOPHY_TMPL = \"\"\"\n",
        "You are an expert philosophy exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in ethics, meta-ethics, epistemology, metaphysics, logic,\n",
        "philosophy of mind and language, political philosophy, and the history of philosophy\n",
        "(ancient, medieval, modern, and contemporary).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any passage and all answer options) very carefully.\n",
        "- Treat the text and wording of the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY PHILOSOPHICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential philosophical clues, such as:\n",
        "   - the main concept (e.g., categorical imperative, utilitarianism, internalism vs externalism,\n",
        "     Gettier problem, a priori vs a posteriori, necessary vs sufficient conditions),\n",
        "   - the relevant philosopher or school (e.g., Kant, Mill, Hume, Plato, Aristotle, Rawls, behaviorism, logical positivism),\n",
        "   - the logical structure (e.g., what follows from what, which statement would they reject, which principle is violated).\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, distinctions, and canonical views of philosophers.\n",
        "- Do NOT invent new doctrines or attribute views to philosophers that are not well-established.\n",
        "- Apply the standard reading unless the CONTEXT explicitly specifies a different interpretation.\n",
        "\n",
        "4) APPLY PHILOSOPHICAL DOCTRINES PRECISELY\n",
        "- Identify which theory, argument, or distinction the question is really testing.\n",
        "- Pay attention to:\n",
        "  - necessary vs sufficient conditions,\n",
        "  - analytic vs synthetic, a priori vs a posteriori,\n",
        "  - validity vs soundness,\n",
        "  - deontological vs consequentialist reasoning,\n",
        "  - internal vs external justification,\n",
        "  - the exact wording of a principle or formulation (e.g., Kant’s Humanity formulation, Mill’s harm principle).\n",
        "- For “Which of the following would X most likely endorse/reject?” style questions, base your choice on\n",
        "  X’s actual doctrine, not on your own judgment of what is true.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH option:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions or doctrines from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the canonical definition or the philosopher’s standard view,\n",
        "    - captures the fundamental idea of the theory rather than a peripheral detail,\n",
        "    - does not add extra assumptions not stated in the QUESTION,\n",
        "    - uses the correct logical strength (e.g., does not turn “some” into “all,” does not confuse necessary with sufficient).\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume extra premises, background facts, or historical claims that are not stated or strongly implied.\n",
        "- Do NOT change the content of a doctrine to make an option fit better; respect standard textbook interpretations.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_philosophy = ChatPromptTemplate.from_template(SOLVER_PROMPT_PHILOSOPHY_TMPL)"
      ],
      "metadata": {
        "id": "N8QdzTMzGsT-"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_PSYCHOLOGY_TMPL = \"\"\"\n",
        "You are an expert psychology exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in clinical psychology, cognitive psychology, social psychology,\n",
        "developmental psychology, personality, biological/physiological psychology, learning, psychometrics,\n",
        "research methods, and ethics (e.g., APA code of conduct).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any vignette, description, and all answer options) very carefully.\n",
        "- Treat the facts and wording in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY PSYCHOLOGICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential psychological clues, such as:\n",
        "   - the main construct or theory (e.g., classical conditioning, operant conditioning, working memory,\n",
        "     attachment style, Big Five traits, self-efficacy, cognitive dissonance),\n",
        "   - the relevant theorist or model (e.g., Piaget, Vygotsky, Erikson, Kohlberg, Bandura, Beck),\n",
        "   - the developmental stage or level (e.g., preconventional vs conventional, sensorimotor vs formal operational),\n",
        "   - the type of design or method (e.g., experiment vs correlational study, longitudinal vs cross-sectional),\n",
        "   - the key symptoms, behaviors, or ethical requirements described in the vignette.\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, diagnostic criteria (at a conceptual level),\n",
        "  major theories, stages, and classical experiments.\n",
        "- Do NOT invent new constructs or attribute theories to psychologists who are not associated with them.\n",
        "- Apply the standard textbook interpretation unless the CONTEXT explicitly specifies a different one.\n",
        "\n",
        "4) APPLY PSYCHOLOGICAL THEORIES PRECISELY\n",
        "- Identify which theory, construct, stage, or principle the question is really testing.\n",
        "- Pay attention to:\n",
        "  - necessary features vs incidental details of a concept,\n",
        "  - differences between similar concepts (e.g., negative reinforcement vs punishment,\n",
        "    state vs trait, reliability vs validity),\n",
        "  - differences between stages (e.g., Kohlberg’s Stage 1 vs Stage 2, Erikson’s crises),\n",
        "  - the direction of cause/effect or prediction implied by the theory.\n",
        "- For ethics questions (e.g., APA), carefully consider:\n",
        "  - informed consent, confidentiality, competence, dual relationships, and risk of harm,\n",
        "  - what the code obligates the psychologist to do in the specific situation.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions or theories from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the canonical textbook definition or theory,\n",
        "    - directly fits ALL key facts given in the QUESTION (age, setting, behavior, stated intentions),\n",
        "    - does not rely on extra assumptions not stated in the QUESTION,\n",
        "    - has the correct level of generality (not too narrow, not too broad) for the construct or stage.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume additional symptoms, diagnoses, or background history that are not clearly stated.\n",
        "- Do NOT assume the person has specific knowledge or intentions beyond what the QUESTION describes.\n",
        "- Do NOT guess rare or exotic explanations when a standard, well-known theory clearly fits better.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_psychology = ChatPromptTemplate.from_template(SOLVER_PROMPT_PSYCHOLOGY_TMPL)"
      ],
      "metadata": {
        "id": "CfCInWkcGt9D"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_BUSINESS_TMPL = \"\"\"\n",
        "You are an expert business and economics exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and MBA level) in microeconomics, macroeconomics, finance, accounting, management,\n",
        "organizational behavior, marketing, operations, business ethics, and quantitative methods.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any tables, numbers, and all answer options) very carefully.\n",
        "- Treat the facts, numerical data, and wording in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY BUSINESS / ECON CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential clues, such as:\n",
        "   - the main domain (e.g., microeconomics, macroeconomics, corporate finance, accounting, management, marketing),\n",
        "   - key concepts (e.g., opportunity cost, elasticity, present value, NPV, CAPM, break-even point,\n",
        "     comparative advantage, marginal cost/benefit, principal–agent problem, game theory, externalities),\n",
        "   - relevant formulas or relationships (e.g., PV = CF/(1+r)^t, profit = TR – TC, elasticity definitions,\n",
        "     accounting identities, basic statistics),\n",
        "   - organizational/management concepts (e.g., leadership style, motivation theory, decision-making biases),\n",
        "   - business ethics or corporate governance principles.\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS AND FORMULAS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, formulas, and conceptual relationships.\n",
        "- Do NOT invent new theories or assume non-standard definitions.\n",
        "- Apply the standard textbook interpretation unless the CONTEXT explicitly specifies a different one.\n",
        "\n",
        "4) APPLY BUSINESS / ECONOMIC LOGIC PRECISELY\n",
        "- Identify which concept, model, or calculation the question is really testing.\n",
        "- Pay careful attention to:\n",
        "  - the difference between average vs marginal, stock vs flow, nominal vs real, short run vs long run,\n",
        "  - risk vs return, cost of capital, discounting vs compounding,\n",
        "  - accounting distinctions (asset/liability/equity, revenue vs profit, cash vs accrual),\n",
        "  - supply–demand shifts vs movement along a curve,\n",
        "  - game-theoretic reasoning (dominant strategies, Nash equilibrium),\n",
        "  - basic statistical reasoning (mean, variance, correlation vs causation).\n",
        "- When numbers are given, use them logically and consistently.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions, models, or formulas from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the exact definitions and standard formulas,\n",
        "    - correctly uses all given information in the QUESTION (including signs, units, and constraints),\n",
        "    - does not rely on extra assumptions not stated in the QUESTION,\n",
        "    - has the correct economic or managerial interpretation (no confusion of cause and effect, or average vs marginal).\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume additional data (e.g., extra numbers, extra constraints) that are not given.\n",
        "- Do NOT assume a different market structure, time period, or financial environment unless clearly stated.\n",
        "- Do NOT change definitions (e.g., of elasticity, NPV, beta, ROI) to force an option to fit.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_business = ChatPromptTemplate.from_template(SOLVER_PROMPT_BUSINESS_TMPL)"
      ],
      "metadata": {
        "id": "WmUL2wWTGxsi"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_HISTORY_TMPL = \"\"\"\n",
        "You are an expert history exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in world history, U.S. history, European history, Asian history,\n",
        "Latin American and African history, intellectual and cultural history, political history,\n",
        "economic history, and questions based on primary-source excerpts.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any passage, quotation, data, and all answer options) very carefully.\n",
        "- Treat the facts, wording, and time/place cues in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY HISTORICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential historical clues, such as:\n",
        "   - time period or approximate dates (e.g., “late 18th century,” “interwar period,” “Post–World War II”),\n",
        "   - geographic region or polity (e.g., Tang China, Mughal India, Weimar Germany, Cold War United States),\n",
        "   - type of source (e.g., political speech, treaty, law code, memoir, propaganda, religious text),\n",
        "   - key themes (e.g., imperialism, industrialization, nationalism, revolution, reform, decolonization, globalization),\n",
        "   - actors and relationships (e.g., state vs. frontier peoples, colonizer vs. colonized, elite vs. peasantry).\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL HISTORY, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard chronology, major events, and characteristic policies or ideas\n",
        "  of states, movements, and historical figures.\n",
        "- Do NOT overwrite or ignore specific details given in the QUESTION (e.g., who is speaking, to whom, and in what setting).\n",
        "- Apply widely accepted historical interpretations unless the CONTEXT or QUESTION clearly specifies a particular viewpoint.\n",
        "\n",
        "4) INTERPRET SOURCES AND CAUSALITY CAREFULLY\n",
        "- For questions based on a passage or source:\n",
        "  - Focus on what the author explicitly states and what is strongly implied by the text.\n",
        "  - Distinguish between what the author approves of and what they criticize.\n",
        "  - Note the tone, audience, and purpose (e.g., justify a policy, criticize a ruler, mobilize support).\n",
        "- Pay careful attention to:\n",
        "  - cause vs. effect (do not confuse consequences with causes),\n",
        "  - continuity vs. change over time,\n",
        "  - similarities vs. differences between regions or periods,\n",
        "  - whether the question is asking for context, consequence, motivation, or historical significance.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - relevant facts or patterns from the CONTEXT (chronology, policies, institutions, conflicts).\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the specific time, place, and actors indicated in the QUESTION,\n",
        "    - fits the main theme or process the QUESTION is testing,\n",
        "    - does not rely on anachronistic assumptions or events from a different period,\n",
        "    - avoids overgeneralization or mixing different regions or eras.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT introduce additional events, dates, or policies that are not supported by the QUESTION or reliable CONTEXT.\n",
        "- Do NOT move events to different centuries or regions just to make an option fit.\n",
        "- Do NOT attribute quotes or ideas to the wrong person or regime.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_history = ChatPromptTemplate.from_template(SOLVER_PROMPT_HISTORY_TMPL)"
      ],
      "metadata": {
        "id": "kQGCsJ7PGzxH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_with_rag_and_wiki(question_text: str):\n",
        "    final_letter = None\n",
        "    # 1) 1단계 LLM: 카테고리 + 키워드\n",
        "    category, keywords = classify_and_extract_keywords(question_text)\n",
        "    if category not in vectorstore:\n",
        "        print(f\"[WARN] Unknown category '{category}', fallback to 'business'\")\n",
        "        category = \"business\"\n",
        "\n",
        "    # 2) 컨텍스트 구성 (FAISS + Wikipedia)\n",
        "    context = build_context_for_solver(question_text, category, keywords)\n",
        "\n",
        "    # 3) 2단계 LLM: CoT로 정답 도출\n",
        "    if category == \"law\":\n",
        "      messages = solver_prompt_law.format_messages(\n",
        "          context=context,\n",
        "          question=question_text\n",
        "      )\n",
        "    elif category == \"philosophy\":\n",
        "      messages = solver_prompt_philosophy.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"psychology\":\n",
        "      messages = solver_prompt_psychology.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"business\":\n",
        "      messages = solver_prompt_business.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"history\":\n",
        "        messages = solver_prompt_history.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "\n",
        "    resp = llm_solver.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # (1) 아래쪽 줄부터 \"FINAL ANSWER\"가 들어간 줄 찾기 (마크다운 포함 허용)\n",
        "    for line in raw.splitlines()[::-1]:  # 아래에서부터 검색\n",
        "        s = line.strip()\n",
        "\n",
        "        # '**Final Answer: A**' 같이 생긴 것도 잡기 위해 'in' 사용\n",
        "        if \"FINAL ANSWER\" in s.upper():\n",
        "            # 마크다운 볼드 제거\n",
        "            s = s.replace(\"**\", \"\").strip()\n",
        "            # 정규식으로 'Final Answer: X'에서 X만 뽑기\n",
        "            m = re.search(r\"FINAL ANSWER\\s*:\\s*([A-Z])\", s, re.IGNORECASE)\n",
        "            if m:\n",
        "                final_letter = m.group(1).upper()\n",
        "                break\n",
        "\n",
        "    # 그래도 못 찾으면, 전체 텍스트에서 대문자 한 글자 검색\n",
        "    if final_letter is None:\n",
        "        for ch in raw:\n",
        "            if \"A\" <= ch <= \"Z\":\n",
        "                final_letter = ch\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"category\": category,\n",
        "        \"keywords\": keywords,\n",
        "        \"raw_reasoning\": raw,       # 디버깅/분석용\n",
        "        \"final_answer\": final_letter,\n",
        "    }"
      ],
      "metadata": {
        "id": "zuM_qWD6G13B"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mmlu용 majority voting 함수"
      ],
      "metadata": {
        "id": "yeYWPeFOlc_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from typing import Callable, Dict, Any\n",
        "\n",
        "def majority_vote_mmlu(\n",
        "    solve_once_fn: Callable[[str], Dict[str, Any]],\n",
        "    prompt: str,\n",
        "    n_vote: int = 5,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    solve_once_fn: full_prompt(str) -> {\"final_answer\": \"A\", ...} 형태로 결과를 주는 함수\n",
        "    prompt: 문제 전체 문자열 (질문 + 보기)\n",
        "    n_vote: 몇 번 반복할지 (기본 5번)\n",
        "\n",
        "    return:\n",
        "        {\n",
        "          \"final_answer\": \"A\",\n",
        "          \"all_votes\": [\"A\",\"B\",\"A\",\"A\",\"C\"],\n",
        "          \"vote_summary\": {\"A\":3, \"B\":1, \"C\":1},\n",
        "          \"winner_run\": <solve_once_fn가 반환한 dict 중에서 우승 답과 같은 걸 하나>\n",
        "        }\n",
        "    \"\"\"\n",
        "    votes = []\n",
        "    outs  = []\n",
        "\n",
        "    for _ in range(n_vote):\n",
        "        out = solve_once_fn(prompt)\n",
        "        outs.append(out)\n",
        "        ans = (out.get(\"final_answer\") or \"\").strip().upper()\n",
        "        if ans and ans in \"ABCDEFGHIJ\":\n",
        "            votes.append(ans)\n",
        "\n",
        "    if not votes:\n",
        "        # 진짜로 답을 하나도 못 뽑으면 fallback\n",
        "        return {\n",
        "            \"final_answer\": \"\",\n",
        "            \"all_votes\": [],\n",
        "            \"vote_summary\": {},\n",
        "            \"winner_run\": outs[0] if outs else {},\n",
        "        }\n",
        "\n",
        "    counter = Counter(votes)\n",
        "    final_ans, _ = counter.most_common(1)[0]\n",
        "\n",
        "    # 우승 답과 같은 run 하나 골라서 reasoning/log 같이 넘겨주기\n",
        "    winner_run = next((o for o in outs if (o.get(\"final_answer\") or \"\").upper() == final_ans), outs[0])\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"all_votes\": votes,\n",
        "        \"vote_summary\": dict(counter),\n",
        "        \"winner_run\": winner_run,\n",
        "    }"
      ],
      "metadata": {
        "id": "TU9oRQ8nlhyT"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트"
      ],
      "metadata": {
        "id": "JnboclVjj564"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_korean(text: str) -> bool:\n",
        "    \"\"\"문자열에 한글이 하나라도 들어있으면 한국어라고 간주.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "    return bool(re.search(r\"[가-힣]\", text))"
      ],
      "metadata": {
        "id": "w5yL7RhNHb8D"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_ewha_single(prompt: str,\n",
        "                      qa_chain,\n",
        "                      n_vote: int = 5) -> str:\n",
        "    votes = []\n",
        "\n",
        "    for _ in range(n_vote):\n",
        "        response = qa_chain.invoke(prompt)   # {'result': '...', 'source_documents': [...]}\n",
        "        text = response[\"result\"]\n",
        "        ans = extract_answer(text)          # 네가 위에 정의한 extract_answer 사용\n",
        "        if ans:\n",
        "            votes.append(ans.strip().upper())\n",
        "\n",
        "    if not votes:\n",
        "        return \"\"   # 진짜 아무것도 못 뽑으면 빈 문자열\n",
        "\n",
        "    counter = Counter(votes)\n",
        "    final_ans, _ = counter.most_common(1)[0]\n",
        "    return final_ans"
      ],
      "metadata": {
        "id": "s3Y6uWgOlqEa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_pro1_single(prompt: str, outer_votes: int = 5) -> Dict[str, Any]:\n",
        "    def _solve_once(q: str) -> Dict[str, Any]:\n",
        "        # 내부 self-consistency는 끄고(=1), 외부에서만 5번 투표\n",
        "        out = solve_mmlu_astute_style(\n",
        "            full_prompt=q,\n",
        "            use_wiki=True,\n",
        "            n_vote=1,\n",
        "        )\n",
        "        # solve_mmlu_astute_style이 이미 \"final_answer\" 키를 갖고 있다고 가정\n",
        "        return out\n",
        "\n",
        "    mv = majority_vote_mmlu(_solve_once, prompt, n_vote=outer_votes)\n",
        "\n",
        "    winner = mv[\"winner_run\"]\n",
        "    final_ans = mv[\"final_answer\"]\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": winner.get(\"category\", \"\"),\n",
        "        \"raw_reasoning\": winner.get(\"raw_reasoning\", \"\"),\n",
        "        \"vote_summary\": mv[\"vote_summary\"],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "XhfbdNXeHY31"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_pro2_single(prompt: str, outer_votes: int = 5) -> Dict[str, Any]:\n",
        "    def _solve_once(q: str) -> Dict[str, Any]:\n",
        "        out = solve_mmlu_with_rag_and_wiki(q)\n",
        "        return out\n",
        "\n",
        "    mv = majority_vote_mmlu(_solve_once, prompt, n_vote=outer_votes)\n",
        "\n",
        "    winner = mv[\"winner_run\"]\n",
        "    final_ans = mv[\"final_answer\"]\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": winner.get(\"category\", \"\"),\n",
        "        \"raw_reasoning\": winner.get(\"raw_reasoning\", \"\"),\n",
        "        \"vote_summary\": mv[\"vote_summary\"],\n",
        "    }\n",
        "    # return final_ans"
      ],
      "metadata": {
        "id": "FC3tc8fAHXRu"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION_COL = \"prompts\"\n",
        "df = pd.read_csv(TESTSET_PATH)\n",
        "\n",
        "pred_lang  = []   # 'ko' or 'en'\n",
        "pred_m1    = []   # (ewha + mmlu_pro1) 정답\n",
        "pred_m2    = []   # (ewha + mmlu_pro2) 정답\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    q = str(row[QUESTION_COL])\n",
        "    print(f\"[{i}] Solving: {q[:60]}...\")\n",
        "\n",
        "    if is_korean(q):\n",
        "        # =======================\n",
        "        # 한국어 → Ewha 학칙 RAG\n",
        "        # =======================\n",
        "        pred_lang.append(\"ko\")\n",
        "\n",
        "        ans_ko = solve_ewha_single(\n",
        "            prompt=q,\n",
        "            qa_chain=ensemble_qa,\n",
        "            n_vote=5,\n",
        "        )\n",
        "\n",
        "        # 한국어 문제는 두 버전 CSV 모두 Ewha 답을 사용\n",
        "        pred_m1.append(ans_ko)\n",
        "        pred_m2.append(ans_ko)\n",
        "\n",
        "    else:\n",
        "        # =======================\n",
        "        # 영어 → mmlu_pro1 / mmlu_pro2\n",
        "        # =======================\n",
        "        pred_lang.append(\"en\")\n",
        "\n",
        "        # mmlu_pro1: Astute-RAG + 5번 voting\n",
        "        out1 = solve_mmlu_pro1_single(q, outer_votes=5)\n",
        "        # final_answer만 쓰고 싶으면 이렇게:\n",
        "        ans1 = out1[\"final_answer\"] if isinstance(out1, dict) else out1\n",
        "        pred_m1.append(ans1)\n",
        "\n",
        "        # mmlu_pro2: category RAG + 5번 voting\n",
        "        out2 = solve_mmlu_pro2_single(q, outer_votes=5)\n",
        "        ans2 = out2[\"final_answer\"] if isinstance(out2, dict) else out2\n",
        "        pred_m2.append(ans2)\n",
        "\n",
        "# 길이 체크 (디버깅용)\n",
        "print(\"len(df)   =\", len(df))\n",
        "print(\"len(pred_lang) =\", len(pred_lang))\n",
        "print(\"len(pred_m1)   =\", len(pred_m1))\n",
        "print(\"len(pred_m2)   =\", len(pred_m2))\n",
        "\n",
        "# -------------------------\n",
        "# (ewha + mmlu_pro1) 정답 csv\n",
        "# -------------------------\n",
        "df_m1 = df.copy()\n",
        "df_m1[\"pred_lang\"]      = pred_lang\n",
        "df_m1[\"rag_cot_answer\"] = pred_m1\n",
        "df_m1.to_csv(\"testset_ewha_mmlu1.csv\", index=False)\n",
        "print(\"[Saved] testset_ewha_mmlu1.csv\")\n",
        "\n",
        "# -------------------------\n",
        "# (ewha + mmlu_pro2) 정답 csv\n",
        "# -------------------------\n",
        "df_m2 = df.copy()\n",
        "df_m2[\"pred_lang\"]      = pred_lang\n",
        "df_m2[\"rag_cot_answer\"] = pred_m2\n",
        "df_m2.to_csv(\"testset_ewha_mmlu2.csv\", index=False)\n",
        "print(\"[Saved] testset_ewha_mmlu2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmmN4y0Jl_8v",
        "outputId": "d34f6c8c-44c9-48f9-973b-bfd273fca273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Solving: QUESTION1) 재학 중인 학생이 휴학을 하려면 학기 개시일로부터 며칠 이내에 휴학을 신청하야하나요?\n",
            "(...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[1] Solving: QUESTION2) '재입학은 a회에 한하여 할 수 있다. 다만 제 28조제4호에 의하여 제적된 자는 제적된...\n",
            "Matched answer: ['D', 'D']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "[2] Solving: QUESTION3) 학생이 소속 학과 또는 전공 이외의 전공 교과목을 총장이 정하는 바에 따라 몇학점 이상 ...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[3] Solving: QUESTION4) 다음 보기의 학생들 중 제적을 당하지 않는 사람을 고르면?\n",
            "(A) 팜 : 징계에 의해 퇴...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[4] Solving: QUESTION5) 2019학년도 휴먼기계바이오공학부의 입학 정원은 몇 명인가? \n",
            "(A) 90명 \n",
            "(B) 1...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[5] Solving: QUESTION6) 1980학년도 이전 입학생에 대하여 적용하는 등급에 따른 성적점으로 잘못 연결된 것은 무...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "[6] Solving: QUESTION7) 사회체육학과 소속 학생에게 수여하는 학위는 무엇인가? \n",
            "(A) 공학사 \n",
            "(B) 문학사 \n",
            "...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[7] Solving: QUESTION8) 복수전공 신청 자격에 해당하지 않는 것은? \n",
            "(A) 1학년을 마친 학생 \n",
            "(B) 평균 평...\n",
            "Matched answer: ['C', 'C']\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Matched answer: ['C']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uf90_SyTmM3C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}