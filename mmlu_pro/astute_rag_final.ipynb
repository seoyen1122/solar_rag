{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoyen1122/solar_rag/blob/main/mmlu_pro/astute_rag_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문서 분석 로직 & 외부 문서는 그냥 불러오기\n"
      ],
      "metadata": {
        "id": "lXWGosH071IU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nyH8sMMs2RD-",
        "outputId": "f2181e6d-7cc6-4acf-aa58-1166a863e78c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-upstage\n",
            "  Downloading langchain_upstage-0.7.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-upstage) (1.1.0)\n",
            "Collecting langchain-openai<2.0.0,>=1.0.2 (from langchain-upstage)\n",
            "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pypdf<5.0.0,>=4.2.0 (from langchain-upstage)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from langchain-upstage) (2.32.4)\n",
            "Collecting tokenizers<0.21.0,>=0.20.0 (from langchain-upstage)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.31.0 (from langchain-upstage)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.47)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (4.15.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<0.21.0,>=0.20.0->langchain-upstage) (0.36.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.3->langchain-upstage) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (2025.11.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_upstage-0.7.5-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, typing-inspect, tokenizers, dataclasses-json, langchain-text-splitters, langchain-openai, langchain-upstage, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "transformers 4.57.2 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-openai-1.1.0 langchain-text-splitters-1.0.0 langchain-upstage-0.7.5 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-4.3.1 requests-2.32.5 tokenizers-0.20.3 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-upstage langchain-community pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pdBgMTNwMuCm",
        "outputId": "cf483115-8388-4f33-abc6-05f2cd4511c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from wikipedia-api) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (2025.11.12)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=cd018f7495e7b9a44bce1d38008f21edfe97e0fa8973dc1ca49e4dd49cc5aefe\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/3c/79/b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ],
      "source": [
        "pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C-AXD7fLRJI-",
        "outputId": "896dcde4-fcb6-40d6-f914-e05f8530b863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdAIEV27UrkW",
        "outputId": "36cc979a-3142-411a-9c90-7bb78d30ea88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-upstage 0.7.5 requires tokenizers<0.21.0,>=0.20.0, but you have tokenizers 0.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8qWw7Tq17dHw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import wikipediaapi\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u3yQM7bzVIz",
        "outputId": "03e27744-4213-4551-a178-f7ea688cb6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gavGzRrztXz",
        "outputId": "7df768b5-0c60-492d-f7c4-6acc830d8a7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp team project\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/nlp team project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c-yFVp9vQ26G"
      },
      "outputs": [],
      "source": [
        "UPSTAGE_API_KEY = \"up_VYzFNHEoEJPfAwYUNp5v9n1CPnMOm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgvozRFhCJMz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"testset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK1l_XYgUPay"
      },
      "outputs": [],
      "source": [
        "llm_classifier = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oElUzmTxV6M-"
      },
      "outputs": [],
      "source": [
        "llm_solver = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solar_pro = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "CNd-bE5razCS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T6fjf7tL0E6A"
      },
      "outputs": [],
      "source": [
        "category_index = {\n",
        "    \"law\":        \"/content/drive/MyDrive/nlp team project/code/mmlu_category/law\",\n",
        "    \"psychology\": \"/content/drive/MyDrive/nlp team project/code/mmlu_category/psychology\",\n",
        "    \"business\":   \"/content/drive/MyDrive/nlp team project/code/mmlu_category/business\",\n",
        "    \"philosophy\": \"/content/drive/MyDrive/nlp team project/code/mmlu_category/philosophy\",\n",
        "    \"history\":    \"/content/drive/MyDrive/nlp team project/code/mmlu_category/history\",\n",
        "}\n",
        "\n",
        "categories = list(category_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wvfgJRYeP9M4"
      },
      "outputs": [],
      "source": [
        "\n",
        "emb = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large-passage\")\n",
        "\n",
        "# 카테고리별 faiss 한번에 로드해서 캐시\n",
        "vectorstore = {}\n",
        "for cat, path in category_index.items():\n",
        "    vectorstore[cat] = FAISS.load_local(\n",
        "        folder_path=path,\n",
        "        embeddings=emb,\n",
        "        allow_dangerous_deserialization=True,\n",
        "    )\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(user_agent= \"NLP-RAG/1.0\", language = 'en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRn3avDKKexv"
      },
      "source": [
        "**1st LLM**:\n",
        "\n",
        "- return category\n",
        "\n",
        "- return 3 keywords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import json\n",
        "\n",
        "# 질문 분석을 위한 전용 프롬프트\n",
        "P_ANALYZE_TMPL = \"\"\"\n",
        "You are an expert Question Analyst for MMLU-Pro.\n",
        "Your task is NOT to answer the question, but to dissect it so that a researcher can find the best evidence.\n",
        "\n",
        "[Available Categories]\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "- other\n",
        "\n",
        "[Task]\n",
        "Analyze the question and options to provide a structured JSON output.\n",
        "You must differentiate between search strategies for **Textbooks** (Vector DB) and **Wikipedia** (Keyword Match).\n",
        "\n",
        "[Output Fields]\n",
        "1. \"category\": Choose ONE from the list above.\n",
        "2. \"core_intent\": Summarize what the question is asking in 1 sentence.\n",
        "3. \"constraints\": List strict conditions (time period, specific person, negation 'NOT', location).\n",
        "4. \"search_queries\": Generate 3-5 **sentence-style** queries for vector search.\n",
        "   - **CRITICAL**: Translate specific scenarios into **Professional/Legal/Academic Terminology**.\n",
        "   - Example: \"Man hit neighbor\" -> \"Tort law battery elements\"\n",
        "5. \"wiki_keywords\": Extract 3-5 **specific entities or nouns** for Wikipedia title search.\n",
        "   - Example: [\"Battery (tort)\", \"Common law\", \"Trespass\"]\n",
        "\n",
        "[Example Shot]\n",
        "Question: \"According to Jean Piaget, at which stage of cognitive development do children begin to think logically about abstract concepts and hypothetical situations?\"\n",
        "Options: (A) Sensorimotor (B) Preoperational (C) Concrete operational (D) Formal operational\n",
        "\n",
        "Output:\n",
        "{{\n",
        "  \"category\": \"psychology\",\n",
        "  \"core_intent\": \"Identify the Piagetian stage associated with abstract and hypothetical reasoning.\",\n",
        "  \"constraints\": [\"Jean Piaget's theory\", \"Abstract concepts\", \"Hypothetical situations\", \"Logic\"],\n",
        "  \"search_queries\": [\n",
        "    \"Piaget cognitive development stages abstract reasoning\",\n",
        "    \"Characteristics of formal operational stage\",\n",
        "    \"Difference between concrete and formal operational stages\"\n",
        "  ],\n",
        "  \"wiki_keywords\": [\n",
        "    \"Jean Piaget\",\n",
        "    \"Cognitive development\",\n",
        "    \"Formal operational stage\",\n",
        "    \"Theory of cognitive development\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "[Real Input]\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Options:\n",
        "{options_text}\n",
        "\n",
        "Return ONLY the valid JSON object.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_analyze_prompt = ChatPromptTemplate.from_template(P_ANALYZE_TMPL)\n",
        "\n",
        "def run_p_analyze(question_text: str, options: dict, llm=None) -> dict:\n",
        "    \"\"\"\n",
        "    질문을 분석하여 검색 쿼리와 제약 조건을 추출합니다.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        llm = llm_solver  # 기존에 정의된 llm 객체 사용\n",
        "\n",
        "    # 옵션 텍스트화\n",
        "    options_str = \"\\n\".join([f\"({k}) {v}\" for k, v in options.items()])\n",
        "\n",
        "    messages = p_analyze_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        options_text=options_str\n",
        "    )\n",
        "\n",
        "    resp = llm.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # JSON 파싱 (실패 시 기본값 반환 처리 포함)\n",
        "    try:\n",
        "        # 마크다운 코드 블록 제거 등 기본적인 정제\n",
        "        if \"```json\" in raw:\n",
        "            raw = raw.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in raw:\n",
        "            raw = raw.split(\"```\")[0].strip()\n",
        "\n",
        "        analysis = json.loads(raw)\n",
        "        return analysis\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] p_analyze failed: {e}\")\n",
        "        # 실패 시 기본값: 검색어는 질문 그대로\n",
        "        return {\n",
        "            \"core_intent\": \"Unknown\",\n",
        "            \"constraints\": [],\n",
        "            \"search_queries\": [question_text]\n",
        "        }"
      ],
      "metadata": {
        "id": "11SgvgDz6WBW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e_n3aEbhUxxX"
      },
      "outputs": [],
      "source": [
        "def fetch_wiki_context(keywords, window_size=2000):\n",
        "    snippets = []\n",
        "    seen_titles = set()\n",
        "\n",
        "    for kw in keywords:\n",
        "        kw = (kw or \"\").strip()\n",
        "        if not kw: continue\n",
        "\n",
        "        candidates = [kw, kw.title()]\n",
        "        # 괄호 제거 등 추가 처리\n",
        "        if \"(\" in kw: candidates.append(kw.split(\"(\")[0].strip())\n",
        "\n",
        "        found_flag = False\n",
        "        for cand in candidates:\n",
        "            if cand in seen_titles: continue\n",
        "\n",
        "            try:\n",
        "                page = wiki.page(cand)\n",
        "                if page.exists():\n",
        "                    seen_titles.add(cand)\n",
        "                    full_text = page.text\n",
        "\n",
        "                    # [개선] 단순히 앞부분만 자르는 게 아니라, 키워드가 등장하는 위치를 찾음\n",
        "                    # 키워드가 텍스트 내에 있으면 그 주변을 가져옴. 없으면 앞부분 가져옴.\n",
        "                    lower_text = full_text.lower()\n",
        "                    lower_kw = kw.lower()\n",
        "                    start_idx = lower_text.find(lower_kw)\n",
        "\n",
        "                    if start_idx == -1:\n",
        "                        # 키워드 못 찾으면 그냥 앞부분\n",
        "                        display_text = full_text[:window_size]\n",
        "                    else:\n",
        "                        # 키워드 주변부 (앞으로 500자, 뒤로 1500자 정도)\n",
        "                        start_pos = max(0, start_idx - 500)\n",
        "                        end_pos = min(len(full_text), start_idx + window_size)\n",
        "                        display_text = full_text[start_pos:end_pos]\n",
        "\n",
        "                    clean_text = display_text.replace('\\n', ' ')\n",
        "                    snippets.append(f\"[Wikipedia: {page.title}]\\n...{clean_text}...\")\n",
        "                    found_flag = True\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    if not snippets:\n",
        "        return \"\"\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TIwiC6e0e44n"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "############################################\n",
        "# 0. 상수 & 기본 설정\n",
        "############################################\n",
        "\n",
        "TOP_K_TEXTBOOK = 5\n",
        "TOP_K_WIKI = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 1. 질문 + 옵션(A~I) 파싱\n",
        "############################################\n",
        "\n",
        "# 1. 질문 + 옵션(A~J) 파싱\n",
        "def parse_question_and_options(prompt: str):\n",
        "    \"\"\"\n",
        "    prompt: QUESTION + (A) ~ (J) 옵션이 한 문자열에 들어있는 형태\n",
        "    return: question_text(str), options(dict: 'A'~'J' -> str)\n",
        "    \"\"\"\n",
        "    pattern = r\"\\(([A-J])\\)\\s*\"\n",
        "    matches = list(re.finditer(pattern, prompt))\n",
        "\n",
        "    if not matches:\n",
        "        return prompt.strip(), {}\n",
        "\n",
        "    first = matches[0]\n",
        "    question_text = prompt[:first.start()].strip()\n",
        "\n",
        "    options: Dict[str, str] = {}\n",
        "    for idx, m in enumerate(matches):\n",
        "        letter = m.group(1)  # 'A'~'J'\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(prompt)\n",
        "        opt_text = prompt[start:end].strip()\n",
        "        options[letter] = opt_text\n",
        "\n",
        "    return question_text, options\n"
      ],
      "metadata": {
        "id": "lNFvwZRPpuBu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 2. \"Final Answer: X\" 파서\n",
        "############################################\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    p_ans 출력에서 'Final Answer: X' 의 X(A~J)를 뽑기.\n",
        "    \"\"\"\n",
        "    m = re.search(r\"Final Answer:\\s*([A-J])\\s*$\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if m:\n",
        "        return m.group(1).upper()\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "zaonqmXWp2gf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################\n",
        "# 3. Memory p_gen (INTERNAL 문서 생성)\n",
        "############################################\n",
        "\n",
        "P_MEM_TMPL = \"\"\"\n",
        "You are a knowledgeable expert in {category}.\n",
        "\n",
        "Task: Using ONLY your own internal knowledge (without seeing any external documents),\n",
        "generate a short document that provides accurate and relevant information to help\n",
        "answer the given exam question.\n",
        "\n",
        "If you truly do not know the answer or lack enough information, explicitly state\n",
        "\"I don't know\" rather than hallucinating facts.\n",
        "\n",
        "Exam Question:\n",
        "{question_text}\n",
        "\n",
        "Write ONE coherent document that:\n",
        "- Focuses only on concepts, definitions, and relations that are relevant to the question.\n",
        "- Is self-contained and clear enough to help another model answer the question.\n",
        "- Avoids unnecessary details.\n",
        "\n",
        "Document:\n",
        "\"\"\".strip()\n",
        "\n",
        "p_mem_prompt = ChatPromptTemplate.from_template(P_MEM_TMPL)\n",
        "\n",
        "\n",
        "def run_p_mem(category: str, question_text: str, llm=None) -> str:\n",
        "    if llm is None:\n",
        "        llm = llm_solver\n",
        "    msgs = p_mem_prompt.format_messages(\n",
        "        category=category,\n",
        "        question_text=question_text,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()"
      ],
      "metadata": {
        "id": "bu5pWXR0p6mv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_p_gen_for_docs(\n",
        "    category: str,             # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    source_type: str,          # \"TEXTBOOK\" or \"WIKIPEDIA\"\n",
        "    question_text: str,        # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    raw_passages: List[str],   # 검색된 원본 텍스트 리스트\n",
        "    start_doc_idx: int = 1,\n",
        "    llm=None,                  # 사용 안 함 (호환성 위해 남겨둠)\n",
        ") -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    [수정됨] LLM을 통한 요약/재작성을 수행하지 않습니다.\n",
        "    검색된 Raw Passage를 그대로 포맷팅하여 반환합니다.\n",
        "    이렇게 해야 정보 손실(Information Loss) 없이 p_con이나 p_ans 단계로 넘어갑니다.\n",
        "    \"\"\"\n",
        "    doc_blocks = []\n",
        "    cur_idx = start_doc_idx\n",
        "\n",
        "    for k, passage in enumerate(raw_passages, start=1):\n",
        "        # 빈 텍스트 무시\n",
        "        if not passage or not passage.strip():\n",
        "            continue\n",
        "\n",
        "        # [중요] LLM 호출(invoke) 없이 원본 텍스트를 그대로 넣습니다.\n",
        "        # 필요하다면 너무 긴 문단만 파이썬 문자열 슬라이싱으로 자르세요 (예: [:2000])\n",
        "        clean_passage = passage.strip()\n",
        "\n",
        "        block = (\n",
        "            f\"[Doc {cur_idx} | SOURCE=EXTERNAL({source_type}) | ORIG_ID={source_type}_{k}]\\n\"\n",
        "            f\"{clean_passage}\"\n",
        "        )\n",
        "        doc_blocks.append(block)\n",
        "        cur_idx += 1\n",
        "\n",
        "    return \"\\n\\n\".join(doc_blocks), cur_idx"
      ],
      "metadata": {
        "id": "1At0qigQ54dp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgTA-0fz4Sc0",
        "outputId": "3030f22f-4e4c-46d1-89c4-88c9256eae8e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "############################################\n",
        "# 5. Retrieval helpers (Hybrid: Vector + BM25)\n",
        "############################################\n",
        "\n",
        "# 전역 캐시 (BM25 인덱스를 매번 만들지 않기 위해 저장)\n",
        "bm25_store = {}   # {category: BM25Okapi_object}\n",
        "doc_store = {}    # {category: [text_list]}\n",
        "\n",
        "def init_bm25_for_category(category: str):\n",
        "    \"\"\"\n",
        "    [초기화] 해당 카테고리의 모든 문서를 로드하여 BM25 인덱스를 생성\n",
        "    \"\"\"\n",
        "    if category in bm25_store:\n",
        "        return\n",
        "\n",
        "    if category not in vectorstore:\n",
        "        return\n",
        "\n",
        "    print(f\"[Init] Building BM25 index for: {category}...\")\n",
        "    vs = vectorstore[category]\n",
        "\n",
        "    try:\n",
        "        # FAISS 메모리에서 모든 문서 텍스트 추출\n",
        "        # (주의: FAISS 로드 시 데이터가 메모리에 있어야 함)\n",
        "        all_docs = list(vs.docstore._dict.values())\n",
        "        texts = [d.page_content for d in all_docs]\n",
        "\n",
        "        if not texts:\n",
        "            print(f\"[Warn] No texts found in docstore for {category}.\")\n",
        "            return\n",
        "\n",
        "        # 토크나이징 (단순 띄어쓰기 기준)\n",
        "        tokenized_corpus = [doc.lower().split() for doc in texts]\n",
        "\n",
        "        # 저장\n",
        "        bm25_store[category] = BM25Okapi(tokenized_corpus)\n",
        "        doc_store[category] = texts\n",
        "        print(f\"[Init] BM25 ready for {category} ({len(texts)} docs)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Warn] Failed to init BM25 for {category} (Pure Vector mode will be used): {e}\")\n",
        "\n",
        "\n",
        "def reciprocal_rank_fusion(results_list: List[List[str]], k=60) -> List[str]:\n",
        "    \"\"\"\n",
        "    [RRF 알고리즘] 여러 검색 결과의 순위를 합산하여 재정렬\n",
        "    \"\"\"\n",
        "    fused_scores = {}\n",
        "\n",
        "    for docs in results_list:\n",
        "        for rank, doc_text in enumerate(docs):\n",
        "            if doc_text not in fused_scores:\n",
        "                fused_scores[doc_text] = 0\n",
        "            # 순위가 높을수록(rank가 작을수록) 높은 점수 부여\n",
        "            fused_scores[doc_text] += 1 / (rank + k)\n",
        "\n",
        "    # 점수 높은 순 정렬\n",
        "    reranked = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [text for text, score in reranked]\n",
        "\n",
        "\n",
        "def get_textbook_passages(category: str, query: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    [수정된 함수] Hybrid Search 적용\n",
        "    1. Vector Search (의미 검색) -> 10개\n",
        "    2. BM25 Search (키워드 검색) -> 10개\n",
        "    3. RRF Fusion -> 상위 5개 반환\n",
        "    \"\"\"\n",
        "    if category not in vectorstore:\n",
        "        return []\n",
        "\n",
        "    # 0. BM25 준비\n",
        "    if category not in bm25_store:\n",
        "        init_bm25_for_category(category)\n",
        "\n",
        "    # 1. Vector Search (Semantic)\n",
        "    vs = vectorstore[category]\n",
        "    # 후보를 10개 정도 가져옴\n",
        "    vec_candidates = vs.similarity_search(query, k=10)\n",
        "    vec_results = [d.page_content for d in vec_candidates]\n",
        "\n",
        "    # 2. BM25 Search (Keyword) - 만약 준비 안됐으면 생략\n",
        "    bm25_results = []\n",
        "    if category in bm25_store:\n",
        "        bm25 = bm25_store[category]\n",
        "        docs = doc_store[category]\n",
        "\n",
        "        tokenized_query = query.lower().split()\n",
        "        # 키워드 매칭 상위 10개\n",
        "        bm25_results = bm25.get_top_n(tokenized_query, docs, n=10)\n",
        "\n",
        "    # 3. Fusion (하나만 있으면 그것만 반환)\n",
        "    if not bm25_results:\n",
        "        final_passages = vec_results\n",
        "    else:\n",
        "        # 두 결과를 섞음\n",
        "        final_passages = reciprocal_rank_fusion([vec_results, bm25_results], k=60)\n",
        "\n",
        "    # 최종 TOP_K 개수만큼 자르기\n",
        "    return final_passages[:TOP_K_TEXTBOOK]\n",
        "\n",
        "\n",
        "def get_wiki_passages(keywords: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    (기존 유지)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        raw = fetch_wiki_context(keywords)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Wikipedia retrieval failed: {e}\")\n",
        "        return []\n",
        "\n",
        "    raw = (raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return []\n",
        "    return [raw]"
      ],
      "metadata": {
        "id": "VJHLEssx2iHM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 6. Iterative Knowledge Consolidation p_con (Few-Shot Optimized)\n",
        "############################################\n",
        "\n",
        "P_CON_TMPL = \"\"\"\n",
        "You are a Knowledge Integrator for MMLU-Pro dataset.\n",
        "\n",
        "Task: Consolidate information from both your own memorized documents (INTERNAL)\n",
        "and externally retrieved documents (EXTERNAL) in response to the given exam question.\n",
        "\n",
        "Guidelines:\n",
        "* For documents that provide consistent information, cluster them together and\n",
        "  summarize the key details into a single, concise document.\n",
        "* For documents with conflicting information, separate them into distinct documents,\n",
        "  ensuring each document captures the unique perspective or data.\n",
        "* Exclude any information that is irrelevant to the question.\n",
        "* For each NEW document you create, clearly indicate:\n",
        "  - Whether the source was INTERNAL(MEMORY) or EXTERNAL(TEXTBOOK/WIKIPEDIA).\n",
        "  - The original document numbers that contributed to it (e.g., FROM=1,3,4).\n",
        "\n",
        "[Examples]\n",
        "\n",
        "<Example 1: Conflict Resolution>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=INTERNAL(MEMORY)]\n",
        "The Treaty of Versailles was signed in 1918.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "The Treaty of Versailles was signed on June 28, 1919, officially ending WWI.\n",
        "\n",
        "Question: When was the Treaty of Versailles signed?\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(TEXTBOOK) | FROM=2]\n",
        "The Treaty of Versailles was signed on June 28, 1919.\n",
        "(Correction: Internal memory incorrectly stated 1918, which was the armistice year, not the treaty signing.)\n",
        "</Example 1>\n",
        "\n",
        "<Example 2: Merging Consistent Info>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(WIKIPEDIA)]\n",
        "Classical conditioning involves a neutral stimulus becoming a conditioned stimulus.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "Pavlov's dog experiment demonstrated classical conditioning by pairing a bell with food.\n",
        "\n",
        "Question: Explain the mechanism of classical conditioning.\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=MERGED(EXTERNAL) | FROM=1,2]\n",
        "Classical conditioning is a learning process where a neutral stimulus (like a bell) becomes a conditioned stimulus after being paired with an unconditioned stimulus (like food). This was demonstrated in Pavlov's dog experiment.\n",
        "</Example 2>\n",
        "\n",
        "[Real Task]\n",
        "\n",
        "Initial Context (numbered documents):\n",
        "{context_init}\n",
        "\n",
        "Last Context (may be empty):\n",
        "{last_context}\n",
        "\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Now produce your New Context following the examples.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_con_prompt = ChatPromptTemplate.from_template(P_CON_TMPL)\n",
        "\n",
        "def run_p_con(\n",
        "    question_text: str,\n",
        "    context_init: str,\n",
        "    last_context: str = \"\",\n",
        "    llm=None,\n",
        ") -> str:\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    msgs = p_con_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        context_init=context_init,\n",
        "        last_context=last_context,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()\n"
      ],
      "metadata": {
        "id": "_Zpu4HRa6-rt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 7. Knowledge Consolidation + Answer Finalization p_ans (10-Option Optimized)\n",
        "############################################\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    모델이 내뱉는 다양한 형식을 모두 잡아내는 강력한 추출 함수\n",
        "    \"\"\"\n",
        "    if not text: return \"\"\n",
        "\n",
        "    # 1순위: \"Final Answer\" 뒤에 오는 첫 번째 영문자 (A-J) 찾기\n",
        "    # 예: \"**Final Answer:** (A)\", \"Final Answer: Option A\", \"Final Answer is [A]\"\n",
        "    # [^\\nA-J]* : 줄바꿈이나 A-J가 나오기 전까지의 모든 특수문자(:, *, 공백 등)를 무시\n",
        "    match = re.search(r\"Final Answer[^\\nA-J]*([A-J])\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if match:\n",
        "        return match.group(1).upper()\n",
        "\n",
        "    # 2순위: <ANSWER> 태그 (프롬프트에서 지시한 경우)\n",
        "    match_tag = re.search(r\"<ANSWER>\\s*\\(?([A-J])\\)?\", text, flags=re.IGNORECASE)\n",
        "    if match_tag:\n",
        "        return match_tag.group(1).upper()\n",
        "\n",
        "    # 3순위: 최후의 수단 - 문장 맨 끝에 있는 (A) 형태 찾기\n",
        "    fallback = re.findall(r\"\\(?([A-J])\\)?\", text.split(\"\\n\")[-1])\n",
        "    if fallback:\n",
        "        return fallback[-1].upper()\n",
        "\n",
        "    return \"\" # 정말 답이 없는 경우\n"
      ],
      "metadata": {
        "id": "aEK5ci917MW5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY_META = {\n",
        "    \"law\": {\n",
        "        \"role\": (\n",
        "            \"You are a distinguished Law Professor and Bar Exam Grader. \"\n",
        "            \"You specialize in applying strict legal doctrines to complex fact patterns. \"\n",
        "            \"Your expertise covers Contracts, Torts, Criminal Law, Property, Constitutional Law, and Evidence.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Spot the precise legal issue (e.g., specific crime, tort, contract doctrine).\\n\"\n",
        "            \"- Apply traditional common-law elements unless a statute in the context clearly overrides them.\\n\"\n",
        "            \"- For crimes, require that ALL elements are satisfied; if one element is missing, that crime is wrong.\\n\"\n",
        "            \"- For 'best defense' or 'most likely' questions, prefer options that directly attack missing elements or raise strong procedural bars \"\n",
        "            \"(e.g., Statute of Frauds, Statute of Limitations).\"\n",
        "        ),\n",
        "    },\n",
        "    \"business\": {\n",
        "        \"role\": (\n",
        "            \"You are a CPA (Certified Public Accountant) and Economics Professor. \"\n",
        "            \"You excel at financial accounting, managerial accounting, corporate finance, and micro/macroeconomics.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Carefully extract all numerical data and relationships before computing.\\n\"\n",
        "            \"- Show each calculation step explicitly (no guessing): check signs, totals, and units.\\n\"\n",
        "            \"- For finance questions, check if time value of money (PV/FV, discounting) is implied by dates or interest rates.\\n\"\n",
        "            \"- For conceptual items, ground answers in standard models (supply/demand, elasticity, basic game theory) rather than intuition.\"\n",
        "        ),\n",
        "    },\n",
        "    \"history\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert Historian specializing in primary source analysis. \"\n",
        "            \"You handle World, U.S., European, and Asian history with a focus on chronology and causality.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- First fix the time period and region using names, events, or terminology.\\n\"\n",
        "            \"- Eliminate options that are anachronistic (wrong century, wrong ruler, wrong war).\\n\"\n",
        "            \"- Distinguish short-term triggers from long-term structural causes when evaluating explanations.\\n\"\n",
        "            \"- When reading passages, consider author, audience, and purpose to match the most plausible interpretation.\"\n",
        "        ),\n",
        "    },\n",
        "    \"philosophy\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert Philosopher specializing in Ethics, Metaphysics, and Epistemology. \"\n",
        "            \"You are precise with terminology and familiar with canonical arguments (Kant, Mill, Aristotle, etc.).\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Identify the relevant school or author first (e.g., Kantian deontology vs. Millian utilitarianism).\\n\"\n",
        "            \"- Pay close attention to technical terms (e.g., validity vs. truth, necessary vs. sufficient, a priori vs. a posteriori).\\n\"\n",
        "            \"- Reject options that contradict the core commitments of the view (e.g., utilitarianism ignoring consequences).\\n\"\n",
        "            \"- Prefer options that match the exact formulation of the principle, not just something that sounds reasonable.\"\n",
        "        ),\n",
        "    },\n",
        "    \"psychology\": {\n",
        "        \"role\": (\n",
        "            \"You are a Clinical and Research Psychologist. \"\n",
        "            \"You specialize in DSM-5 criteria, developmental stages, cognitive psychology, and experimental design.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- For diagnosis, match symptoms strictly to DSM-5 criteria, especially duration, severity, and exclusion conditions.\\n\"\n",
        "            \"- For development/theory items, map behaviors to the correct named theory and precise stage (e.g., Piaget, Kohlberg, Erikson).\\n\"\n",
        "            \"- In research design questions, clearly identify IV, DV, and likely confounds; distinguish correlation from causation.\\n\"\n",
        "            \"- For ethics scenarios, prioritize APA principles such as informed consent, confidentiality, and minimizing harm.\"\n",
        "        ),\n",
        "    },\n",
        "}\n",
        "\n",
        "DEFAULT_CATEGORY_META = {\n",
        "    \"role\": (\n",
        "        \"You are an expert exam solver for MMLU-Pro. You are careful, analytical, and precise.\"\n",
        "    ),\n",
        "    \"guidelines\": (\n",
        "        \"- Read the QUESTION carefully and respect all stated constraints.\\n\"\n",
        "        \"- Use the provided Context as primary evidence and avoid unsupported assumptions.\\n\"\n",
        "        \"- Eliminate options that conflict with the facts, definitions, or chronology in the Context.\\n\"\n",
        "        \"- Choose the single best-supported option, even if other options seem partially plausible.\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "IsbhE45AKGPc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_ANS_TMPL = \"\"\"\n",
        "You are an expert multiple-choice exam solver for MMLU-Pro, using an Astute-RAG style reasoning process.\n",
        "\n",
        "[Role]\n",
        "{category_role}\n",
        "\n",
        "[Category-Specific Guidelines]\n",
        "{category_guidelines}\n",
        "\n",
        "You are given:\n",
        "[Initial Context]  (short, noisy, or partial)\n",
        "{context_init}\n",
        "\n",
        "[Consolidated Context]  (higher-quality, filtered evidence)\n",
        "{context_con}\n",
        "\n",
        "[QUESTION]\n",
        "{question_with_options}\n",
        "\n",
        "Your job is to carefully combine your INTERNAL knowledge with the given EXTERNAL context,\n",
        "and then follow the **three-stage Astute-RAG reasoning** below.\n",
        "\n",
        "--------------------------------\n",
        "Stage 1 – Evidence Aggregation (Astute Step 1)\n",
        "--------------------------------\n",
        "1. From the QUESTION ONLY (ignore context for now), extract 3–5 key clues:\n",
        "   - important concepts, time periods, entities, relationships, or definitions.\n",
        "2. Using the CONTEXT (Initial + Consolidated), list 3–7 **relevant evidence statements**:\n",
        "   - each statement should be short (1 sentence),\n",
        "   - include only facts that help discriminate between the options.\n",
        "3. If the context contradicts itself, give higher trust to the **Consolidated Context**,\n",
        "   but never violate explicit constraints stated in the QUESTION.\n",
        "\n",
        "--------------------------------\n",
        "Stage 2 – Option-wise Diagnosis with Score & Confidence (Astute Step 2)\n",
        "--------------------------------\n",
        "For each option (A, B, C, D, ...), do the following:\n",
        "\n",
        "1. In 1–2 sentences, compare the option with the key clues + evidence:\n",
        "   - Explain how it is supported or contradicted.\n",
        "   - Check whether it satisfies all critical constraints in the QUESTION.\n",
        "\n",
        "2. Assign three evaluations to this option:\n",
        "   - A **Label**: one of\n",
        "     * \"CLEARLY SUPPORTED\"\n",
        "     * \"PARTIALLY SUPPORTED / DUBIOUS\"\n",
        "     * \"CLEARLY CONTRADICTED\"\n",
        "   - A numerical **Score** between 0 and 1:\n",
        "     * 0.0 ≈ completely wrong, 1.0 ≈ very strongly supported.\n",
        "   - A short **Confidence** phrase: one of [\"high\", \"medium\", \"low\"].\n",
        "\n",
        "Use the following format for each option:\n",
        "\n",
        "Option A:\n",
        "- Reasoning: ...\n",
        "- Label: CLEARLY SUPPORTED\n",
        "- Score: 0.82\n",
        "- Confidence: high\n",
        "\n",
        "(Repeat this exact structure for options B, C, D, ...)\n",
        "\n",
        "--------------------------------\n",
        "Stage 3 – Global Consistency Check & Final Decision (Astute Step 3)\n",
        "--------------------------------\n",
        "1. Look at ALL options, their Labels, and Scores together.\n",
        "2. Eliminate every option that is:\n",
        "   - labeled \"CLEARLY CONTRADICTED\", or\n",
        "   - has Score < 0.30 (unless every option is very low-scoring).\n",
        "3. Among the remaining options, choose **one single BEST** answer by asking:\n",
        "   - Which option is most strongly and directly supported by the evidence and key clues?\n",
        "   - Does any option rely on extra assumptions not justified by the context?\n",
        "4. If two options have similar Scores, briefly explain why the higher one\n",
        "   is still better given the QUESTION wording and constraints.\n",
        "\n",
        "Finally, on the last line of your response, output the answer in the format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "(where X is a single capital letter such as A, B, C, D, ...).\n",
        "Do NOT output anything after this line.\n",
        "\"\"\".strip()\n",
        "p_ans_prompt = ChatPromptTemplate.from_template(P_ANS_TMPL)"
      ],
      "metadata": {
        "id": "33MzDXy6EOGV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 살짝 변경\n",
        "def run_p_ans(\n",
        "    context_init: str,\n",
        "    context_con: str,\n",
        "    full_question: str,\n",
        "    category: str,\n",
        "    llm=None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    p_gen/p_con으로 만들어진 context를 기반으로,\n",
        "    astute-RAG 방식(INTERNAL vs EXTERNAL, Step 1~4)을 그대로 따르되,\n",
        "    category별 역할/전략 텍스트를 추가하여 특화된 solver로 동작하게 함.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    meta = CATEGORY_META.get(category, DEFAULT_CATEGORY_META)\n",
        "\n",
        "    msgs = p_ans_prompt.format_messages(\n",
        "        category_role=meta[\"role\"],\n",
        "        category_guidelines=meta[\"guidelines\"],\n",
        "        context_init=context_init,\n",
        "        context_con=context_con,\n",
        "        question_with_options=full_question,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    raw = resp.content.strip()\n",
        "    letter = extract_final_answer_letter(raw)\n",
        "    return {\"final_answer\": letter, \"raw_reasoning\": raw}"
      ],
      "metadata": {
        "id": "qLx-PIdkK167"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_astute_style(\n",
        "    full_prompt: str,\n",
        "    use_wiki: bool = True,\n",
        "    n_vote: int = 5\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1. 통합 분석 (One-Shot Prompt 적용된 run_p_analyze 사용)\n",
        "    # ---------------------------------------------------------\n",
        "    question_text, options = parse_question_and_options(full_prompt)\n",
        "\n",
        "    try:\n",
        "        # [변경] 여기서 Category, Textbook Query, Wiki Keywords를 한 번에 다 가져옴\n",
        "        analysis = run_p_analyze(question_text, options, llm=llm_solver)\n",
        "    except NameError:\n",
        "        print(\"[Error] run_p_analyze not defined. Using fallback.\")\n",
        "        analysis = {}\n",
        "\n",
        "    # 결과 추출 (안전하게 get 사용)\n",
        "    # 1) 카테고리 (구버전 함수 classify_... 삭제됨)\n",
        "    category = analysis.get(\"category\", \"business\")\n",
        "\n",
        "    # 2) 제약조건\n",
        "    constraints = analysis.get(\"constraints\", [])\n",
        "\n",
        "    # 3) 검색어 분리\n",
        "    # 교과서용 (문장형)\n",
        "    textbook_queries = analysis.get(\"search_queries\", [question_text])\n",
        "    # 위키용 (명사형)\n",
        "    wiki_keywords = analysis.get(\"wiki_keywords\", [])\n",
        "\n",
        "    # [Fallback] 만약 위키 키워드가 비었으면 교과서 쿼리라도 씀\n",
        "    if not wiki_keywords:\n",
        "        wiki_keywords = textbook_queries\n",
        "\n",
        "    print(f\"   -> [Analysis] Category: {category}\")\n",
        "    print(f\"   -> [Textbook Query] {textbook_queries[:1]}...\")\n",
        "    print(f\"   -> [Wiki Keywords] {wiki_keywords}\")\n",
        "\n",
        "    # 벡터 DB 확인\n",
        "    if category not in vectorstore:\n",
        "        print(f\"   -> [Warn] Category '{category}' not found. Fallback to 'business'.\")\n",
        "        category = \"business\"\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2. 검색 (Dual-Track: Hybrid Vector + Wiki)\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # Track A: Textbook (Vector + BM25 Hybrid)\n",
        "    # 문장형 쿼리에 제약조건을 더해서 문맥 강화\n",
        "    combined_textbook_query = \" \".join(textbook_queries) + \" \" + \" \".join(constraints)\n",
        "    tb_passages = get_textbook_passages(category, combined_textbook_query)\n",
        "\n",
        "    # Track B: Wikipedia (Entity Search)\n",
        "    # 명사형 키워드로 정확한 표제어 매칭\n",
        "    wiki_passages = []\n",
        "    if use_wiki:\n",
        "        wiki_passages = get_wiki_passages(wiki_keywords)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. Context 생성 (p_mem -> p_gen -> p_con)\n",
        "    # ---------------------------------------------------------\n",
        "    doc_blocks = []\n",
        "    next_doc_idx = 1\n",
        "\n",
        "    # Internal Memory\n",
        "    mem_doc_text = run_p_mem(category, question_text)\n",
        "    if mem_doc_text.strip():\n",
        "        doc_blocks.append(f\"[Doc {next_doc_idx} | SOURCE=INTERNAL(MEMORY)]\\n{mem_doc_text}\")\n",
        "        next_doc_idx += 1\n",
        "\n",
        "    # Textbook Docs (LLM 요약 없이 Pass-through)\n",
        "    if tb_passages:\n",
        "        tb_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category, \"TEXTBOOK\", question_text, tb_passages, next_doc_idx, None\n",
        "        )\n",
        "        if tb_block.strip(): doc_blocks.append(tb_block)\n",
        "\n",
        "    # Wiki Docs (LLM 요약 없이 Pass-through)\n",
        "    if wiki_passages:\n",
        "        wiki_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category, \"WIKIPEDIA\", question_text, wiki_passages, next_doc_idx, None\n",
        "        )\n",
        "        if wiki_block.strip(): doc_blocks.append(wiki_block)\n",
        "\n",
        "    context_init = \"\\n\\n\".join(doc_blocks)\n",
        "\n",
        "    # Consolidation\n",
        "    context_con = run_p_con(question_text=question_text, context_init=context_init)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. Voting (Self-Consistency)\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # Voting용 질문 구성 (제약조건 명시)\n",
        "    constraints_str = \"\\n\".join([f\"- {c}\" for c in constraints])\n",
        "    augmented_question = f\"{full_prompt}\\n\\n[CRITICAL CONSTRAINTS]\\n{constraints_str}\"\n",
        "\n",
        "    # 다양성을 위한 Temperature 설정\n",
        "    llm_voter = ChatUpstage(api_key=UPSTAGE_API_KEY, model=\"solar-pro2\", temperature=0.7)\n",
        "\n",
        "    votes = []\n",
        "    reasonings = []\n",
        "\n",
        "    print(f\"   -> [Voting] Running {n_vote} iterations...\")\n",
        "    for i in range(n_vote):\n",
        "        try:\n",
        "            ans = run_p_ans(\n",
        "                context_init=context_init,\n",
        "                context_con=context_con,\n",
        "                full_question=augmented_question,\n",
        "                category=category,\n",
        "                llm=llm_voter\n",
        "            )\n",
        "            letter = ans[\"final_answer\"]\n",
        "\n",
        "            # 유효한 답만 투표\n",
        "            if letter and letter in \"ABCDEFGHIJ\":\n",
        "                votes.append(letter)\n",
        "\n",
        "            reasonings.append(f\"[Run {i+1} Answer: {letter}]\\n{ans['raw_reasoning']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [Vote Error]: {e}\")\n",
        "            continue\n",
        "\n",
        "    # 최종 결과 집계\n",
        "    if not votes:\n",
        "        final_ans = \"A\" # Fallback\n",
        "        vote_summary = \"None\"\n",
        "    else:\n",
        "        # 최빈값 선택\n",
        "        count = Counter(votes)\n",
        "        final_ans = count.most_common(1)[0][0]\n",
        "        vote_summary = str(dict(count))\n",
        "        print(f\"   -> [Result] Winner: {final_ans} | Votes: {vote_summary}\")\n",
        "\n",
        "    full_log = \"\\n\" + \"=\"*40 + \"\\n\".join(reasonings)\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": category,\n",
        "        \"analysis\": analysis,\n",
        "        \"keywords\": wiki_keywords, # 변경됨: extracted_keywords -> wiki_keywords\n",
        "        \"context_init\": context_init,\n",
        "        \"context_con\": context_con,\n",
        "        \"raw_reasoning\": full_log,\n",
        "        \"vote_summary\": vote_summary\n",
        "    }"
      ],
      "metadata": {
        "id": "KMrStAyL7gBQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "100개"
      ],
      "metadata": {
        "id": "2vHKM8nt4Qvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/testset_100.csv\")\n",
        "QUESTION_COL = \"prompts\"\n",
        "\n",
        "results = []\n",
        "for i, row in df.iterrows():\n",
        "    q = row[QUESTION_COL]\n",
        "    print(f\"[{i}] Solving: {q[:60]}...\")\n",
        "    out = solve_mmlu_astute_style(q)\n",
        "    results.append(out[\"final_answer\"])\n",
        "    df.loc[i, \"pred_category\"] = out[\"category\"]\n",
        "    df.loc[i, \"kw1\"] = out[\"keywords\"][0] if len(out[\"keywords\"]) > 0 else \"\"\n",
        "    df.loc[i, \"kw2\"] = out[\"keywords\"][1] if len(out[\"keywords\"]) > 1 else \"\"\n",
        "    df.loc[i, \"kw3\"] = out[\"keywords\"][2] if len(out[\"keywords\"]) > 2 else \"\"\n",
        "    df.loc[i, \"rag_cot_answer\"] = out[\"final_answer\"]\n",
        "    df.loc[i, \"cot_full\"] = out[\"raw_reasoning\"]\n",
        "\n",
        "df.to_csv(\"astute-rag-1126-final.csv\", index=False)\n",
        "print(\"저장 완료:1126.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwQVpjeR5SG-",
        "outputId": "3fe82ea2-a7e2-43c8-ba68-9625dc0f4363",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Solving: QUESTION4868) In 1797, John Frere made a discovery that he d...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne Palaeolithic site', 'Acheulean handaxe', 'Paleoanthropology history', 'Deep stratigraphy archaeology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[1] Solving: QUESTION586) BobGafneyand Susan Medina invested $40,000 and ...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership accounting income distribution with interest and management fee']...\n",
            "   -> [Wiki Keywords] ['Partnership accounting', 'Income distribution agreement', 'Capital contribution accounting', 'Partnership profit sharing', 'Managerial compensation in partnerships']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[2] Solving: QUESTION138) If at the beginning of each month a deposit of ...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Future value of monthly compounded annuity formula']...\n",
            "   -> [Wiki Keywords] ['Future value', 'Compound interest', 'Annuity', 'Time value of money', 'Compound interest formula']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 3, 'E': 2}\n",
            "[3] Solving: QUESTION520) George and Richard Martin, partners in a law fi...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Calculating percentage increase in business expenses']...\n",
            "   -> [Wiki Keywords] ['Percentage increase', 'Business mathematics', 'Rent calculation', 'Financial percentage change']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[4] Solving: QUESTION1326) A large privately owned and operated shopping ...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['First Amendment rights in privately owned public spaces']...\n",
            "   -> [Wiki Keywords] ['First Amendment to the United States Constitution', 'State action (United States law)', 'Public forum doctrine', 'Lloyd Corporation v. Tanner', 'Privately owned public space']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[5] Solving: QUESTION1769) A farmer owned a 40-acre tract of farmland loc...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Real property lease option to purchase enforceability defenses']...\n",
            "   -> [Wiki Keywords] ['Specific performance (law)', 'Parol evidence rule', 'Condition precedent', 'Material breach', 'Statute of frauds']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[6] Solving: QUESTION1200) Is the recognition of foreign judgments subjec...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Private International Law', 'Monism (international relations)', 'Dualism (international law)', 'Recognition of foreign judgments', 'Vienna Convention on the Law of Treaties']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[7] Solving: QUESTION1163) A mechanic agreed in writing to make repairs t...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Contract modification enforceability under duress or undue influence']...\n",
            "   -> [Wiki Keywords] ['Contract law', 'Duress (contract law)', 'Undue influence', 'Contract modification', 'Economic duress']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[8] Solving: QUESTION10832) Mani referred to God by which of the followin...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Manichaean terminology for God']...\n",
            "   -> [Wiki Keywords] ['Manichaeism', 'Mani (prophet)', 'Manichaean cosmology', 'Gnostic theology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[9] Solving: QUESTION10952) Construct a complete truth table for the foll...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Logical validity of conditional syllogism in propositional logic']...\n",
            "   -> [Wiki Keywords] ['Propositional logic', 'Truth table', 'Logical validity', 'Conditional statement', 'Biconditional']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[10] Solving: QUESTION2449) Dr. Ryan is a psychotherapist in a small town....\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for therapists treating former sexual partners']...\n",
            "   -> [Wiki Keywords] ['Psychotherapy ethics', 'American Psychological Association', 'Dual relationships (psychotherapy)', 'Professional boundaries', 'Therapist-patient confidentiality']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[11] Solving: QUESTION1979) A landscaper agreed to maintain the yard of a ...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Contract law damages for partial performance breach']...\n",
            "   -> [Wiki Keywords] ['Contract law', 'Breach of contract', 'Quantum meruit', 'Restitution (law)', 'Mitigation of damages']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[12] Solving: QUESTION10850) One objection to Singer’s theory that he cons...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections about proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', 'Famine, Affluence, and Morality', \"Singer's Pond analogy\", 'Acting on moral obligations', 'Ethical partiality']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[13] Solving: QUESTION1422) A company offered to sell several loads of lan...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Contract law offer acceptance with modifications']...\n",
            "   -> [Wiki Keywords] ['Contract law', 'Uniform Commercial Code', 'Offer and acceptance', 'Battle of the forms', 'UCC Article 2']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[14] Solving: QUESTION2277) Child abuse and neglect are most associated wi...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Attachment theory child abuse disorganized attachment']...\n",
            "   -> [Wiki Keywords] ['Attachment theory', 'Disorganized attachment', 'Child abuse effects', 'Mary Ainsworth', 'Strange Situation procedure']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[15] Solving: QUESTION2368) What are the two principal explanations for th...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Theoretical models of short-term memory capacity limitations']...\n",
            "   -> [Wiki Keywords] ['Short-term memory', 'Working memory', 'Memory limitation theories', 'Interference theory', 'Time-decay theory']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[16] Solving: QUESTION4834) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Martin Luther Address to the Christian Nobility omitted topics']...\n",
            "   -> [Wiki Keywords] ['Address to the Christian Nobility of the German Nation', \"Martin Luther's Reformation writings\", \"Themes in Luther's Address to the Christian Nobility\", \"Historical context of Luther's 1520 treatise\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[17] Solving: QUESTION11011) I don't understand why everyone thinks they b...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Informal fallacy attacking opponent's intelligence instead of argument\"]...\n",
            "   -> [Wiki Keywords] ['Ad hominem', 'Logical fallacy', 'Informal fallacy', 'Straw man fallacy', 'Begging the question']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[18] Solving: QUESTION2054) What are the assumptions concerning an individ...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Theoretical foundations of projective personality assessment']...\n",
            "   -> [Wiki Keywords] ['Projective test', 'Psychodynamic psychology', 'Unconscious mind', 'Personality assessment', 'Rorschach test']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[19] Solving: QUESTION373) Mr. Joseph Miles and Mr. Gary Rose are partners...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership profit distribution with guaranteed salary']...\n",
            "   -> [Wiki Keywords] ['Partnership (accounting)', 'Profit sharing', 'Partnership agreement', 'Business partnership law']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 4, 'E': 1}\n",
            "[20] Solving: QUESTION5041) What does Australia have in common with the re...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Global Holocene epoch cultural development patterns']...\n",
            "   -> [Wiki Keywords] ['Holocene', 'Megafauna extinction', 'Holocene extinction event', 'Cultural diversity in the Holocene', 'Australian Aboriginal cultures']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[21] Solving: QUESTION4751) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Historical context of 'Winter King' and Bohemia's lawful king Ferdinand\"]...\n",
            "   -> [Wiki Keywords] ['Winter King (Frederick V)', \"Thirty Years' War\", 'Holy Roman Empire', 'Defenestration of Prague', 'Bohemian Revolt']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[22] Solving: QUESTION11192) Select the best translation into predicate lo...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Predicate logic translation of universal statements']...\n",
            "   -> [Wiki Keywords] ['Predicate logic', 'First-order logic', 'Universal quantification', 'Set theory', 'Logical implication']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[23] Solving: QUESTION109) Mr. Castle will buy one of two 10-HP motors off...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Break-even analysis for motors with differing efficiency and purchase costs']...\n",
            "   -> [Wiki Keywords] ['Capital cost', 'Energy efficiency', 'Break-even analysis', 'Total cost of ownership', 'Motor efficiency']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[24] Solving: QUESTION4994) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Geopolitical influences on military technology development Europe vs. China']...\n",
            "   -> [Wiki Keywords] ['Gunpowder warfare', 'Military history of medieval Europe', 'Mongol invasions of China', 'Technological diffusion', 'Geopolitical strategy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 4, 'I': 1}\n",
            "[25] Solving: QUESTION2631) Group A consists of people whose measured inte...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['vocational interest alignment and occupational success in engineering']...\n",
            "   -> [Wiki Keywords] [\"Holland's vocational preference theory\", 'Person-environment fit', 'Vocational psychology', 'Occupational satisfaction', 'Career persistence factors']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[26] Solving: QUESTION4942) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Federalist #15 analysis weaknesses of Articles of Confederation']...\n",
            "   -> [Wiki Keywords] ['Federalist No. 15', 'Articles of Confederation weaknesses', 'Post-American Revolutionary War treaties', 'British forts in the Great Lakes', 'Spanish control of Mississippi River']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[27] Solving: QUESTION1114) A defendant hated a victim and decided to kill...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['legal distinction between first and second degree murder premeditation']...\n",
            "   -> [Wiki Keywords] ['First-degree murder', 'Second-degree murder', 'Premeditation (law)', 'Voluntary manslaughter', 'Legal intoxication defenses']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[28] Solving: QUESTION287) An automobile that cost $3,000 four years ago i...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Straight-line depreciation calculation method']...\n",
            "   -> [Wiki Keywords] ['Depreciation', 'Straight-line depreciation', 'Asset valuation', 'Accounting principles']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[29] Solving: QUESTION4765) Which of the following is the Pleistocene ice ...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Pleistocene glaciation Rocky Mountains North America ice sheet']...\n",
            "   -> [Wiki Keywords] ['Cordilleran Ice Sheet', 'Pleistocene glaciation', 'Laurentide Ice Sheet', 'Rocky Mountains geology', 'North American glaciation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[30] Solving: QUESTION4886) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Historical context of Logan's Address and early U.S. Indian policies\"]...\n",
            "   -> [Wiki Keywords] [\"Logan's Address\", 'Native American history', 'Early United States Indian policy', '18th-century Native American sovereignty', 'Colonial-era Native American relations']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[31] Solving: QUESTION644) An invoice of $10,000 is marked (6/10), (n/30)....\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Calculating annual percentage rate for trade credit terms']...\n",
            "   -> [Wiki Keywords] ['Trade credit', 'Annual percentage rate', 'Discount terms', 'Cash discount', 'Net payment terms']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[32] Solving: QUESTION10783) Ashford's article is meant to address a parti...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Ashford ethical paralysis global poverty responsibility']...\n",
            "   -> [Wiki Keywords] ['Peter Singer (philosopher)', 'Global poverty ethics', 'Structural injustice', 'Ethical prioritization', 'Moral responsibility']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 4, 'E': 1}\n",
            "[33] Solving: QUESTION1601) A federal statute provides states with funds f...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Federal statutory conditions on state-administered programs and sovereign immunity exceptions']...\n",
            "   -> [Wiki Keywords] ['Sovereign immunity (U.S. Constitution)', 'Eleventh Amendment to the United States Constitution', 'Federal funding conditions', 'South Dakota v. Dole', 'Ex parte Young']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'H': 1, 'G': 4}\n",
            "[34] Solving: QUESTION11104) All things that are spoiled are inedible. Tim...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Logical fallacy of applying properties to individuals from categories']...\n",
            "   -> [Wiki Keywords] ['Fallacy of Division', 'Logical Fallacies', 'Equivocation', 'Questionable Cause']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[35] Solving: QUESTION10914) Carens's main conclusion is that \n",
            "(A) liberal...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Carens liberal egalitarianism immigration policy argument']...\n",
            "   -> [Wiki Keywords] ['Joseph Carens', 'Liberal egalitarianism', 'Open borders', 'Anti-cosmopolitanism', 'Immigration policy philosophy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[36] Solving: QUESTION507) assume you are Indonesian. In 2010, the rupiah ...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Real exchange rate calculation method with inflation adjustment']...\n",
            "   -> [Wiki Keywords] ['Real exchange rate', 'Purchasing power parity', 'Consumer price index', 'Inflation (economics)', 'Exchange rate']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[37] Solving: QUESTION1271) Two men held-up a liquor store in a city. Duri...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Constitutional limits on pre-indictment delay in felony murder prosecutions']...\n",
            "   -> [Wiki Keywords] ['Statute of limitations', 'Felony murder rule', 'Due process', 'Pre-indictment delay', 'Confrontation Clause']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 4, 'A': 1}\n",
            "[38] Solving: QUESTION1647) Liang, a talented student from another country...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Constitutional analysis of state citizenship requirements for public school teachers']...\n",
            "   -> [Wiki Keywords] ['Equal Protection Clause', 'United States constitutional law', 'Alienage discrimination', 'Public employment law', 'Foley v. Connelie']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[39] Solving: QUESTION11239) Zhuangzi describes a state as ziran, which me...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Zhuangzi's concept of ziran in Daoist philosophy\"]...\n",
            "   -> [Wiki Keywords] ['Zhuangzi', 'Ziran (Daoism)', 'Daoist philosophy', 'Spontaneity in Daoism', 'Naturalness (philosophy)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[40] Solving: QUESTION2386) Which of the following strategies would probab...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Evidence-based interventions for childhood aggression reduction']...\n",
            "   -> [Wiki Keywords] ['Aggression in children', 'Social skills training', 'Behavioral catharsis', 'Observational learning', 'Competitive sports psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[41] Solving: QUESTION2615) Which of the following statements expresses a ...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Effects of aging on sexual function in males and females']...\n",
            "   -> [Wiki Keywords] ['Aging and sexuality', 'Sexual response cycle', 'Physiology of aging', 'Human sexual behavior', 'Erectile dysfunction']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 4, 'B': 1}\n",
            "[42] Solving: QUESTION5019) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Historical condemnations of unchecked executive power in 20th century US']...\n",
            "   -> [Wiki Keywords] ['Korematsu v. United States', 'Japanese American internment', 'Frank Murphy dissent', 'Civil liberties violations', 'Executive power abuse cases']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[43] Solving: QUESTION271) Consider an arbitrage-free securities market mo...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Risk-neutral measure derivation for correlated Brownian motion assets']...\n",
            "   -> [Wiki Keywords] ['Risk-neutral measure', 'Arbitrage-free', 'Geometric Brownian motion', 'Stochastic differential equation', 'Martingale pricing']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'B': 1, 'E': 2, 'I': 1, 'A': 1}\n",
            "[44] Solving: QUESTION10881) \"The minor premise must affirm the antecedent...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Logical rule for evaluating hypothetical syllogisms']...\n",
            "   -> [Wiki Keywords] ['Hypothetical syllogism', 'Conditional argument', 'Logical validity', 'Deductive reasoning', 'Syllogism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[45] Solving: QUESTION1485) Hume's attack on natural law is founded on his...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Hume's empiricism critique of natural law objectivity\"]...\n",
            "   -> [Wiki Keywords] ['David Hume', 'Natural law', 'Moral skepticism', 'Is-ought problem', 'Empiricism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[46] Solving: QUESTION11210) Baier argues that genuine moral rules: \n",
            "(A) m...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Baier's criteria for genuine moral rules\"]...\n",
            "   -> [Wiki Keywords] ['Kurt Baier', 'Moral rules', 'Universal ethics', 'Ethical universalism', 'Moral philosophy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[47] Solving: QUESTION2519) Babbling ordinarily begins at about 4 to 5 mon...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Developmental stages of infant vocalization and phonetic inventory']...\n",
            "   -> [Wiki Keywords] ['Infant development', 'Language acquisition', 'Speech development', 'Canonical babbling', 'Phonetic development']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[48] Solving: QUESTION2055) Have studies on learning supported the Increme...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Empirical evidence comparing incremental vs one-trial learning theories']...\n",
            "   -> [Wiki Keywords] ['Learning theory (education)', 'One-trial learning', 'Incremental learning', 'Cognitive psychology', 'Behavioral psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[49] Solving: QUESTION962) A plaintiff sued a defendant for injuries that ...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Admissibility of habit evidence in negligence cases under FRE 406']...\n",
            "   -> [Wiki Keywords] ['Federal Rules of Evidence 406', 'Character evidence', 'Habit evidence admissibility', 'Negligence (tort)', 'Relevance (law)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 4, 'H': 1}\n",
            "[50] Solving: QUESTION10806) According to Kant, nothing can be called “goo...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Kantian concept of unqualified good']...\n",
            "   -> [Wiki Keywords] ['Immanuel Kant', 'Groundwork of the Metaphysics of Morals', 'Good Will (Kant)', 'Deontological ethics', 'Categorical Imperative']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[51] Solving: QUESTION4708) Conflict models emphasize the importance of __...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Conflict models vs integration models in state society development']...\n",
            "   -> [Wiki Keywords] ['Conflict theory (social sciences)', 'Integration theory (anthropology)', 'State formation', 'Sociopolitical evolution', 'Anthropological theories of state']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'G': 2, 'F': 3}\n",
            "[52] Solving: QUESTION2337) For deception in an experiment to be permissib...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['ethical criteria for permissible deception in psychological research']...\n",
            "   -> [Wiki Keywords] ['Research ethics', 'Deception in experiments', 'Informed consent', 'APA Ethics Code', 'Institutional Review Board']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[53] Solving: QUESTION10878) Which branch of Judaism founded by Zacharias ...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Zacharias Frankel's Positive-Historical Judaism movement\"]...\n",
            "   -> [Wiki Keywords] ['Zacharias Frankel', 'Positive-Historical Judaism', 'Conservative Judaism', 'Jewish denominations history']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[54] Solving: QUESTION1642) A homeowner conveyed his property to his cousi...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law doctrine life estate remainder merger conveyance']...\n",
            "   -> [Wiki Keywords] ['Doctrine of Worthier Title', 'Life Estate', \"Rule in Shelley's Case\", 'Doctrine of Merger', 'Common Law Property']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 4, 'E': 1}\n",
            "[55] Solving: QUESTION4938) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Economic impact of U.S. entry into World War II']...\n",
            "   -> [Wiki Keywords] ['World War II economic history', 'Pearl Harbor economic impact', 'United States home front during World War II', 'Franklin D. Roosevelt and the economy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[56] Solving: QUESTION2663) Some contemporary intelligence researchers lik...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[57] Solving: QUESTION1569) In 1993, a rancher had good record title to a ...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Race-notice jurisdiction recording act property law analysis']...\n",
            "   -> [Wiki Keywords] ['Race-notice recording system', 'Fee simple absolute', 'Adverse possession', 'Constructive notice', 'Grantor-Grantee Index']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[58] Solving: QUESTION2483) Trace language development during preschool ag...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Language development milestones in preschool children']...\n",
            "   -> [Wiki Keywords] ['Language development', 'Preschool development', 'Child language acquisition', \"Piaget's theory of cognitive development\", 'Speech and language milestones']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[59] Solving: QUESTION862) The following entries appeared in the ledgers o...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Inventory turnover ratio calculation with beginning inventory purchases and ending inventory']...\n",
            "   -> [Wiki Keywords] ['Inventory turnover', 'Cost of goods sold', 'Financial ratio', 'Inventory management', 'Accounting principles']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[60] Solving: QUESTION283) Steve King buys dress slacks on sale at $33.15 ...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Calculating total cost with sales tax for multiple items']...\n",
            "   -> [Wiki Keywords] ['Sales tax', 'Unit price', 'Business mathematics', 'Cost calculation', 'Consumer arithmetic']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[61] Solving: QUESTION4839) At its peak, the population of the city of Teo...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Peak population estimate of Teotihuacán in Mesoamerican history']...\n",
            "   -> [Wiki Keywords] ['Teotihuacán', 'Mesoamerican demography', 'Ancient city population estimates', 'Teotihuacán population history']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[62] Solving: QUESTION769) Calculate the Gross Domestic Product using the ...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['GDP calculation using total expenditure approach formula']...\n",
            "   -> [Wiki Keywords] ['Gross domestic product', 'Expenditure approach to GDP', 'National income accounting', 'GDP formula components']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[63] Solving: QUESTION11245) When was the major shift by Greek philosopher...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Historical transition from anthropomorphic to abstract divine concepts in Greek philosophy']...\n",
            "   -> [Wiki Keywords] ['Pre-Socratic philosophy', 'Anthropomorphism in Greek religion', 'Xenophanes (philosopher)', 'Greek natural philosophy', 'Axial Age']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 3, 'A': 2}\n",
            "[64] Solving: QUESTION1360) A wife and husband are married and own a dairy...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Tenancy by entirety property transfer validity without spouse consent']...\n",
            "   -> [Wiki Keywords] ['Tenancy by the entirety', 'Quitclaim deed', 'Marital property', 'Joint property law', 'Concurrent estate']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[65] Solving: QUESTION2526) Jupiter pilots his newly created perfectionism...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['test-retest reliability correlation methodology']...\n",
            "   -> [Wiki Keywords] ['Test-retest reliability', 'Psychometrics', 'Reliability (statistics)', 'Correlation and dependence', 'Psychological testing']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[66] Solving: QUESTION11137) Naturalists who concentrated on natural eleme...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Philosophical traditions emphasizing natural elements and processes']...\n",
            "   -> [Wiki Keywords] ['Daoism', 'Yin-Yang School', 'Naturalism in philosophy', 'East Asian philosophy', 'Shintoism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[67] Solving: QUESTION2318) How does the study of stereotyping relate to a...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Intersection of stereotyping and attribution theory in social cognition']...\n",
            "   -> [Wiki Keywords] ['Attribution theory (psychology)', 'Stereotyping', 'Social cognition', 'Fundamental attribution error', 'Heuristic (psychology)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 3, 'E': 2}\n",
            "[68] Solving: QUESTION2052) How is incoming sensory verbal information abs...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Neuropsychological mechanisms of verbal sensory information classification']...\n",
            "   -> [Wiki Keywords] ['Sensory processing', 'Cognitive neuroscience', 'Perception', 'Neural classification', 'Verbal memory']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[69] Solving: QUESTION2643) Research into ___________ has helped us unders...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Neuropsychological mechanisms of paradoxical reward']...\n",
            "   -> [Wiki Keywords] ['Paradoxical reward', 'Reward system', 'Dopamine', 'Neurotransmitters', 'Reinforcement theory']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[70] Solving: QUESTION2694) Which of the following is not an available too...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychometric tools for suicide risk assessment']...\n",
            "   -> [Wiki Keywords] ['Suicide risk assessment', 'Beck Scale for Suicidal Ideation', 'Oxford Happiness Questionnaire', 'Mood Disorder Questionnaire', 'Depression Anxiety Stress Scales']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 4, 'G': 1}\n",
            "[71] Solving: QUESTION4726) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Non-aligned movement Cold War neutrality Sukarno']...\n",
            "   -> [Wiki Keywords] ['Bandung Conference', 'Non-Aligned Movement', 'Cold War neutrality', 'Sukarno foreign policy', 'Indonesia Cold War']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[72] Solving: QUESTION967) A city imposes a municipal excise tax of $200 p...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Constitutionality of municipal taxes on interstate commerce under Commerce Clause']...\n",
            "   -> [Wiki Keywords] ['Commerce Clause', 'Dormant Commerce Clause', 'Excise Tax', 'Complete Auto Transit test', 'Privilege Tax']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'G': 2, 'B': 3}\n",
            "[73] Solving: QUESTION290) On October 17, Thomas Long purchased two $1,000...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Bond purchase cost calculation at discount with brokerage fees']...\n",
            "   -> [Wiki Keywords] ['Bond valuation', 'Accrued interest', 'Brokerage fee', 'Bond discount', 'Net proceeds calculation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[74] Solving: QUESTION623) ____________ describes the extrinsic properties...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Marketing concept describing extrinsic product attributes and psychological satisfaction']...\n",
            "   -> [Wiki Keywords] ['Brand imagery', 'Brand equity', 'Product branding', 'Consumer psychology', 'Brand identity']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[75] Solving: QUESTION1009) A developer is the owner of a parcel of land i...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Notice jurisdiction priority rules for unrecorded conveyances']...\n",
            "   -> [Wiki Keywords] ['Notice jurisdiction', 'Fee simple absolute', 'Recording acts (property law)', 'Bona fide purchaser', 'Priority of title']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[76] Solving: QUESTION4741) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Presidents with Coolidgean views on taxation and property rights']...\n",
            "   -> [Wiki Keywords] ['Calvin Coolidge', 'Ronald Reagan', 'Supply-side economics', 'Fiscal conservatism', 'Property rights in U.S. political history']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[77] Solving: QUESTION425) What is the date of maturity of a 60-day note d...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Calculating maturity date of a time note in business law']...\n",
            "   -> [Wiki Keywords] ['Promissory note', 'Maturity date (finance)', 'Commercial paper', 'Negotiable instrument']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[78] Solving: QUESTION10932) E.F. Schumacher, famous economist, in an arti...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Rhetorical fallacy of asking whether one believes in inappropriate technology']...\n",
            "   -> [Wiki Keywords] ['Equivocation', 'False dilemma', 'Rhetorical question fallacy', 'Logical fallacies', 'E.F. Schumacher']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 4, 'D': 1}\n",
            "[79] Solving: QUESTION1205) A landlord is the owner in fee simple of a tra...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['landlord tenant insurance covenant assignment liability']...\n",
            "   -> [Wiki Keywords] ['Landlord-tenant law', 'Covenant (law)', 'Privity of contract', \"Rule in Spencer's Case\", 'Assignment of lease']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[80] Solving: QUESTION4715) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Logan's 1774 speech analysis perspective on vengeance and peace\"]...\n",
            "   -> [Wiki Keywords] [\"Logan's Lament\", \"Lord Dunmore's War\", 'Mingo people', 'Colonel Michael Cresap', '1774 American Indian speeches']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[81] Solving: QUESTION11042) Richardson-Self argues that sexist speech \n",
            "(A...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal classification of sexist speech as hate speech Richardson-Self']...\n",
            "   -> [Wiki Keywords] ['Hate speech', 'Sexist speech', 'Richardson-Self', 'Freedom of speech', 'Gender discrimination']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[82] Solving: QUESTION4923) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ming Dynasty foreign trade restrictions coastal cities']...\n",
            "   -> [Wiki Keywords] ['Ming Dynasty trade policy', 'Haijin (Ming maritime prohibition)', 'Canton System (Qing trade restrictions)', \"Ibn Battuta's observations on Chinese trade\", 'Yuan to Ming economic transition']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[83] Solving: QUESTION240) Daniel receives at 6.5% commission on all sales...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Calculating total sales from commission percentage and amount']...\n",
            "   -> [Wiki Keywords] ['Commission (business)', 'Business mathematics', 'Sales revenue calculation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'E': 2, 'F': 3}\n",
            "[84] Solving: QUESTION11017) According to Hobbes, the definition of injust...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Hobbesian definition of injustice in Leviathan']...\n",
            "   -> [Wiki Keywords] ['Thomas Hobbes', 'Leviathan (book)', 'Social contract', 'State of nature', 'Sovereign (Hobbes)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[85] Solving: QUESTION1286) Which of the following criticisms of Llewellyn...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] [\"Critiques of Karl Llewellyn's grand and formal legal reasoning styles\"]...\n",
            "   -> [Wiki Keywords] ['Karl Llewellyn', 'Grand style legal reasoning', 'Formal style legal reasoning', 'Legal realism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[86] Solving: QUESTION4871) A subsistence strategy and settlement pattern ...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Archaeological subsistence strategies with planned resource acquisition']...\n",
            "   -> [Wiki Keywords] ['Foraging', 'Hunter-gatherer', 'Subsistence strategy', 'Logistical collecting', 'Seasonal migration']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[87] Solving: QUESTION4878) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Franklin D. Roosevelt response to Huey P. Long Share Our Wealth Society']...\n",
            "   -> [Wiki Keywords] ['Huey P. Long', 'Share Our Wealth Society', 'Second New Deal', 'Franklin D. Roosevelt', 'New Deal']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[88] Solving: QUESTION4724) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Elie Wiesel's perspective on Holocaust remembrance and reconciliation\"]...\n",
            "   -> [Wiki Keywords] ['Elie Wiesel', 'Holocaust remembrance', 'Collective memory', 'Historical reconciliation', 'Post-war German-Jewish relations']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 3, 'B': 2}\n",
            "[89] Solving: QUESTION4898) This question refers to the following informat...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Citizenship requirements in ancient Athenian democracy']...\n",
            "   -> [Wiki Keywords] ['Ancient Athenian democracy', 'Thucydides', 'History of the Peloponnesian War', 'Athenian citizenship', \"Pericles' citizenship law\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[90] Solving: QUESTION936) A defendant, an indigent, was arrested and char...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['constitutional burden of proof for mental incompetency in criminal trials']...\n",
            "   -> [Wiki Keywords] ['Burden of proof (law)', 'Insanity defense', 'Ineffective assistance of counsel', 'Competence to stand trial', 'Sixth Amendment to the United States Constitution']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 4, 'H': 1}\n",
            "[91] Solving: QUESTION2056) When an adult mouse or bird is castrated, its ...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Comparative effects of castration on sexual behavior in primates versus non-primates']...\n",
            "   -> [Wiki Keywords] ['Sexual behavior in primates', 'Hormonal control of behavior', 'Castration effects on mammals', 'Comparative primate psychology', 'Neuroendocrinology of sexual motivation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[92] Solving: QUESTION246) Costs for producing one widget: Materials:2 par...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Cost accounting analysis of material labor and expense components']...\n",
            "   -> [Wiki Keywords] ['Cost accounting', 'Production cost analysis', 'Labor cost calculation', 'Material cost breakdown', 'Total cost computation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[93] Solving: QUESTION11274) The universe, like a watch, must have a maker...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Watchmaker analogy as informal logical fallacy classification']...\n",
            "   -> [Wiki Keywords] ['Watchmaker analogy', 'William Paley', 'Informal fallacy', 'Cosmological argument', 'Analogical fallacy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[94] Solving: QUESTION2234) What is higher-order (second-order)conditionin...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Definition of higher-order conditioning in classical conditioning']...\n",
            "   -> [Wiki Keywords] ['Classical conditioning', 'Higher-order conditioning', 'Conditioned stimulus', 'Secondary reinforcement', 'Behavioral psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[95] Solving: QUESTION307) The enforcement of company privacy is complex a...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Corporate boundaryless nature and privacy enforcement challenges']...\n",
            "   -> [Wiki Keywords] ['Corporate privacy', 'Boundaryless organization', 'Information privacy', 'Organizational behavior']\n",
            "   -> [Voting] Running 5 iterations...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로\n",
        "GT_PATH = \"/content/testset_100.csv\"        # 정답 파일\n",
        "PRED_PATH = \"/content/drive/MyDrive/nlp team project/astute-rag-1126-final.csv\"       # 출력 파일\n",
        "\n",
        "# 2. 컬럼 이름\n",
        "GT_COL = \"answers\"               # testset.csv에서 정답 컬럼\n",
        "PRED_COL = \"rag_cot_answer\"      # baseline.csv에서 예측 컬럼\n",
        "\n",
        "# 3. csv 로드\n",
        "gt_df = pd.read_csv(GT_PATH)\n",
        "pred_df = pd.read_csv(PRED_PATH)\n",
        "\n",
        "# 4. Series 추출\n",
        "gt = gt_df[GT_COL].astype(str)\n",
        "pred = pred_df[PRED_COL].astype(str)\n",
        "\n",
        "# 5. 정규화 함수\n",
        "def normalize_choice(x: str) -> str:\n",
        "    x = x.strip().upper()\n",
        "    for ch in x:\n",
        "        if \"A\" <= ch <= \"Z\":\n",
        "            return ch\n",
        "    return x\n",
        "\n",
        "# 인덱스 리셋이 포인트\n",
        "gt_norm = gt.apply(normalize_choice).reset_index(drop=True)\n",
        "pred_norm = pred.apply(normalize_choice).reset_index(drop=True)\n",
        "\n",
        "print(len(gt_norm), len(pred_norm))  # 둘 다 25 나오는지 체크 한번 해보고\n",
        "\n",
        "# 6. 정확도 계산\n",
        "correct = (gt_norm == pred_norm)\n",
        "accuracy = correct.mean()\n",
        "\n",
        "print(f\"총 문제 수: {len(gt_norm)}\")\n",
        "print(f\"정답 개수: {correct.sum()}\")\n",
        "print(f\"정확도: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "6j_LVA6_5FyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 testset.csv"
      ],
      "metadata": {
        "id": "V81fETNv5sqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import traceback\n",
        "from collections import Counter\n",
        "\n",
        "# 1. 데이터 로드 (원본 데이터 보존을 위해 copy 사용)\n",
        "# 테스트할 범위 슬라이싱 (예: 25번부터 끝까지)\n",
        "input_file = \"testset.csv\"\n",
        "df = pd.read_csv(input_file)[25:].copy()\n",
        "QUESTION_COL = \"prompts\"\n",
        "\n",
        "print(f\"🚀 Processing {len(df)} questions from {input_file}...\")\n",
        "\n",
        "# 2. 실행 루프\n",
        "results = []\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    q = row[QUESTION_COL]\n",
        "    print(f\"\\n[{i}] Solving: {q[:60]}...\")\n",
        "\n",
        "    try:\n",
        "        # 메인 솔버 호출\n",
        "        out = solve_mmlu_astute_style(full_prompt=q, use_wiki=True, n_vote=5)\n",
        "\n",
        "        # 결과 저장\n",
        "        final_ans = out.get(\"final_answer\", \"A\") # 기본값 A\n",
        "        category = out.get(\"category\", \"business\")\n",
        "        keywords = out.get(\"keywords\", [])\n",
        "        reasoning = out.get(\"raw_reasoning\", \"\")\n",
        "\n",
        "        results.append(final_ans)\n",
        "\n",
        "        # DataFrame 업데이트\n",
        "        df.loc[i, \"rag_cot_answer\"] = final_ans\n",
        "        df.loc[i, \"pred_category\"] = category\n",
        "        df.loc[i, \"cot_full\"] = reasoning\n",
        "\n",
        "        # 키워드 저장 (개수가 가변적이므로 안전하게 처리)\n",
        "        df.loc[i, \"kw1\"] = keywords[0] if len(keywords) > 0 else \"\"\n",
        "        df.loc[i, \"kw2\"] = keywords[1] if len(keywords) > 1 else \"\"\n",
        "        df.loc[i, \"kw3\"] = keywords[2] if len(keywords) > 2 else \"\"\n",
        "\n",
        "        # (선택) 전체 키워드와 쿼리도 저장해두면 분석할 때 좋습니다\n",
        "        df.loc[i, \"all_keywords\"] = str(keywords)\n",
        "\n",
        "        # 중간 저장 (선택 사항: 코랩 런타임 끊김 대비)\n",
        "        if i % 10 == 0:\n",
        "            df.to_csv(\"temp_checkpoint.csv\", index=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"💥 Error processing index {i}: {e}\")\n",
        "        traceback.print_exc()\n",
        "        # 에러 시 기본값 채우기 (멈추지 않도록)\n",
        "        df.loc[i, \"rag_cot_answer\"] = \"A\"\n",
        "        df.loc[i, \"cot_full\"] = f\"Error: {str(e)}\"\n",
        "\n",
        "# 3. 최종 저장\n",
        "output_file = \"astute_rag_final_수정.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"\\n✅ 모든 작업 완료! 결과 저장됨: {output_file}\")"
      ],
      "metadata": {
        "id": "_uFFQoQp5u4s",
        "outputId": "c7b8e956-a8a7-4fff-ea0c-d85be5497dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Processing 25 questions from testset.csv...\n",
            "\n",
            "[25] Solving: QUESTION26) QUESTION 6) A psychologist is asked to see a 10-...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for minor consent in school-based psychological counseling']...\n",
            "   -> [Wiki Keywords] ['Informed consent', 'Minor consent in therapy', 'APA Ethics Code', 'Child assent in research', 'School psychology ethics']\n",
            "[Init] Building BM25 index for: psychology...\n",
            "[Init] BM25 ready for psychology (2232 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "\n",
            "[26] Solving: QUESTION27) A man is at home in his apartment, alone, late a...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law elements of robbery burglary and trespassing']...\n",
            "   -> [Wiki Keywords] ['Robbery (law)', 'Burglary', 'Trespassing', 'Aggravated assault', 'Common law crimes']\n",
            "[Init] Building BM25 index for: law...\n",
            "[Init] BM25 ready for law (91859 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "\n",
            "[27] Solving: QUESTION28) What do Homo sapiens and Australopithecus afaren...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative evolutionary traits between Homo sapiens and Australopithecus afarensis']...\n",
            "   -> [Wiki Keywords] ['Australopithecus afarensis', 'Homo sapiens', 'Bipedalism', 'Hominin evolution', 'Locomotion in early humans']\n",
            "[Init] Building BM25 index for: history...\n",
            "[Init] BM25 ready for history (17941 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "\n",
            "[28] Solving: QUESTION29)This question refers to the following information...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Tang dynasty frontier policy with nomadic tribes']...\n",
            "   -> [Wiki Keywords] ['Tang dynasty foreign relations', 'Tang dynasty military policy', 'Tang dynasty nomadic tribes', 'Du Fu Ballad of the Army Carts', 'Tang-Sogdiana relations']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "\n",
            "[29] Solving: QUESTION30)Homo erectus differed from Homo habilis in which ...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative cranial capacity Homo erectus Homo habilis']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Homo habilis', 'Human evolution', 'Paleoanthropology', 'Hominin species comparison']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "\n",
            "[30] Solving: QUESTION31)During the manic phase of a bipolar disorder, ind...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Diagnostic criteria for manic episode in bipolar disorder']...\n",
            "   -> [Wiki Keywords] ['Bipolar disorder', 'Manic episode', 'DSM-5 diagnostic criteria', 'Bipolar I disorder', 'Mood disorders']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "\n",
            "[31] Solving: QUESTION32) This question refers to the following informatio...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Clemenceau's attribution of WWI responsibility to Germany\"]...\n",
            "   -> [Wiki Keywords] ['Georges Clemenceau', 'Grandeur and Misery of Victory', 'Deutschland über alles', 'World War I responsibility', 'German nationalism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "\n",
            "[32] Solving: QUESTION33) You receive a phone call from Hermann H., age 28...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['APA ethical guidelines for therapist-client value conflicts']...\n",
            "   -> [Wiki Keywords] ['American Psychological Association Ethics Code', 'Countertransference', 'Therapist-client relationship', 'Ethical referral', 'Professional boundaries in psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "\n",
            "[33] Solving: QUESTION34) During the second stage of Kohlberg’s preconvent...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Kohlberg preconventional stage 2 punishment and reward orientation']...\n",
            "   -> [Wiki Keywords] ['Lawrence Kohlberg', 'Moral development', 'Preconventional morality', 'Instrumental purpose orientation', 'Stages of moral development']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "\n",
            "[34] Solving: QUESTION35)  In satisfying Kant's Humanity formulation of th...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Kant's categorical imperative humanity formulation obligations\"]...\n",
            "   -> [Wiki Keywords] ['Categorical imperative', 'Humanity formulation', 'Immanuel Kant', 'Moral philosophy', 'Kantian ethics']\n",
            "[Init] Building BM25 index for: philosophy...\n",
            "[Init] BM25 ready for philosophy (54977 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 3, 'F': 1, 'E': 1}\n",
            "\n",
            "[35] Solving: QUESTION36) Aristotle says  that what makes things be what t...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Aristotelian essence dependence on individual existence']...\n",
            "   -> [Wiki Keywords] ['Aristotelianism', 'Hylomorphism', 'Theory of forms', 'Metaphysics (Aristotle)', 'Platonic realism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "\n",
            "[36] Solving: QUESTION37) The ________ School of jurisprudence believes th...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Jurisprudence schools defining law as historical social traditions']...\n",
            "   -> [Wiki Keywords] ['Historical school of jurisprudence', 'Schools of legal thought', 'Legal positivism', 'Customary law', 'Friedrich Karl von Savigny']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "\n",
            "[37] Solving: QUESTION38) A woman was standing in the aisle of a subway ca...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law distinction between larceny and robbery when force occurs post-taking']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Robbery (law)', 'Common law crimes', 'Criminal law elements', 'Theft act definitions']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'B': 1, 'G': 4}\n",
            "\n",
            "[38] Solving: QUESTION39) A defendant met her friend at the electronics st...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Criminal liability for unintentional possession of stolen goods']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Receiving stolen property', 'Theft', 'Criminal law', 'Possession of stolen goods']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "\n",
            "[39] Solving: QUESTION40)____________ refers to a strategic process involv...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Strategic stakeholder engagement for sustainable customer relationships']...\n",
            "   -> [Wiki Keywords] ['Sustainable Development', 'Environmental Stewardship', 'Green Marketing', 'Eco-branding', 'Stakeholder Theory']\n",
            "[Init] Building BM25 index for: business...\n",
            "[Init] BM25 ready for business (6285 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 4, 'E': 1}\n",
            "\n",
            "[40] Solving: QUESTION41)This question refers to the following information...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ancient Mesopotamian and Egyptian religious conceptions of the afterlife']...\n",
            "   -> [Wiki Keywords] ['The Epic of Gilgamesh', 'The Maxims of Ptahhotep', 'Ancient Near Eastern religion', 'Afterlife in ancient Mesopotamia', 'Egyptian afterlife beliefs']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "\n",
            "[41] Solving: QUESTION42) Is the recognition of foreign judgments subject ...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Recognition of foreign judgments', 'Monism (international relations)', 'Dualism (international law)', 'Conflict of laws', 'Treaty implementation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "\n",
            "[42] Solving: QUESTION43) Some contemporary intelligence researchers like ...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "\n",
            "[43] Solving: QUESTION44) BobGafneyand Susan Medina invested $40,000 and $...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership accounting profit distribution with management fee and interest on capital']...\n",
            "   -> [Wiki Keywords] ['Partnership accounting', 'Profit sharing', 'Partnership agreement terms', 'Interest on capital in partnerships', 'Management fee allocation']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "\n",
            "[44] Solving: QUESTION45) One objection to Singer’s theory that he conside...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections regarding proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', 'Famine, Affluence, and Morality', \"Singer's Pond Example\", 'Ethical obligations to strangers', 'Moral philosophy objections']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "\n",
            "[45] Solving: QUESTION46) In 1797, John Frere made a discovery that he des...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne Palaeolithic site', 'Paleolithic archaeology', 'Stone Age tools discovery', 'Prehistoric archaeology history']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "\n",
            "[46] Solving: QUESTION47) Pick the correct description of the following te...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Utilitarianism definition greatest good for the greatest number']...\n",
            "   -> [Wiki Keywords] ['Utilitarianism', 'Jeremy Bentham', 'Greatest happiness principle', 'Consequentialism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "\n",
            "[47] Solving: QUESTION48) Which of the following describes a key change in...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Evolutionary changes in Homo erectus brain development']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Encephalization quotient', 'Human evolution', 'Hominin brain evolution', 'Paleoanthropology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "\n",
            "[48] Solving: QUESTION49) Delia was accepted to both Harvard University an...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychological conflict types approach-approach definition']...\n",
            "   -> [Wiki Keywords] ['Approach-approach conflict', 'Cognitive dissonance', 'Psychological conflict types', 'Decision-making psychology']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "\n",
            "[49] Solving: QUESTION50) Which is the least accurate description of legal...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Core tenets of legal positivism in jurisprudence']...\n",
            "   -> [Wiki Keywords] ['Legal positivism', 'Jurisprudence', 'Separation thesis', 'H.L.A. Hart', 'John Austin (legal philosopher)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'C': 1, 'B': 4}\n",
            "\n",
            "✅ 모든 작업 완료! 결과 저장됨: astute_rag_final_수정.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로\n",
        "GT_PATH = \"testset.csv\"          # 정답 파일\n",
        "PRED_PATH = \"astute_rag_final_수정.csv\"  # 출력 파일 (현재 경로에 저장됨)\n",
        "\n",
        "# 2. 컬럼 이름\n",
        "GT_COL = \"answers\"               # testset.csv에서 정답 컬럼\n",
        "PRED_COL = \"rag_cot_answer\"      # baseline.csv에서 예측 컬럼\n",
        "\n",
        "# 3. csv 로드\n",
        "gt_df = pd.read_csv(GT_PATH)[25:]\n",
        "pred_df = pd.read_csv(PRED_PATH)\n",
        "\n",
        "# 4. Series 추출\n",
        "gt = gt_df[GT_COL].astype(str)\n",
        "pred = pred_df[PRED_COL].astype(str)\n",
        "\n",
        "# 5. 정규화 함수\n",
        "def normalize_choice(x: str) -> str:\n",
        "    x = x.strip().upper()\n",
        "    for ch in x:\n",
        "        if \"A\" <= ch <= \"Z\":\n",
        "            return ch\n",
        "    return x\n",
        "\n",
        "# 인덱스 리셋 (중요: 길이를 맞추기 위해)\n",
        "gt_norm = gt.apply(normalize_choice).reset_index(drop=True)\n",
        "pred_norm = pred.apply(normalize_choice).reset_index(drop=True)\n",
        "\n",
        "print(f\"Ground Truth 개수: {len(gt_norm)}, Prediction 개수: {len(pred_norm)}\")\n",
        "\n",
        "# 6. 정확도 계산\n",
        "correct = (gt_norm == pred_norm)\n",
        "accuracy = correct.mean()\n",
        "\n",
        "print(f\"총 문제 수: {len(gt_norm)}\")\n",
        "print(f\"정답 개수: {correct.sum()}\")\n",
        "print(f\"정확도: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "J4s43TAo8Dry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0627cc6f-6a09-448d-cc18-a5f33892e683"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth 개수: 25, Prediction 개수: 25\n",
            "총 문제 수: 25\n",
            "정답 개수: 20\n",
            "정확도: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNHCT1wTzgWv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}