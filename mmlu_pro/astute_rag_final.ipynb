{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoyen1122/solar_rag/blob/main/mmlu_pro/astute_rag_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "문서 분석 로직 & 외부 문서는 그냥 불러오기\n"
      ],
      "metadata": {
        "id": "lXWGosH071IU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nyH8sMMs2RD-",
        "outputId": "7d36974b-f50b-476f-b93d-385258b64887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-upstage\n",
            "  Downloading langchain_upstage-0.7.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from langchain-upstage) (1.0.7)\n",
            "Collecting langchain-openai<2.0.0,>=1.0.2 (from langchain-upstage)\n",
            "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pypdf<5.0.0,>=4.2.0 (from langchain-upstage)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from langchain-upstage) (2.32.4)\n",
            "Collecting tokenizers<0.21.0,>=0.20.0 (from langchain-upstage)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.31.0 (from langchain-upstage)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (4.15.0)\n",
            "Collecting langchain-core<2.0.0,>=1.0.3 (from langchain-upstage)\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<0.21.0,>=0.20.0->langchain-upstage) (0.36.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.3->langchain-upstage) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (2025.11.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_upstage-0.7.5-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, typing-inspect, tokenizers, dataclasses-json, langchain-core, langchain-text-splitters, langchain-openai, langchain-upstage, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 1.0.7\n",
            "    Uninstalling langchain-core-1.0.7:\n",
            "      Successfully uninstalled langchain-core-1.0.7\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "transformers 4.57.1 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.0 langchain-openai-1.1.0 langchain-text-splitters-1.0.0 langchain-upstage-0.7.5 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-4.3.1 requests-2.32.5 tokenizers-0.20.3 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-upstage langchain-community pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pdBgMTNwMuCm",
        "outputId": "bd41673b-703a-4327-bbe1-8a4348b0ac59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from wikipedia-api) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (2025.11.12)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=30be5a29aaa43a4f201b5e74eab29551781082e7f5aeb64ddc7653b97b98a1ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/3c/79/b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ],
      "source": [
        "pip install wikipedia-api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C-AXD7fLRJI-",
        "outputId": "cd17848a-2381-4d77-983f-8e4d2a056a88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n"
          ]
        }
      ],
      "source": [
        "pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdAIEV27UrkW",
        "outputId": "f2959150-154d-4650-f393-6cef3e961482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-upstage 0.7.5 requires tokenizers<0.21.0,>=0.20.0, but you have tokenizers 0.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.22.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qWw7Tq17dHw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from typing import List, Tuple\n",
        "\n",
        "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import wikipediaapi\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u3yQM7bzVIz",
        "outputId": "c391d14b-252a-4d25-a122-fee9cbc46800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gavGzRrztXz",
        "outputId": "e1a4b291-86f7-4d33-e252-a0bde7e56fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/nlp team project\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/nlp team project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-yFVp9vQ26G"
      },
      "outputs": [],
      "source": [
        "UPSTAGE_API_KEY = \"up_VYzFNHEoEJPfAwYUNp5v9n1CPnMOm\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgvozRFhCJMz"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"testset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK1l_XYgUPay"
      },
      "outputs": [],
      "source": [
        "llm_classifier = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oElUzmTxV6M-"
      },
      "outputs": [],
      "source": [
        "llm_solver = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solar_pro = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "CNd-bE5razCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6fjf7tL0E6A"
      },
      "outputs": [],
      "source": [
        "category_index = {\n",
        "    \"law\":        \"/content/drive/MyDrive/nlp team project/code/mmlu_category/law\",\n",
        "    \"psychology\": \"/content/drive/MyDrive/nlp team project/code/mmlu_category/psychology\",\n",
        "    \"business\":   \"/content/drive/MyDrive/nlp team project/code/mmlu_category/business\",\n",
        "    \"philosophy\": \"/content/drive/MyDrive/nlp team project/code/mmlu_category/philosophy\",\n",
        "    \"history\":    \"/content/drive/MyDrive/nlp team project/code/mmlu_category/history\",\n",
        "}\n",
        "\n",
        "categories = list(category_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvfgJRYeP9M4"
      },
      "outputs": [],
      "source": [
        "\n",
        "emb = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large-passage\")\n",
        "\n",
        "# 카테고리별 faiss 한번에 로드해서 캐시\n",
        "vectorstore = {}\n",
        "for cat, path in category_index.items():\n",
        "    vectorstore[cat] = FAISS.load_local(\n",
        "        folder_path=path,\n",
        "        embeddings=emb,\n",
        "        allow_dangerous_deserialization=True,\n",
        "    )\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(user_agent= \"NLP-RAG/1.0\", language = 'en')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRn3avDKKexv"
      },
      "source": [
        "**1st LLM**:\n",
        "\n",
        "- return category\n",
        "\n",
        "- return 3 keywords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import json\n",
        "\n",
        "# 질문 분석을 위한 전용 프롬프트\n",
        "P_ANALYZE_TMPL = \"\"\"\n",
        "You are an expert Question Analyst for MMLU-Pro.\n",
        "Your task is NOT to answer the question, but to dissect it so that a researcher can find the best evidence.\n",
        "\n",
        "[Task]\n",
        "Analyze the following exam question and extracted information:\n",
        "\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Options:\n",
        "{options_text}\n",
        "\n",
        "Output a JSON object with the following fields:\n",
        "1. \"core_intent\": Summarize what the question is asking in 1 sentence.\n",
        "2. \"constraints\": A list of strict conditions that the answer MUST satisfy (e.g., time period, specific person, negation 'NOT', location).\n",
        "3. \"search_queries\": A list of 3-5 optimized search queries to put into a vector database or Wikipedia.\n",
        "   - Break down complex questions into simpler sub-queries.\n",
        "   - Include specific entities mentioned in the question.\n",
        "\n",
        "Example Output:\n",
        "{{\n",
        "  \"core_intent\": \"Identify the specific treaty that ended the Crimean War.\",\n",
        "  \"constraints\": [\"Must be a treaty\", \"Related to Crimean War\", \"Must match the historical timeline (1856)\"],\n",
        "  \"search_queries\": [\"Treaty ending Crimean War\", \"Paris Treaty 1856\", \"Crimean War conclusion diplomatic agreement\"]\n",
        "}}\n",
        "\n",
        "Return ONLY the valid JSON object.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_analyze_prompt = ChatPromptTemplate.from_template(P_ANALYZE_TMPL)\n",
        "\n",
        "def run_p_analyze(question_text: str, options: dict, llm=None) -> dict:\n",
        "    \"\"\"\n",
        "    질문을 분석하여 검색 쿼리와 제약 조건을 추출합니다.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        llm = llm_solver  # 기존에 정의된 llm 객체 사용\n",
        "\n",
        "    # 옵션 텍스트화\n",
        "    options_str = \"\\n\".join([f\"({k}) {v}\" for k, v in options.items()])\n",
        "\n",
        "    messages = p_analyze_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        options_text=options_str\n",
        "    )\n",
        "\n",
        "    resp = llm.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # JSON 파싱 (실패 시 기본값 반환 처리 포함)\n",
        "    try:\n",
        "        # 마크다운 코드 블록 제거 등 기본적인 정제\n",
        "        if \"```json\" in raw:\n",
        "            raw = raw.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in raw:\n",
        "            raw = raw.split(\"```\")[0].strip()\n",
        "\n",
        "        analysis = json.loads(raw)\n",
        "        return analysis\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] p_analyze failed: {e}\")\n",
        "        # 실패 시 기본값: 검색어는 질문 그대로\n",
        "        return {\n",
        "            \"core_intent\": \"Unknown\",\n",
        "            \"constraints\": [],\n",
        "            \"search_queries\": [question_text]\n",
        "        }"
      ],
      "metadata": {
        "id": "11SgvgDz6WBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzr6RkbISTas"
      },
      "outputs": [],
      "source": [
        "category_prompt_template = \"\"\"\n",
        "You are an expert exam classifier for MMLU-Pro.\n",
        "\n",
        "There are 5 possible categories:\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "\n",
        "[Task]\n",
        "You will be given ONE multiple-choice exam question (stem + options).\n",
        "\n",
        "First, think about the question in the following way:\n",
        "\n",
        "1. Read the entire question and options carefully.\n",
        "2. Extract 3–6 essential CLUES:\n",
        "   - short phrases capturing key entities, concepts, time periods, theories, or legal doctrines.\n",
        "   - Each clue should be specific enough to guide retrieval.\n",
        "\n",
        "Then, based on these clues:\n",
        "\n",
        "3. Choose the single best category from the 5 above.\n",
        "4. Propose 5 EXACT Wikipedia article titles for retrieval.\n",
        "   - Titles 1–2: Specific entities / proper nouns\n",
        "     (e.g., \"Sherman Antitrust Act\", \"Jean Piaget\").\n",
        "   - Titles 3–5: Broader parent topics\n",
        "     (e.g., \"Antitrust law\", \"Developmental psychology\").\n",
        "   - [CRITICAL] Do NOT use descriptive phrases like\n",
        "     \"history of...\", \"principles of...\". Just concise noun titles.\n",
        "\n",
        "[Output]\n",
        "Return ONLY one valid JSON object with fields:\n",
        "- \"clues\": list of 3–6 short strings\n",
        "- \"category\": one of [\"law\", \"psychology\", \"business\", \"philosophy\", \"history\"]\n",
        "- \"keywords\": list of exactly 5 strings (Wikipedia article titles)\n",
        "\n",
        "[Example]\n",
        "Q: \"In 1797, John Frere made a discovery...\"\n",
        "Output:\n",
        "{{\n",
        "  \"clues\": [\n",
        "    \"1797 discovery\",\n",
        "    \"John Frere\",\n",
        "    \"ancient stone tools\",\n",
        "    \"Paleolithic archaeology\"\n",
        "  ],\n",
        "  \"category\": \"history\",\n",
        "  \"keywords\": [\n",
        "    \"John Frere\",\n",
        "    \"Hoxne Hoard\",\n",
        "    \"Paleolithic\",\n",
        "    \"Stone Age\",\n",
        "    \"Archaeology\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Now classify the following question and return ONLY the JSON object.\n",
        "\n",
        "[Question]\n",
        "{question}\n",
        "\"\"\".strip()\n",
        "\n",
        "# Re-create the prompt object\n",
        "category_prompt = ChatPromptTemplate.from_template(category_prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93dJK7O09Jar"
      },
      "outputs": [],
      "source": [
        "def classify_and_extract_keywords(question_text: str):\n",
        "    # 위에서 정의한 (Few-Shot이 추가된) 프롬프트 템플릿 사용\n",
        "    messages = category_prompt.format_messages(question=question_text)\n",
        "\n",
        "    # LLM 호출 (temperature=0.1 정도로 낮게 설정된 llm_classifier 권장)\n",
        "    resp = llm_classifier.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # 빈 응답 방어 로직\n",
        "    if not raw:\n",
        "        print(\"[WARN] Empty LLM output for category, fallback to 'history'\")\n",
        "        return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    # JSON 파싱 로직\n",
        "    data = {}\n",
        "    try:\n",
        "        # 1차 시도: 전체 파싱\n",
        "        data = json.loads(raw)\n",
        "    except json.JSONDecodeError:\n",
        "        # 2차 시도: 마크다운 코드블록(```json ... ```)이나 잡다한 텍스트 제거 후 파싱\n",
        "        start = raw.find(\"{\")\n",
        "        end = raw.rfind(\"}\")\n",
        "        if start != -1 and end != -1:\n",
        "            json_str = raw[start:end+1]\n",
        "            try:\n",
        "                data = json.loads(json_str)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"[WARN] JSON parse failed: {e}\")\n",
        "        else:\n",
        "            print(\"[WARN] No JSON braces found.\")\n",
        "\n",
        "    # 파싱 실패 시 기본값 반환\n",
        "    if not data:\n",
        "         return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    # 데이터 추출\n",
        "    category = data.get(\"category\", \"history\").strip().lower()\n",
        "    raw_keywords = data.get(\"keywords\", [])\n",
        "\n",
        "    # [수정 포인트] 문자열 변환 및 공백 제거만 하고, 개수 제한은 [:5] 정도로 넉넉하게\n",
        "    keywords = [str(k).strip() for k in raw_keywords if str(k).strip()][:5]\n",
        "\n",
        "    # 키워드가 하나도 없으면 기본값\n",
        "    if not keywords:\n",
        "        keywords = [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    return category, keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_n3aEbhUxxX"
      },
      "outputs": [],
      "source": [
        "def fetch_wiki_context(keywords, window_size=2000):\n",
        "    snippets = []\n",
        "    seen_titles = set()\n",
        "\n",
        "    for kw in keywords:\n",
        "        kw = (kw or \"\").strip()\n",
        "        if not kw: continue\n",
        "\n",
        "        candidates = [kw, kw.title()]\n",
        "        # 괄호 제거 등 추가 처리\n",
        "        if \"(\" in kw: candidates.append(kw.split(\"(\")[0].strip())\n",
        "\n",
        "        found_flag = False\n",
        "        for cand in candidates:\n",
        "            if cand in seen_titles: continue\n",
        "\n",
        "            try:\n",
        "                page = wiki.page(cand)\n",
        "                if page.exists():\n",
        "                    seen_titles.add(cand)\n",
        "                    full_text = page.text\n",
        "\n",
        "                    # [개선] 단순히 앞부분만 자르는 게 아니라, 키워드가 등장하는 위치를 찾음\n",
        "                    # 키워드가 텍스트 내에 있으면 그 주변을 가져옴. 없으면 앞부분 가져옴.\n",
        "                    lower_text = full_text.lower()\n",
        "                    lower_kw = kw.lower()\n",
        "                    start_idx = lower_text.find(lower_kw)\n",
        "\n",
        "                    if start_idx == -1:\n",
        "                        # 키워드 못 찾으면 그냥 앞부분\n",
        "                        display_text = full_text[:window_size]\n",
        "                    else:\n",
        "                        # 키워드 주변부 (앞으로 500자, 뒤로 1500자 정도)\n",
        "                        start_pos = max(0, start_idx - 500)\n",
        "                        end_pos = min(len(full_text), start_idx + window_size)\n",
        "                        display_text = full_text[start_pos:end_pos]\n",
        "\n",
        "                    clean_text = display_text.replace('\\n', ' ')\n",
        "                    snippets.append(f\"[Wikipedia: {page.title}]\\n...{clean_text}...\")\n",
        "                    found_flag = True\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    if not snippets:\n",
        "        return \"\"\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIwiC6e0e44n"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "############################################\n",
        "# 0. 상수 & 기본 설정\n",
        "############################################\n",
        "\n",
        "TOP_K_TEXTBOOK = 5\n",
        "TOP_K_WIKI = 5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 1. 질문 + 옵션(A~I) 파싱\n",
        "############################################\n",
        "\n",
        "# 1. 질문 + 옵션(A~J) 파싱\n",
        "def parse_question_and_options(prompt: str):\n",
        "    \"\"\"\n",
        "    prompt: QUESTION + (A) ~ (J) 옵션이 한 문자열에 들어있는 형태\n",
        "    return: question_text(str), options(dict: 'A'~'J' -> str)\n",
        "    \"\"\"\n",
        "    pattern = r\"\\(([A-J])\\)\\s*\"\n",
        "    matches = list(re.finditer(pattern, prompt))\n",
        "\n",
        "    if not matches:\n",
        "        return prompt.strip(), {}\n",
        "\n",
        "    first = matches[0]\n",
        "    question_text = prompt[:first.start()].strip()\n",
        "\n",
        "    options: Dict[str, str] = {}\n",
        "    for idx, m in enumerate(matches):\n",
        "        letter = m.group(1)  # 'A'~'J'\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(prompt)\n",
        "        opt_text = prompt[start:end].strip()\n",
        "        options[letter] = opt_text\n",
        "\n",
        "    return question_text, options\n"
      ],
      "metadata": {
        "id": "lNFvwZRPpuBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 2. \"Final Answer: X\" 파서\n",
        "############################################\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    p_ans 출력에서 'Final Answer: X' 의 X(A~J)를 뽑기.\n",
        "    \"\"\"\n",
        "    m = re.search(r\"Final Answer:\\s*([A-J])\\s*$\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if m:\n",
        "        return m.group(1).upper()\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "zaonqmXWp2gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################\n",
        "# 3. Memory p_gen (INTERNAL 문서 생성)\n",
        "############################################\n",
        "\n",
        "P_MEM_TMPL = \"\"\"\n",
        "You are a knowledgeable expert in {category}.\n",
        "\n",
        "Task: Using ONLY your own internal knowledge (without seeing any external documents),\n",
        "generate a short document that provides accurate and relevant information to help\n",
        "answer the given exam question.\n",
        "\n",
        "If you truly do not know the answer or lack enough information, explicitly state\n",
        "\"I don't know\" rather than hallucinating facts.\n",
        "\n",
        "Exam Question:\n",
        "{question_text}\n",
        "\n",
        "Write ONE coherent document that:\n",
        "- Focuses only on concepts, definitions, and relations that are relevant to the question.\n",
        "- Is self-contained and clear enough to help another model answer the question.\n",
        "- Avoids unnecessary details.\n",
        "\n",
        "Document:\n",
        "\"\"\".strip()\n",
        "\n",
        "p_mem_prompt = ChatPromptTemplate.from_template(P_MEM_TMPL)\n",
        "\n",
        "\n",
        "def run_p_mem(category: str, question_text: str, llm=None) -> str:\n",
        "    if llm is None:\n",
        "        llm = llm_solver\n",
        "    msgs = p_mem_prompt.format_messages(\n",
        "        category=category,\n",
        "        question_text=question_text,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()"
      ],
      "metadata": {
        "id": "bu5pWXR0p6mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_p_gen_for_docs(\n",
        "    category: str,             # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    source_type: str,          # \"TEXTBOOK\" or \"WIKIPEDIA\"\n",
        "    question_text: str,        # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    raw_passages: List[str],   # 검색된 원본 텍스트 리스트\n",
        "    start_doc_idx: int = 1,\n",
        "    llm=None,                  # 사용 안 함 (호환성 위해 남겨둠)\n",
        ") -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    [수정됨] LLM을 통한 요약/재작성을 수행하지 않습니다.\n",
        "    검색된 Raw Passage를 그대로 포맷팅하여 반환합니다.\n",
        "    이렇게 해야 정보 손실(Information Loss) 없이 p_con이나 p_ans 단계로 넘어갑니다.\n",
        "    \"\"\"\n",
        "    doc_blocks = []\n",
        "    cur_idx = start_doc_idx\n",
        "\n",
        "    for k, passage in enumerate(raw_passages, start=1):\n",
        "        # 빈 텍스트 무시\n",
        "        if not passage or not passage.strip():\n",
        "            continue\n",
        "\n",
        "        # [중요] LLM 호출(invoke) 없이 원본 텍스트를 그대로 넣습니다.\n",
        "        # 필요하다면 너무 긴 문단만 파이썬 문자열 슬라이싱으로 자르세요 (예: [:2000])\n",
        "        clean_passage = passage.strip()\n",
        "\n",
        "        block = (\n",
        "            f\"[Doc {cur_idx} | SOURCE=EXTERNAL({source_type}) | ORIG_ID={source_type}_{k}]\\n\"\n",
        "            f\"{clean_passage}\"\n",
        "        )\n",
        "        doc_blocks.append(block)\n",
        "        cur_idx += 1\n",
        "\n",
        "    return \"\\n\\n\".join(doc_blocks), cur_idx"
      ],
      "metadata": {
        "id": "1At0qigQ54dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgTA-0fz4Sc0",
        "outputId": "53d2f042-ed45-4785-d0dc-b3ee5cef3e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rank_bm25\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Installing collected packages: rank_bm25\n",
            "Successfully installed rank_bm25-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "############################################\n",
        "# 5. Retrieval helpers (Hybrid: Vector + BM25)\n",
        "############################################\n",
        "\n",
        "# 전역 캐시 (BM25 인덱스를 매번 만들지 않기 위해 저장)\n",
        "bm25_store = {}   # {category: BM25Okapi_object}\n",
        "doc_store = {}    # {category: [text_list]}\n",
        "\n",
        "def init_bm25_for_category(category: str):\n",
        "    \"\"\"\n",
        "    [초기화] 해당 카테고리의 모든 문서를 로드하여 BM25 인덱스를 생성\n",
        "    \"\"\"\n",
        "    if category in bm25_store:\n",
        "        return\n",
        "\n",
        "    if category not in vectorstore:\n",
        "        return\n",
        "\n",
        "    print(f\"[Init] Building BM25 index for: {category}...\")\n",
        "    vs = vectorstore[category]\n",
        "\n",
        "    try:\n",
        "        # FAISS 메모리에서 모든 문서 텍스트 추출\n",
        "        # (주의: FAISS 로드 시 데이터가 메모리에 있어야 함)\n",
        "        all_docs = list(vs.docstore._dict.values())\n",
        "        texts = [d.page_content for d in all_docs]\n",
        "\n",
        "        if not texts:\n",
        "            print(f\"[Warn] No texts found in docstore for {category}.\")\n",
        "            return\n",
        "\n",
        "        # 토크나이징 (단순 띄어쓰기 기준)\n",
        "        tokenized_corpus = [doc.lower().split() for doc in texts]\n",
        "\n",
        "        # 저장\n",
        "        bm25_store[category] = BM25Okapi(tokenized_corpus)\n",
        "        doc_store[category] = texts\n",
        "        print(f\"[Init] BM25 ready for {category} ({len(texts)} docs)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Warn] Failed to init BM25 for {category} (Pure Vector mode will be used): {e}\")\n",
        "\n",
        "\n",
        "def reciprocal_rank_fusion(results_list: List[List[str]], k=60) -> List[str]:\n",
        "    \"\"\"\n",
        "    [RRF 알고리즘] 여러 검색 결과의 순위를 합산하여 재정렬\n",
        "    \"\"\"\n",
        "    fused_scores = {}\n",
        "\n",
        "    for docs in results_list:\n",
        "        for rank, doc_text in enumerate(docs):\n",
        "            if doc_text not in fused_scores:\n",
        "                fused_scores[doc_text] = 0\n",
        "            # 순위가 높을수록(rank가 작을수록) 높은 점수 부여\n",
        "            fused_scores[doc_text] += 1 / (rank + k)\n",
        "\n",
        "    # 점수 높은 순 정렬\n",
        "    reranked = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [text for text, score in reranked]\n",
        "\n",
        "\n",
        "def get_textbook_passages(category: str, query: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    [수정된 함수] Hybrid Search 적용\n",
        "    1. Vector Search (의미 검색) -> 10개\n",
        "    2. BM25 Search (키워드 검색) -> 10개\n",
        "    3. RRF Fusion -> 상위 5개 반환\n",
        "    \"\"\"\n",
        "    if category not in vectorstore:\n",
        "        return []\n",
        "\n",
        "    # 0. BM25 준비\n",
        "    if category not in bm25_store:\n",
        "        init_bm25_for_category(category)\n",
        "\n",
        "    # 1. Vector Search (Semantic)\n",
        "    vs = vectorstore[category]\n",
        "    # 후보를 10개 정도 가져옴\n",
        "    vec_candidates = vs.similarity_search(query, k=10)\n",
        "    vec_results = [d.page_content for d in vec_candidates]\n",
        "\n",
        "    # 2. BM25 Search (Keyword) - 만약 준비 안됐으면 생략\n",
        "    bm25_results = []\n",
        "    if category in bm25_store:\n",
        "        bm25 = bm25_store[category]\n",
        "        docs = doc_store[category]\n",
        "\n",
        "        tokenized_query = query.lower().split()\n",
        "        # 키워드 매칭 상위 10개\n",
        "        bm25_results = bm25.get_top_n(tokenized_query, docs, n=10)\n",
        "\n",
        "    # 3. Fusion (하나만 있으면 그것만 반환)\n",
        "    if not bm25_results:\n",
        "        final_passages = vec_results\n",
        "    else:\n",
        "        # 두 결과를 섞음\n",
        "        final_passages = reciprocal_rank_fusion([vec_results, bm25_results], k=60)\n",
        "\n",
        "    # 최종 TOP_K 개수만큼 자르기\n",
        "    return final_passages[:TOP_K_TEXTBOOK]\n",
        "\n",
        "\n",
        "def get_wiki_passages(keywords: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    (기존 유지)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        raw = fetch_wiki_context(keywords)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Wikipedia retrieval failed: {e}\")\n",
        "        return []\n",
        "\n",
        "    raw = (raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return []\n",
        "    return [raw]"
      ],
      "metadata": {
        "id": "VJHLEssx2iHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 6. Iterative Knowledge Consolidation p_con (Few-Shot Optimized)\n",
        "############################################\n",
        "\n",
        "P_CON_TMPL = \"\"\"\n",
        "You are a Knowledge Integrator for MMLU-Pro dataset.\n",
        "\n",
        "Task: Consolidate information from both your own memorized documents (INTERNAL)\n",
        "and externally retrieved documents (EXTERNAL) in response to the given exam question.\n",
        "\n",
        "Guidelines:\n",
        "* For documents that provide consistent information, cluster them together and\n",
        "  summarize the key details into a single, concise document.\n",
        "* For documents with conflicting information, separate them into distinct documents,\n",
        "  ensuring each document captures the unique perspective or data.\n",
        "* Exclude any information that is irrelevant to the question.\n",
        "* For each NEW document you create, clearly indicate:\n",
        "  - Whether the source was INTERNAL(MEMORY) or EXTERNAL(TEXTBOOK/WIKIPEDIA).\n",
        "  - The original document numbers that contributed to it (e.g., FROM=1,3,4).\n",
        "\n",
        "[Examples]\n",
        "\n",
        "<Example 1: Conflict Resolution>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=INTERNAL(MEMORY)]\n",
        "The Treaty of Versailles was signed in 1918.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "The Treaty of Versailles was signed on June 28, 1919, officially ending WWI.\n",
        "\n",
        "Question: When was the Treaty of Versailles signed?\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(TEXTBOOK) | FROM=2]\n",
        "The Treaty of Versailles was signed on June 28, 1919.\n",
        "(Correction: Internal memory incorrectly stated 1918, which was the armistice year, not the treaty signing.)\n",
        "</Example 1>\n",
        "\n",
        "<Example 2: Merging Consistent Info>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(WIKIPEDIA)]\n",
        "Classical conditioning involves a neutral stimulus becoming a conditioned stimulus.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "Pavlov's dog experiment demonstrated classical conditioning by pairing a bell with food.\n",
        "\n",
        "Question: Explain the mechanism of classical conditioning.\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=MERGED(EXTERNAL) | FROM=1,2]\n",
        "Classical conditioning is a learning process where a neutral stimulus (like a bell) becomes a conditioned stimulus after being paired with an unconditioned stimulus (like food). This was demonstrated in Pavlov's dog experiment.\n",
        "</Example 2>\n",
        "\n",
        "[Real Task]\n",
        "\n",
        "Initial Context (numbered documents):\n",
        "{context_init}\n",
        "\n",
        "Last Context (may be empty):\n",
        "{last_context}\n",
        "\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Now produce your New Context following the examples.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_con_prompt = ChatPromptTemplate.from_template(P_CON_TMPL)\n",
        "\n",
        "def run_p_con(\n",
        "    question_text: str,\n",
        "    context_init: str,\n",
        "    last_context: str = \"\",\n",
        "    llm=None,\n",
        ") -> str:\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    msgs = p_con_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        context_init=context_init,\n",
        "        last_context=last_context,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()\n"
      ],
      "metadata": {
        "id": "_Zpu4HRa6-rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 7. Knowledge Consolidation + Answer Finalization p_ans (10-Option Optimized)\n",
        "############################################\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    모델이 내뱉는 다양한 형식을 모두 잡아내는 강력한 추출 함수\n",
        "    \"\"\"\n",
        "    if not text: return \"\"\n",
        "\n",
        "    # 1순위: \"Final Answer\" 뒤에 오는 첫 번째 영문자 (A-J) 찾기\n",
        "    # 예: \"**Final Answer:** (A)\", \"Final Answer: Option A\", \"Final Answer is [A]\"\n",
        "    # [^\\nA-J]* : 줄바꿈이나 A-J가 나오기 전까지의 모든 특수문자(:, *, 공백 등)를 무시\n",
        "    match = re.search(r\"Final Answer[^\\nA-J]*([A-J])\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if match:\n",
        "        return match.group(1).upper()\n",
        "\n",
        "    # 2순위: <ANSWER> 태그 (프롬프트에서 지시한 경우)\n",
        "    match_tag = re.search(r\"<ANSWER>\\s*\\(?([A-J])\\)?\", text, flags=re.IGNORECASE)\n",
        "    if match_tag:\n",
        "        return match_tag.group(1).upper()\n",
        "\n",
        "    # 3순위: 최후의 수단 - 문장 맨 끝에 있는 (A) 형태 찾기\n",
        "    fallback = re.findall(r\"\\(?([A-J])\\)?\", text.split(\"\\n\")[-1])\n",
        "    if fallback:\n",
        "        return fallback[-1].upper()\n",
        "\n",
        "    return \"\" # 정말 답이 없는 경우\n"
      ],
      "metadata": {
        "id": "aEK5ci917MW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 카테고리별 역할 / 풀이 전략 텍스트\n",
        "# ============================================\n",
        "\n",
        "CATEGORY_META = {\n",
        "    \"law\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert law exam solver. \"\n",
        "            \"You specialize in bar-exam style multiple-choice questions \"\n",
        "            \"in criminal law, torts, contracts, constitutional law, property, and evidence.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"When solving LAW questions:\\n\"\n",
        "            \"- Treat the QUESTION as a fact pattern and map it to specific legal rules and elements.\\n\"\n",
        "            \"- Identify the relevant doctrine (e.g., mens rea, causation, standing, jurisdiction, remedies).\\n\"\n",
        "            \"- For each option, check whether ALL required elements are satisfied or if any element is missing.\\n\"\n",
        "            \"- If CONTEXT (textbook/Wikipedia) conflicts with the specific facts in the QUESTION, \"\n",
        "            \"always follow the QUESTION's fact pattern.\\n\"\n",
        "        ),\n",
        "    },\n",
        "    \"history\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert history exam solver. \"\n",
        "            \"You handle world, U.S., European, Asian, Latin American and African history, \"\n",
        "            \"and questions based on primary-source excerpts.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"When solving HISTORY questions:\\n\"\n",
        "            \"- First infer the approximate time period, region, and key actors from the QUESTION.\\n\"\n",
        "            \"- Use CONTEXT mainly to confirm chronology, causes, and consequences of events.\\n\"\n",
        "            \"- Pay attention to clues about ideology, institutions, wars, treaties, and social movements.\\n\"\n",
        "            \"- If the QUESTION's wording suggests a specific event or policy, treat that as the strongest clue.\\n\"\n",
        "        ),\n",
        "    },\n",
        "    \"philosophy\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert philosophy exam solver. \"\n",
        "            \"You handle ethics, epistemology, metaphysics, logic, philosophy of mind and language, \"\n",
        "            \"political philosophy, and the history of philosophy.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"When solving PHILOSOPHY questions:\\n\"\n",
        "            \"- Identify which author, school, or position is being tested (e.g., Kantian, utilitarian, rationalist).\\n\"\n",
        "            \"- Pay close attention to technical distinctions (e.g., de re vs. de dicto, internalism vs. externalism).\\n\"\n",
        "            \"- Use CONTEXT to recall canonical definitions, standard objections, and typical examples.\\n\"\n",
        "            \"- Match each option to the most precise doctrinal description instead of relying on vague intuition.\\n\"\n",
        "        ),\n",
        "    },\n",
        "    \"psychology\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert psychology exam solver. \"\n",
        "            \"You handle cognitive, social, clinical, developmental, and biological psychology.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"When solving PSYCHOLOGY questions:\\n\"\n",
        "            \"- Identify the main subfield (e.g., memory, perception, conditioning, social cognition, development).\\n\"\n",
        "            \"- Pay attention to experimental design details (IV, DV, control, randomization) when present.\\n\"\n",
        "            \"- Use CONTEXT to recall definitions of constructs and classic findings.\\n\"\n",
        "            \"- Carefully distinguish between similar concepts (e.g., classical vs operant conditioning, \"\n",
        "            \"state vs trait, positive vs negative reinforcement).\\n\"\n",
        "        ),\n",
        "    },\n",
        "    \"business\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert business and economics exam solver. \"\n",
        "            \"You handle microeconomics, macroeconomics, corporate finance, accounting, management, and marketing.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"When solving BUSINESS/ECON questions:\\n\"\n",
        "            \"- First identify the main domain (e.g., micro, macro, finance, accounting, management, marketing).\\n\"\n",
        "            \"- Extract the key variables and relationships (e.g., supply/demand shifts, elasticity, NPV, leverage).\\n\"\n",
        "            \"- Use CONTEXT to recall definitions, formulas, and standard qualitative implications.\\n\"\n",
        "            \"- When numbers are given, reason about direction and relative size; compute exactly only if necessary.\\n\"\n",
        "        ),\n",
        "    },\n",
        "}\n",
        "\n",
        "DEFAULT_CATEGORY_META = {\n",
        "    \"role\": (\n",
        "        \"You are an expert exam solver for MMLU-Pro across law, history, philosophy, psychology, and business.\"\n",
        "    ),\n",
        "    \"guidelines\": (\n",
        "        \"Always prioritize the QUESTION text, use the CONTEXT as supporting evidence, \"\n",
        "        \"and compare each option carefully against both.\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "IsbhE45AKGPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_ANS_TMPL = \"\"\"\n",
        "You are an Astute-RAG style expert exam solver for MMLU-Pro.\n",
        "\n",
        "[Category Specialization]\n",
        "{category_role}\n",
        "\n",
        "[Category-Specific Strategy]\n",
        "{category_guidelines}\n",
        "\n",
        "Your goal:\n",
        "- Use BOTH your INTERNAL memorized knowledge and EXTERNAL retrieved documents.\n",
        "- Always prioritize the QUESTION constraints over conflicting evidence.\n",
        "\n",
        "[QUESTION]\n",
        "{question_with_options}\n",
        "\n",
        "Initial Context:\n",
        "{context_init}\n",
        "\n",
        "[Consolidated Context]:\n",
        "{context_con}\n",
        "\n",
        "Astute-RAG Reasoning Procedure:\n",
        "\n",
        "Step 1. Analyze the Question\n",
        "- Identify the core concept and any specific constraints (dates, negation, strict conditions).\n",
        "- If the question asks for the \"BEST\" option, define the criteria for \"best\".\n",
        "\n",
        "Step 2. Process of Elimination (CRITICAL)\n",
        "- For EACH option (A) through (J), explicitly check if it contradicts the Consolidated Context or the Question constraints.\n",
        "- Mark options as [ELIMINATED] if they are factually wrong or irrelevant.\n",
        "- Mark options as [POSSIBLE] if they are supported by evidence.\n",
        "\n",
        "Step 3. Pairwise Comparison & Differentiation (CRITICAL UPDATE)\n",
        "- Look at the options marked [POSSIBLE].\n",
        "- Compare them in pairs (e.g., Option A vs. Option B).\n",
        "- Identify the **ONE distinguishing factor** that separates them (e.g., \"Option A applies to Stage 1, while Option B applies to Stage 2\").\n",
        "- Check this distinguishing factor against the Question's constraints.\n",
        "- If an option fits the context generally but fails the specific distinguishing factor required by the question, ELIMINATE it.\n",
        "\n",
        "Step 4. The \"Devil's Advocate\" Check\n",
        "- Pick your tentative best answer (e.g., Option B).\n",
        "- Ask yourself: \"Why might Option B be WRONG?\" (Look for subtle traps, strict legal definitions, or exceptions).\n",
        "- If the counter-argument is weak, confirm Option B. If it's strong, reconsider the runner-up.\n",
        "\n",
        "Final Output Format:\n",
        "Provide your step-by-step reasoning, and then end with exactly:\n",
        "Final Answer: X\n",
        "(where X is the capital letter of the correct option)\n",
        "\"\"\".strip()\n",
        "\n",
        "p_ans_prompt = ChatPromptTemplate.from_template(P_ANS_TMPL)"
      ],
      "metadata": {
        "id": "33MzDXy6EOGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 살짝 변경\n",
        "def run_p_ans(\n",
        "    context_init: str,\n",
        "    context_con: str,\n",
        "    full_question: str,\n",
        "    category: str,\n",
        "    llm=None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    p_gen/p_con으로 만들어진 context를 기반으로,\n",
        "    astute-RAG 방식(INTERNAL vs EXTERNAL, Step 1~4)을 그대로 따르되,\n",
        "    category별 역할/전략 텍스트를 추가하여 특화된 solver로 동작하게 함.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    meta = CATEGORY_META.get(category, DEFAULT_CATEGORY_META)\n",
        "\n",
        "    msgs = p_ans_prompt.format_messages(\n",
        "        category_role=meta[\"role\"],\n",
        "        category_guidelines=meta[\"guidelines\"],\n",
        "        context_init=context_init,\n",
        "        context_con=context_con,\n",
        "        question_with_options=full_question,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    raw = resp.content.strip()\n",
        "    letter = extract_final_answer_letter(raw)\n",
        "    return {\"final_answer\": letter, \"raw_reasoning\": raw}"
      ],
      "metadata": {
        "id": "qLx-PIdkK167"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from langchain_upstage import ChatUpstage # 혹시 import 안 되어 있을까봐\n",
        "\n",
        "def solve_mmlu_astute_style(\n",
        "    full_prompt: str,\n",
        "    use_wiki: bool = True,\n",
        "    n_vote: int = 5  # [설정] 투표 횟수 (보통 3~5 추천)\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1. Analyze & Retrieval (기존과 동일)\n",
        "    # ---------------------------------------------------------\n",
        "    # 1) 질문/선지 분리\n",
        "    question_text, options = parse_question_and_options(full_prompt)\n",
        "\n",
        "    # 2) 질문 분석 (p_analyze)\n",
        "    # (앞서 추가한 run_p_analyze 함수가 있다고 가정)\n",
        "    try:\n",
        "        analysis = run_p_analyze(question_text, options, llm=llm_solver)\n",
        "        constraints = analysis.get(\"constraints\", [])\n",
        "        search_queries = analysis.get(\"search_queries\", [question_text])\n",
        "    except NameError:\n",
        "        # p_analyze를 아직 정의 안 했다면 기본값 처리\n",
        "        analysis = {}\n",
        "        constraints = []\n",
        "        search_queries = [question_text]\n",
        "\n",
        "    print(f\"   -> [Analysis] Constraints: {constraints[:3]}\")\n",
        "\n",
        "    # 3) Category 분류\n",
        "    category, extracted_keywords = classify_and_extract_keywords(question_text)\n",
        "    if category not in vectorstore:\n",
        "        category = \"business\"\n",
        "\n",
        "    # 4) Retrieval (분석된 쿼리 사용)\n",
        "    combined_query = \" \".join(search_queries)\n",
        "    tb_passages = get_textbook_passages(category, combined_query)\n",
        "\n",
        "    # 위키 검색 (기존 키워드 방식 유지 혹은 쿼리 활용)\n",
        "    # 여기서는 호환성을 위해 기존 로직 + 쿼리 활용\n",
        "    wiki_passages = []\n",
        "    if use_wiki:\n",
        "        # 쿼리에서 명사만 추출하거나, 분석된 쿼리를 사용해 위키 검색\n",
        "        # (편의상 기존 get_wiki_passages 사용 가정)\n",
        "        # Use extracted_keywords from classification for wiki search\n",
        "        wiki_passages = get_wiki_passages(extracted_keywords)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2. Context Building (p_mem -> p_gen -> p_con) (기존과 동일)\n",
        "    # ---------------------------------------------------------\n",
        "    # 5) p_mem: INTERNAL 문서\n",
        "    doc_blocks = []\n",
        "    next_doc_idx = 1\n",
        "\n",
        "    mem_doc_text = run_p_mem(category, question_text)\n",
        "    if mem_doc_text.strip():\n",
        "        doc_blocks.append(\n",
        "            f\"[Doc {next_doc_idx} | SOURCE=INTERNAL(MEMORY)]\\n{mem_doc_text}\"\n",
        "        )\n",
        "        next_doc_idx += 1\n",
        "\n",
        "    # 6) p_gen: TEXTBOOK docs (LLM 없이 Pass-through)\n",
        "    tb_block, next_doc_idx = run_p_gen_for_docs(\n",
        "        category=category,\n",
        "        source_type=\"TEXTBOOK\",\n",
        "        question_text=question_text,\n",
        "        raw_passages=tb_passages,\n",
        "        start_doc_idx=next_doc_idx,\n",
        "        llm=None, # LLM 사용 안 함\n",
        "    )\n",
        "    if tb_block.strip():\n",
        "        doc_blocks.append(tb_block)\n",
        "\n",
        "    # 7) p_gen: WIKIPEDIA docs\n",
        "    if use_wiki and wiki_passages:\n",
        "        wiki_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category=category,\n",
        "            source_type=\"WIKIPEDIA\",\n",
        "            question_text=question_text,\n",
        "            raw_passages=wiki_passages,\n",
        "            start_doc_idx=next_doc_idx,\n",
        "            llm=None,\n",
        "        )\n",
        "        if wiki_block.strip():\n",
        "            doc_blocks.append(wiki_block)\n",
        "\n",
        "    context_init = \"\\n\\n\".join(doc_blocks)\n",
        "\n",
        "    # 8) p_con: consolidation\n",
        "    context_con = run_p_con(\n",
        "        question_text=question_text,\n",
        "        context_init=context_init,\n",
        "        last_context=\"\",\n",
        "    )\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. Voting (Self-Consistency) ★ [여기가 변경됨]\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # 분석된 제약조건을 질문에 포함\n",
        "    constraints_str = \"\\n\".join([f\"- {c}\" for c in constraints])\n",
        "    augmented_question = f\"{full_prompt}\\n\\n[CRITICAL CONSTRAINTS]\\n{constraints_str}\"\n",
        "\n",
        "    # 투표용 LLM (Temperature를 높여서 다양성 확보)\n",
        "    llm_voter = ChatUpstage(\n",
        "        api_key=UPSTAGE_API_KEY,\n",
        "        model=\"solar-pro2\",\n",
        "        temperature=0.7  # 0.5 ~ 0.8 사이 추천\n",
        "    )\n",
        "\n",
        "    votes = []\n",
        "    reasonings = []\n",
        "\n",
        "    print(f\"   -> [Voting] Running {n_vote} iterations...\")\n",
        "\n",
        "    for i in range(n_vote):\n",
        "        try:\n",
        "            # p_ans 실행\n",
        "            ans = run_p_ans(\n",
        "                context_init=context_init,\n",
        "                context_con=context_con,\n",
        "                full_question=augmented_question,\n",
        "                category=category,\n",
        "                llm=llm_voter # Voter LLM 사용\n",
        "            )\n",
        "\n",
        "            letter = ans[\"final_answer\"]\n",
        "            # 유효한 답(A-J)만 투표에 포함\n",
        "            if letter and letter in \"ABCDEFGHIJ\":\n",
        "                votes.append(letter)\n",
        "\n",
        "            reasonings.append(f\"[Run {i+1} Answer: {letter}]\\n{ans['raw_reasoning']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [Error in vote {i}]: {e}\")\n",
        "            continue\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. Result Aggregation\n",
        "    # ---------------------------------------------------------\n",
        "    if not votes:\n",
        "        final_ans = \"A\" # 투표 실패 시 기본값 (혹은 에러 처리)\n",
        "        print(\"   -> [Warn] No valid votes collected.\")\n",
        "    else:\n",
        "        # 최빈값(Mode) 찾기\n",
        "        count = Counter(votes)\n",
        "        final_ans = count.most_common(1)[0][0]\n",
        "\n",
        "        # 투표 현황 로그 출력 (디버깅용)\n",
        "        vote_summary = str(dict(count))\n",
        "        print(f\"   -> [Result] Winner: {final_ans} | Votes: {vote_summary}\")\n",
        "\n",
        "    # Reasoning 로그 합치기 (나중에 분석용)\n",
        "    full_log = \"\\n\" + \"=\"*40 + \"\\n\".join(reasonings)\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": category,\n",
        "        \"analysis\": analysis,\n",
        "        \"keywords\": extracted_keywords, # ADDED THIS LINE\n",
        "        \"context_init\": context_init,\n",
        "        \"context_con\": context_con,\n",
        "        \"raw_reasoning\": full_log, # 모든 투표의 Reasoning을 저장\n",
        "        \"vote_summary\": str(dict(Counter(votes))) if votes else \"None\"\n",
        "    }"
      ],
      "metadata": {
        "id": "KMrStAyL7gBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/testset_100.csv\")\n",
        "QUESTION_COL = \"prompts\"\n",
        "\n",
        "results = []\n",
        "for i, row in df.iterrows():\n",
        "    q = row[QUESTION_COL]\n",
        "    print(f\"[{i}] Solving: {q[:60]}...\")\n",
        "    out = solve_mmlu_astute_style(q)\n",
        "    results.append(out[\"final_answer\"])\n",
        "    df.loc[i, \"pred_category\"] = out[\"category\"]\n",
        "    df.loc[i, \"kw1\"] = out[\"keywords\"][0] if len(out[\"keywords\"]) > 0 else \"\"\n",
        "    df.loc[i, \"kw2\"] = out[\"keywords\"][1] if len(out[\"keywords\"]) > 1 else \"\"\n",
        "    df.loc[i, \"kw3\"] = out[\"keywords\"][2] if len(out[\"keywords\"]) > 2 else \"\"\n",
        "    df.loc[i, \"rag_cot_answer\"] = out[\"final_answer\"]\n",
        "    df.loc[i, \"cot_full\"] = out[\"raw_reasoning\"]\n",
        "\n",
        "df.to_csv(\"astute-rag-1126-final.csv\", index=False)\n",
        "print(\"저장 완료:1126.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwQVpjeR5SG-",
        "outputId": "9eafe434-de21-4b84-f417-ed7b5e91811f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Solving: QUESTION4868) In 1797, John Frere made a discovery that he d...\n",
            "   -> [Analysis] Constraints: ['Must involve John Frere', 'Must be from 1797', 'Must describe his discovery']\n",
            "[Init] Building BM25 index for: history...\n",
            "[Init] BM25 ready for history (17941 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[1] Solving: QUESTION586) BobGafneyand Susan Medina invested $40,000 and ...\n",
            "   -> [Analysis] Constraints: ['Bob Gafney invested $40,000 and receives 4% of net income as manager', 'Susan Medina invested $50,000', 'Each partner receives 6% interest on their investment']\n",
            "[Init] Building BM25 index for: business...\n",
            "[Init] BM25 ready for business (6285 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 4, 'C': 1}\n",
            "[2] Solving: QUESTION138) If at the beginning of each month a deposit of ...\n",
            "   -> [Analysis] Constraints: ['Deposits of $500 made monthly', 'Interest rate of 8% compounded monthly', 'Time period of exactly five years']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'D': 1, 'E': 3, 'A': 1}\n",
            "[3] Solving: QUESTION520) George and Richard Martin, partners in a law fi...\n",
            "   -> [Analysis] Constraints: ['Must calculate percentage increase', 'Current rent: $6300 annually', 'New rent: $715 monthly']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[4] Solving: QUESTION1326) A large privately owned and operated shopping ...\n",
            "   -> [Analysis] Constraints: ['Mall is privately owned and operated', 'Protesters were peaceful and did not interfere with traffic', 'First and Fourteenth Amendment rights claimed']\n",
            "[Init] Building BM25 index for: law...\n",
            "[Init] BM25 ready for law (91859 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[5] Solving: QUESTION1769) A farmer owned a 40-acre tract of farmland loc...\n",
            "   -> [Analysis] Constraints: ['Must involve a lease agreement with an option to purchase real property', 'Must consider the Statute of Frauds and parol evidence rule applicability', \"Must address whether the farmer's unfulfilled survey promise affects enforceability\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[6] Solving: QUESTION1200) Is the recognition of foreign judgments subjec...\n",
            "   -> [Analysis] Constraints: ['Focus on legal doctrines (monism, dualism, incorporation, transformation)', 'Compare foreign judgment recognition to treaty incorporation/transformation', 'Exclude automatic enforcement without process (F) unless supported by doctrine']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 4, 'B': 1}\n",
            "[7] Solving: QUESTION1163) A mechanic agreed in writing to make repairs t...\n",
            "   -> [Analysis] Constraints: ['Must analyze enforceability of contract modification', 'Must consider elements of duress or undue influence', 'Must evaluate relationship between original contract terms and modified agreement']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[8] Solving: QUESTION10832) Mani referred to God by which of the followin...\n",
            "   -> [Analysis] Constraints: ['Must be a name used by Mani', 'Must refer to God in Manichaean theology', 'Must be one of the provided options (A-J)']\n",
            "[Init] Building BM25 index for: philosophy...\n",
            "[Init] BM25 ready for philosophy (54977 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[9] Solving: QUESTION10952) Construct a complete truth table for the foll...\n",
            "   -> [Analysis] Constraints: ['Must analyze the argument ~C ⊃ D, D ⊃ C ⊢ C', 'Must use truth table evaluation', 'Must identify counterexample if argument is invalid']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[10] Solving: QUESTION2449) Dr. Ryan is a psychotherapist in a small town....\n",
            "   -> [Analysis] Constraints: ['Psychotherapist-client boundary issues', 'Past sexual relationship between therapist and potential client', 'Ethical considerations for professional objectivity']\n",
            "[Init] Building BM25 index for: psychology...\n",
            "[Init] BM25 ready for psychology (2232 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[11] Solving: QUESTION1979) A landscaper agreed to maintain the yard of a ...\n",
            "   -> [Analysis] Constraints: ['Contract duration: six months', 'Fee: $300 per month, payable at the end of six months', 'Work performed: four months before breach']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[12] Solving: QUESTION10850) One objection to Singer’s theory that he cons...\n",
            "   -> [Analysis] Constraints: ['Must be an objection Singer explicitly considers', \"Must relate to Peter Singer's ethical theory\", 'Must be one of the provided options (A-J)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'E': 2, 'J': 3}\n",
            "[13] Solving: QUESTION1422) A company offered to sell several loads of lan...\n",
            "   -> [Analysis] Constraints: [\"Must consider the legal validity of the offeree's initial notification as acceptance\", \"Must evaluate the impact of the offeree's modified acceptance form\", \"Must assess the effect of the offeree's verbal rejection and return of goods\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[14] Solving: QUESTION2277) Child abuse and neglect are most associated wi...\n",
            "   -> [Analysis] Constraints: ['Must relate to child abuse and neglect', 'Must select from provided attachment pattern options', 'Must identify the strongest empirical association']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[15] Solving: QUESTION2368) What are the two principal explanations for th...\n",
            "   -> [Analysis] Constraints: ['Must relate to short-term memory limitations', 'Must select two principal explanations from given options', 'Must exclude explanations not directly tied to capacity limits']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[16] Solving: QUESTION4834) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Must be a topic NOT mentioned in the provided excerpt', 'Must be one of the listed options (A-J)', 'Analysis must be based solely on the given text']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[17] Solving: QUESTION11011) I don't understand why everyone thinks they b...\n",
            "   -> [Analysis] Constraints: ['Must be one of the four listed fallacies (A-D)', \"Analysis must focus on the argument's logical structure\", \"Must NOT evaluate the argument's factual claims\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'D': 2, 'C': 3}\n",
            "[18] Solving: QUESTION2054) What are the assumptions concerning an individ...\n",
            "   -> [Analysis] Constraints: ['Must relate to projective testing theory', 'Must focus on unconscious personality elements', 'Must exclude conscious-only or fixed-trait assumptions']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[19] Solving: QUESTION373) Mr. Joseph Miles and Mr. Gary Rose are partners...\n",
            "   -> [Analysis] Constraints: ['Mr. Miles receives a $600 monthly salary (total $7,200 annually)', 'Remaining profits after salary are split equally between partners', 'Total profits for the year are $6,000']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'J': 2, 'C': 3}\n",
            "[20] Solving: QUESTION5041) What does Australia have in common with the re...\n",
            "   -> [Analysis] Constraints: ['Must pertain to the Holocene epoch', 'Must apply to Australia and global regions', 'Must exclude events unique to Australia (e.g., megafauna extinction)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[21] Solving: QUESTION4751) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: [\"Must relate to the 'Winter King' (Frederick V of the Palatinate)\", \"Must connect to the Thirty Years' War (1618–1648) or Defenestration of Prague (1618)\", 'Must explain why the narrator warns the Winter King to stay away from these locations']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[22] Solving: QUESTION11192) Select the best translation into predicate lo...\n",
            "   -> [Analysis] Constraints: ['Must represent universal quantification', 'Must express subset relationship (robots ⊆ artifacts)', 'Must use proper logical connectives (⊃, •, ∨, ⊂)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[23] Solving: QUESTION109) Mr. Castle will buy one of two 10-HP motors off...\n",
            "   -> [Analysis] Constraints: ['Motor A: $169 price, 85.2% efficiency', 'Motor B: $149 price, 82.1% efficiency', 'Annual maintenance fee: 14.5% of purchase price']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'E': 1, 'I': 1, 'B': 1, 'J': 2}\n",
            "[24] Solving: QUESTION4994) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Focus on military technology development (gunpowder weaponry)', 'Compare Europe (1200s-1400s) and China (post-1300s)', 'Address differing military threats (siege warfare vs. steppe nomads)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[25] Solving: QUESTION2631) Group A consists of people whose measured inte...\n",
            "   -> [Analysis] Constraints: ['Group A has interests highly similar to engineers', 'Group B has interests highly dissimilar to engineers', 'Both groups entered engineering']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[26] Solving: QUESTION4942) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: [\"Must relate to Federalist #15's themes (weakness of Articles of Confederation, need for stronger central government)\", 'Must involve a historical event or policy that undermined U.S. sovereignty or unity under the Articles of Confederation', 'Must be one of the listed options (A-J)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 3, 'D': 1, 'H': 1}\n",
            "[27] Solving: QUESTION1114) A defendant hated a victim and decided to kill...\n",
            "   -> [Analysis] Constraints: ['Jurisdiction defines first-degree murder as premeditated and deliberate killing', 'All other forms of murder are second-degree murder', 'Defendant had prior intent to kill the victim']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[28] Solving: QUESTION287) An automobile that cost $3,000 four years ago i...\n",
            "   -> [Analysis] Constraints: ['Time period of 4 years', 'Initial value of $3,000', 'Final value of $1,000']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[29] Solving: QUESTION4765) Which of the following is the Pleistocene ice ...\n",
            "   -> [Analysis] Constraints: ['Must be a Pleistocene ice mass', 'Must be located in North America', 'Must be centered in the Rocky Mountains']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[30] Solving: QUESTION4886) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: [\"Must align with Logan's Address themes (vengeance, sovereignty, grievances against white settlers)\", 'Must reflect early U.S. historical context (post-1774, pre-1800s)', \"Must exclude policies contradicting Logan's emphasis on territorial rights and autonomy\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[31] Solving: QUESTION644) An invoice of $10,000 is marked (6/10), (n/30)....\n",
            "   -> [Analysis] Constraints: ['Must use the discount term (6/10), n/30', 'Must calculate APR based on the given invoice amount ($10,000)', 'Must follow standard financial formulas for APR calculation in credit terms']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[32] Solving: QUESTION10783) Ashford's article is meant to address a parti...\n",
            "   -> [Analysis] Constraints: [\"Must relate to Ashford's article\", 'Must identify a form of ethical paralysis', \"Must align with Singer's arguments or global poverty/ethics context\"]\n",
            "[WARN] No JSON braces found.\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[33] Solving: QUESTION1601) A federal statute provides states with funds f...\n",
            "   -> [Analysis] Constraints: ['Focus on sovereign immunity and federal funding conditions', 'Consider Eleventh Amendment implications for federal vs. state lawsuits', 'Analyze congressional power to impose conditions on federal funds']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 4, 'E': 1}\n",
            "[34] Solving: QUESTION11104) All things that are spoiled are inedible. Tim...\n",
            "   -> [Analysis] Constraints: ['Must be a type of logical fallacy', 'Must analyze the structure of the argument', \"Must consider the meaning of 'spoiled' in different contexts\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[35] Solving: QUESTION10914) Carens's main conclusion is that \n",
            "(A) liberal...\n",
            "   -> [Analysis] Constraints: [\"Must focus on Carens's conclusion\", \"Must relate to liberal egalitarianism's stance on immigration, borders, or cosmopolitanism\", \"Must exclude options contradicting Carens's actual arguments (e.g., closed borders, anti-immigration sentiments, envy-based egalitarianism)\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[36] Solving: QUESTION507) assume you are Indonesian. In 2010, the rupiah ...\n",
            "   -> [Analysis] Constraints: ['Must use 2010 as the base year with CPI = 100 for both countries', \"Must account for Indonesia's CPI rising to 105 (5% inflation) by 2019\", 'Must account for US CPI rising to 110 (10% inflation) by 2019']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 4, 'E': 1}\n",
            "[37] Solving: QUESTION1271) Two men held-up a liquor store in a city. Duri...\n",
            "   -> [Analysis] Constraints: [\"Jurisdiction's statute of limitations for murder is five years\", 'Delay between crime and indictment was 5 months', 'Prosecutor delayed indictment to identify accomplice']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[38] Solving: QUESTION1647) Liang, a talented student from another country...\n",
            "   -> [Analysis] Constraints: ['Focus on U.S. constitutional law (Equal Protection Clause, state powers)', 'Context is public education employment', 'Must address non-citizen vs. citizenship requirements']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[39] Solving: QUESTION11239) Zhuangzi describes a state as ziran, which me...\n",
            "   -> [Analysis] Constraints: [\"Must relate to Zhuangzi's philosophy\", \"Must define 'ziran'\", 'Must select from provided options (A-J)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[40] Solving: QUESTION2386) Which of the following strategies would probab...\n",
            "   -> [Analysis] Constraints: ['Must evaluate effectiveness of strategies for reducing child aggressiveness', 'Must compare all four listed options (A-D)', 'Must identify the least effective strategy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[41] Solving: QUESTION2615) Which of the following statements expresses a ...\n",
            "   -> [Analysis] Constraints: ['Must focus on aging and sexual functioning relationship', 'Must select from provided options (A-H)', 'Must reflect scientifically accurate physiological changes']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[42] Solving: QUESTION5019) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Must involve criticism of unchecked executive/authority power', 'Must reference a twentieth-century U.S. political event or figure', 'Must involve civil liberties or rights violations']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 3, 'H': 2}\n",
            "[43] Solving: QUESTION271) Consider an arbitrage-free securities market mo...\n",
            "   -> [Analysis] Constraints: ['Arbitrage-free market model', 'Constant risk-free interest rate', 'Stock price processes follow geometric Brownian motion with same Brownian motion driver']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 4, 'B': 1}\n",
            "[44] Solving: QUESTION10881) \"The minor premise must affirm the antecedent...\n",
            "   -> [Analysis] Constraints: ['Must relate to logical argument structures', 'Must involve antecedent/consequent analysis', 'Must match the specific validity rule provided']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[45] Solving: QUESTION1485) Hume's attack on natural law is founded on his...\n",
            "[WARN] p_analyze failed: Expecting ',' delimiter: line 4 column 3 (char 347)\n",
            "   -> [Analysis] Constraints: []\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[46] Solving: QUESTION11210) Baier argues that genuine moral rules: \n",
            "(A) m...\n",
            "   -> [Analysis] Constraints: [\"Must reference Baier's moral philosophy\", 'Must select from provided options (A-J)', 'Must identify a necessary condition for genuine moral rules']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[47] Solving: QUESTION2519) Babbling ordinarily begins at about 4 to 5 mon...\n",
            "   -> [Analysis] Constraints: ['Age range: 4 to 5 months', 'Initial babbling stage', 'Excludes morphemes/words']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[48] Solving: QUESTION2055) Have studies on learning supported the Increme...\n",
            "   -> [Analysis] Constraints: ['Focus on empirical studies', 'Compare Incremental vs. One-trial theories', 'Consider task type (cognitive/motor/simple/complex)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[49] Solving: QUESTION962) A plaintiff sued a defendant for injuries that ...\n",
            "   -> [Analysis] Constraints: ['Jurisdiction with a statute requiring motorists to stop for pedestrians in crosswalks', \"Testimony about plaintiff's general habit of crossing outside crosswalks\", 'Evidence admissibility under relevant legal standards']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'D': 1, 'H': 4}\n",
            "[50] Solving: QUESTION10806) According to Kant, nothing can be called “goo...\n",
            "   -> [Analysis] Constraints: [\"Must be Kant's specific philosophical claim\", \"Must reference 'good without qualification'\", 'Must exclude conditional goods']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[51] Solving: QUESTION4708) Conflict models emphasize the importance of __...\n",
            "   -> [Analysis] Constraints: ['Must distinguish between conflict and integration models', 'Must specify tensions emphasized by each model', 'Must select from provided option pairs']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 3, 'E': 2}\n",
            "[52] Solving: QUESTION2337) For deception in an experiment to be permissib...\n",
            "   -> [Analysis] Constraints: ['Must relate to ethical guidelines for deception in research', 'Must identify a necessary condition for permissible deception', 'Must exclude incorrect ethical requirements (e.g., specific timeframes for explanation, participant requests for revelation)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[53] Solving: QUESTION10878) Which branch of Judaism founded by Zacharias ...\n",
            "   -> [Analysis] Constraints: ['Founded by Zacharias Frankel', \"Known for 'Positive-Historical Judaism'\", 'Must be a branch of Judaism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[54] Solving: QUESTION1642) A homeowner conveyed his property to his cousi...\n",
            "   -> [Analysis] Constraints: [\"Must involve property conveyed 'for life with remainder to heirs'\", \"Must address validity of life tenant's subsequent conveyance\", 'Must resolve conflict between life estate and vested remainder']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'C': 2, 'D': 3}\n",
            "[55] Solving: QUESTION4938) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Must relate to economic consequences of U.S. entry into WWII post-Pearl Harbor', 'Must align with historical timeline (post-1941)', 'Must exclude options describing negative U.S. economic outcomes (e.g., depression, recession)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[56] Solving: QUESTION2663) Some contemporary intelligence researchers lik...\n",
            "   -> [Analysis] Constraints: ['Must involve criticism from Howard Gardner and/or Robert Sternberg', 'Must relate to school curricula or teaching methods', 'Must be a specific focus area (subject/method)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[57] Solving: QUESTION1569) In 1993, a rancher had good record title to a ...\n",
            "   -> [Analysis] Constraints: ['Jurisdiction uses Grantor-Grantee Indices, no Tract Index', \"Recording act states: 'Every conveyance... shall be invalid... unless recorded'\", 'Analysis must consider notice types (race, notice, race-notice jurisdictions)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 4, 'J': 1}\n",
            "[58] Solving: QUESTION2483) Trace language development during preschool ag...\n",
            "   -> [Analysis] Constraints: ['Must focus on preschool age (typically 3-5 years)', 'Must describe actual language development milestones', \"Must exclude incorrect or exaggerated claims (e.g., 'entirely new language spontaneously', 'language development regresses')\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 4, 'G': 1}\n",
            "[59] Solving: QUESTION862) The following entries appeared in the ledgers o...\n",
            "   -> [Analysis] Constraints: ['Must use Beginning Inventory ($16,000)', 'Must use Purchases ($58,000)', 'Must use Ending Inventory ($14,000)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[60] Solving: QUESTION283) Steve King buys dress slacks on sale at $33.15 ...\n",
            "   -> [Analysis] Constraints: ['Price per two pairs: $33.15', 'Sales tax: 5.5%', 'Quantity: four pairs']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[61] Solving: QUESTION4839) At its peak, the population of the city of Teo...\n",
            "   -> [Analysis] Constraints: [\"Must refer to Teotihuacán's peak population\", 'Must be a historical estimate', 'Exclude modern or projected populations']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[62] Solving: QUESTION769) Calculate the Gross Domestic Product using the ...\n",
            "   -> [Analysis] Constraints: ['Must use the total expenditure approach (GDP = C + I + G + (X - M))', 'Exclude non-expenditure components (e.g., Wages and salaries, Taxes)', 'Units must be in billions of dollars']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[63] Solving: QUESTION11245) When was the major shift by Greek philosopher...\n",
            "   -> [Analysis] Constraints: ['Must involve Greek philosophers', 'Must reference rejection of anthropomorphic divine concepts', 'Must specify a historical time period from provided options']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[64] Solving: QUESTION1360) A wife and husband are married and own a dairy...\n",
            "   -> [Analysis] Constraints: ['Property ownership type: Tenants by the entirety', 'Transfer method: Quitclaim deed', 'Jurisdiction: Common law property principles (US/UK)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 5}\n",
            "[65] Solving: QUESTION2526) Jupiter pilots his newly created perfectionism...\n",
            "   -> [Analysis] Constraints: ['Same test administered twice', 'Same group of students', 'One-month interval']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[66] Solving: QUESTION11137) Naturalists who concentrated on natural eleme...\n",
            "   -> [Analysis] Constraints: ['Must be one of the listed options (A-J)', 'Must emphasize natural elements/processes', 'Excludes human-centric or ritual-focused traditions']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[67] Solving: QUESTION2318) How does the study of stereotyping relate to a...\n",
            "   -> [Analysis] Constraints: ['Must relate stereotyping and attribution theory', 'Must select from provided options (A-J)', 'Must avoid incorrect equivalences or contradictions']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[68] Solving: QUESTION2052) How is incoming sensory verbal information abs...\n",
            "   -> [Analysis] Constraints: ['Focus on sensory verbal information', 'Classification mechanism by the nervous system', 'Exclude non-verbal sensory processing']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 3, 'E': 2}\n",
            "[69] Solving: QUESTION2643) Research into ___________ has helped us unders...\n",
            "   -> [Analysis] Constraints: ['Must be a research topic from the provided list (A-I)', 'Directly linked to paradoxical reward mechanisms']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 4, 'H': 1}\n",
            "[70] Solving: QUESTION2694) Which of the following is not an available too...\n",
            "   -> [Analysis] Constraints: ['Must select one option that is NOT a suicide risk assessment tool', 'Answer must be among the provided options (A-J)', 'Requires knowledge of validated suicide risk assessment instruments']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[71] Solving: QUESTION4726) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Must involve Sukarno and other leaders from Africa, Asia, and the Middle East', 'Must refer to a conflict where neutrality was attempted but not fully achieved', \"Must align with Sukarno's historical context (1955 Bandung Conference and Cold War era)\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 4, 'A': 1}\n",
            "[72] Solving: QUESTION967) A city imposes a municipal excise tax of $200 p...\n",
            "   -> [Analysis] Constraints: ['Must involve municipal excise tax on commercial artists/studios and itinerant figure drawers', 'Must consider credit mechanism for taxes paid on studio maintenance', 'Must address interstate commerce implications (gallery located in neighboring state)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[73] Solving: QUESTION290) On October 17, Thomas Long purchased two $1,000...\n",
            "   -> [Analysis] Constraints: ['Bonds purchased on October 17', 'Two $1,000 bonds', '6% interest payable January 1 and July 1']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 4, 'J': 1}\n",
            "[74] Solving: QUESTION623) ____________ describes the extrinsic properties...\n",
            "   -> [Analysis] Constraints: ['Must relate to extrinsic product attributes', 'Must address psychological/social needs', 'Must be a branded marketing concept']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 4, 'B': 1}\n",
            "[75] Solving: QUESTION1009) A developer is the owner of a parcel of land i...\n",
            "   -> [Analysis] Constraints: ['Fee simple absolute ownership initially held by the developer', 'Notice jurisdiction applies (race-notice statute)', 'All grantees paid value and had no actual or inquiry notice']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[76] Solving: QUESTION4741) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Must be a U.S. president from the provided list (A-J)', \"Must align with Coolidge's principles of limited government taxation, property rights, and fiscal restraint\", 'Excludes presidents known for expansive government spending or progressive taxation policies']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[77] Solving: QUESTION425) What is the date of maturity of a 60-day note d...\n",
            "   -> [Analysis] Constraints: ['Must calculate 60 days from March 15', 'Must account for month-end date transitions (e.g., March has 31 days)', 'Must exclude weekends/holidays unless specified']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[78] Solving: QUESTION10932) E.F. Schumacher, famous economist, in an arti...\n",
            "   -> [Analysis] Constraints: [\"Must analyze Schumacher's quote from the Atlantic (April 1979)\", 'Must identify a fallacy from given options (A-D)', 'Focus on rhetorical technique in technology terminology debate']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[79] Solving: QUESTION1205) A landlord is the owner in fee simple of a tra...\n",
            "   -> [Analysis] Constraints: ['Lease term: August 1, 2001 - July 31, 2008', \"Fire occurred after dentist's possession (post-2005)\", \"Insurance lapse occurred after tenant's assignment to doctor\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: H | Votes: {'H': 3, 'C': 2}\n",
            "[80] Solving: QUESTION4715) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: [\"Must focus on Logan's stated perspective in the passage\", 'Must exclude interpretations not directly supported by the text', \"Must consider Logan's described actions and emotional state\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[81] Solving: QUESTION11042) Richardson-Self argues that sexist speech \n",
            "(A...\n",
            "   -> [Analysis] Constraints: [\"Must reflect Richardson-Self's specific argument\", 'Must address the relationship between sexist speech and hate speech', 'Must consider context, violence, and discrimination as factors']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 4, 'D': 1}\n",
            "[82] Solving: QUESTION4923) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Must relate to Ming Dynasty (1368–1644 C.E.)', 'Must involve foreign trade policies', 'Must exclude policies from other dynasties (e.g., Yuan, Qing)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[83] Solving: QUESTION240) Daniel receives at 6.5% commission on all sales...\n",
            "   -> [Analysis] Constraints: ['Commission rate is exactly 6.5%', 'Commission amount is $275.08', 'Answer must be one of the provided numerical options']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 4, 'E': 1}\n",
            "[84] Solving: QUESTION11017) According to Hobbes, the definition of injust...\n",
            "   -> [Analysis] Constraints: [\"Must reflect Thomas Hobbes's specific view\", 'Must align with his political/social contract theory', 'Excludes non-Hobbesian concepts (e.g., inherent rights, divine law)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'J': 2, 'A': 3}\n",
            "[85] Solving: QUESTION1286) Which of the following criticisms of Llewellyn...\n",
            "   -> [Analysis] Constraints: [\"Must critique Llewellyn's grand/formal style distinction\", \"Must evaluate which criticism is 'most compelling'\", 'Must align with legal reasoning theory']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[86] Solving: QUESTION4871) A subsistence strategy and settlement pattern ...\n",
            "   -> [Analysis] Constraints: ['Must involve seasonality', 'Must involve planned resource acquisition', 'Must be a recognized anthropological/archaeological subsistence strategy']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 3, 'I': 2}\n",
            "[87] Solving: QUESTION4878) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: ['Response must be from FDR, not Long', \"Must relate to FDR's reaction to Long's wealth redistribution ideas\", 'Timeframe: 1934 or later (post-radio address)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[88] Solving: QUESTION4724) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: [\"Must focus on Wiesel's assertion about remembering the Holocaust\", \"Must relate to the German people's relationship with their history\", 'Must exclude options implying forgiveness, revenge, or Jewish-centric necessity']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[89] Solving: QUESTION4898) This question refers to the following informat...\n",
            "   -> [Analysis] Constraints: [\"Must refer to the time period of Thucydides' writing (ca. 415 B.C.E.)\", 'Must align with Athenian democracy practices of the 5th century BCE', 'Excludes non-citizens, women, and minors based on historical context']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 5}\n",
            "[90] Solving: QUESTION936) A defendant, an indigent, was arrested and char...\n",
            "   -> [Analysis] Constraints: ['Must address constitutional burden of proof for mental incompetency', \"Must consider ineffective assistance of counsel claims due to defendant's paranoia\", 'Must evaluate appeal options (granted/denied) based on legal standards']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[91] Solving: QUESTION2056) When an adult mouse or bird is castrated, its ...\n",
            "   -> [Analysis] Constraints: ['Focus on sexual behavior post-castration', 'Compare higher primates (e.g., humans) with less developed animals (e.g., mice, birds)', 'Consider timing of castration (pre- vs post-puberty/maturity)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 4, 'J': 1}\n",
            "[92] Solving: QUESTION246) Costs for producing one widget: Materials:2 par...\n",
            "   -> [Analysis] Constraints: ['Must use provided cost data (materials: $50, expenses: $10, labor: $100)', 'Must calculate total cost ($160) and cost proportions', 'Must avoid unsupported assumptions about operations/parts count']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[93] Solving: QUESTION11274) The universe, like a watch, must have a maker...\n",
            "   -> [Analysis] Constraints: ['Must be a type of logical fallacy', 'Related to analogy or causation reasoning', 'Must match common fallacy classifications']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[94] Solving: QUESTION2234) What is higher-order (second-order)conditionin...\n",
            "   -> [Analysis] Constraints: ['Must relate to conditioning theory', 'Must distinguish from first-order conditioning', 'Must involve neutral/conditioned stimuli pairing']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[95] Solving: QUESTION307) The enforcement of company privacy is complex a...\n",
            "   -> [Analysis] Constraints: ['First blank must describe corporate structural characteristics (e.g., boundaryless/public/private spaces)', 'Second blank must relate to information management challenges (control information OR maintain individual privacy)', 'Third blank must specify spatial context of corporate activities (public/private spaces)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[96] Solving: QUESTION208) You are asked to determine the price of a Europ...\n",
            "   -> [Analysis] Constraints: ['Must use Black-Scholes framework', 'European put option', 'Stock price = $100']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'C': 1, 'I': 4}\n",
            "[97] Solving: QUESTION2604) Given the following set of ungrouped measureme...\n",
            "   -> [Analysis] Constraints: ['Measurements are ungrouped', 'Dataset: 3, 5, 6, 6, 7, 9', 'Must compute mean, median, and mode']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 5}\n",
            "[98] Solving: QUESTION10970) What does \"Mahavira\" mean? \n",
            "(A) \"Peaceful War...\n",
            "   -> [Analysis] Constraints: [\"Must relate to the etymology or meaning of 'Mahavira'\", 'Must be one of the given options (A-J)', 'Relevant to Jainism or historical/religious context of the term']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[99] Solving: QUESTION468) On October 25 RalphMuffetaccepted a draft for $...\n",
            "   -> [Analysis] Constraints: ['Draft amount: $620', 'Draft dated October 10, accepted October 25', 'Due 3 months after sight']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 3, 'C': 2}\n",
            "저장 완료:1126.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로\n",
        "GT_PATH = \"/content/testset_100.csv\"        # 정답 파일\n",
        "PRED_PATH = \"/content/drive/MyDrive/nlp team project/astute-rag-1126-final.csv\"       # 출력 파일\n",
        "\n",
        "# 2. 컬럼 이름\n",
        "GT_COL = \"answers\"               # testset.csv에서 정답 컬럼\n",
        "PRED_COL = \"rag_cot_answer\"      # baseline.csv에서 예측 컬럼\n",
        "\n",
        "# 3. csv 로드\n",
        "gt_df = pd.read_csv(GT_PATH)\n",
        "pred_df = pd.read_csv(PRED_PATH)\n",
        "\n",
        "# 4. Series 추출\n",
        "gt = gt_df[GT_COL].astype(str)\n",
        "pred = pred_df[PRED_COL].astype(str)\n",
        "\n",
        "# 5. 정규화 함수\n",
        "def normalize_choice(x: str) -> str:\n",
        "    x = x.strip().upper()\n",
        "    for ch in x:\n",
        "        if \"A\" <= ch <= \"Z\":\n",
        "            return ch\n",
        "    return x\n",
        "\n",
        "# 인덱스 리셋이 포인트\n",
        "gt_norm = gt.apply(normalize_choice).reset_index(drop=True)\n",
        "pred_norm = pred.apply(normalize_choice).reset_index(drop=True)\n",
        "\n",
        "print(len(gt_norm), len(pred_norm))  # 둘 다 25 나오는지 체크 한번 해보고\n",
        "\n",
        "# 6. 정확도 계산\n",
        "correct = (gt_norm == pred_norm)\n",
        "accuracy = correct.mean()\n",
        "\n",
        "print(f\"총 문제 수: {len(gt_norm)}\")\n",
        "print(f\"정답 개수: {correct.sum()}\")\n",
        "print(f\"정확도: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "6j_LVA6_5FyW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a2eefaf-00c3-4fe6-d811-aff0f3311b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 100\n",
            "총 문제 수: 100\n",
            "정답 개수: 66\n",
            "정확도: 66.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 testset.csv"
      ],
      "metadata": {
        "id": "V81fETNv5sqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"testset.csv\")[25:]  # 질문, 선택지 다 합쳐진 컬럼 가정\n",
        "QUESTION_COL = \"prompts\"\n",
        "\n",
        "results = []\n",
        "for i, row in df.iterrows():\n",
        "    q = row[QUESTION_COL]\n",
        "    print(f\"[{i}] Solving: {q[:60]}...\")\n",
        "    out = solve_mmlu_astute_style(q)\n",
        "    results.append(out[\"final_answer\"])\n",
        "    df.loc[i, \"pred_category\"] = out[\"category\"]\n",
        "    df.loc[i, \"kw1\"] = out[\"keywords\"][0] if len(out[\"keywords\"]) > 0 else \"\"\n",
        "    df.loc[i, \"kw2\"] = out[\"keywords\"][1] if len(out[\"keywords\"]) > 1 else \"\"\n",
        "    df.loc[i, \"kw3\"] = out[\"keywords\"][2] if len(out[\"keywords\"]) > 2 else \"\"\n",
        "    df.loc[i, \"rag_cot_answer\"] = out[\"final_answer\"]\n",
        "    df.loc[i, \"cot_full\"] = out[\"raw_reasoning\"]\n",
        "\n",
        "df.to_csv(\"baseline-1126-llmreranker.csv\", index=False)\n",
        "print(\"저장 완료:baseline-1126.csv\")"
      ],
      "metadata": {
        "id": "_uFFQoQp5u4s",
        "outputId": "57da7eb2-6774-4069-afa8-88ecd505d2b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25] Solving: QUESTION26) QUESTION 6) A psychologist is asked to see a 10-...\n",
            "   -> [Analysis] Constraints: ['Must involve a 10-year-old child', 'Must occur in a school setting', 'Must adhere to ethical responsibilities for psychologists']\n",
            "[Init] Building BM25 index for: psychology...\n",
            "[Init] BM25 ready for psychology (2232 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 4, 'A': 1}\n",
            "[26] Solving: QUESTION27) A man is at home in his apartment, alone, late a...\n",
            "   -> [Analysis] Constraints: ['Must involve common law crimes', 'Must consider breaking into the apartment (burglary)', 'Must consider threat with a gun during theft (robbery)']\n",
            "[Init] Building BM25 index for: law...\n",
            "[Init] BM25 ready for law (91859 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 5}\n",
            "[27] Solving: QUESTION28) What do Homo sapiens and Australopithecus afaren...\n",
            "   -> [Analysis] Constraints: ['Answer must be one of the provided options (A-J)', 'Focus on verifiable biological, behavioral, or anatomical similarities', 'Exclude incorrect options through comparative analysis of both species']\n",
            "[Init] Building BM25 index for: history...\n",
            "[Init] BM25 ready for history (17941 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[28] Solving: QUESTION29)This question refers to the following information...\n",
            "   -> [Analysis] Constraints: ['Must relate to Tang dynasty (750 C.E.)', 'Must address relations with western nomadic/frontier peoples', \"Must align with themes in Du Fu's poem (military burden, frontier unrest, imperial expansion)\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 4, 'B': 1}\n",
            "[29] Solving: QUESTION30)Homo erectus differed from Homo habilis in which ...\n",
            "   -> [Analysis] Constraints: ['Comparison must be between Homo erectus and Homo habilis', 'Exclude incorrect traits (e.g., bipedalism, tool use, herbivory, geographic exclusivity)', 'Focus on validated differences (brain size, body size, lifespan, fossil distribution)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[30] Solving: QUESTION31)During the manic phase of a bipolar disorder, ind...\n",
            "   -> [Analysis] Constraints: ['Must relate to manic phase of bipolar disorder', 'Must select from given options (A-G)', 'Must reflect DSM-5 or clinical diagnostic criteria for mania']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[31] Solving: QUESTION32) This question refers to the following informatio...\n",
            "   -> [Analysis] Constraints: [\"Must reference Georges Clemenceau's 1930 text 'Grandeur and Misery of Victory'\", \"Must analyze the quoted passage about Germany's 'excess of candour' and 'Deutschland über alles'\", \"Must avoid interpretations contradicting the text's explicit claims\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 4, 'G': 1}\n",
            "[32] Solving: QUESTION33) You receive a phone call from Hermann H., age 28...\n",
            "   -> [Analysis] Constraints: ['Must adhere to ethical guidelines for psychologists', 'Cannot discriminate based on political views', \"Must prioritize client's therapeutic needs\"]\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[33] Solving: QUESTION34) During the second stage of Kohlberg’s preconvent...\n",
            "   -> [Analysis] Constraints: ['Must relate to Kohlberg’s preconventional level', 'Must specify the second stage', 'Must align with developmental psychology theory']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[34] Solving: QUESTION35)  In satisfying Kant's Humanity formulation of th...\n",
            "   -> [Analysis] Constraints: [\"Must relate to Kant's Humanity formulation\", 'Must be a general goal', \"Must be paired with promoting others' permissible ends\"]\n",
            "[Init] Building BM25 index for: philosophy...\n",
            "[Init] BM25 ready for philosophy (54977 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[35] Solving: QUESTION36) Aristotle says  that what makes things be what t...\n",
            "   -> [Analysis] Constraints: [\"Must align with Aristotle's philosophy (NOT Plato's)\", 'Essence/form must NOT exist independently of individuals', 'Answer must address destruction of all species members']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[36] Solving: QUESTION37) The ________ School of jurisprudence believes th...\n",
            "   -> [Analysis] Constraints: ['Must be a recognized school of jurisprudence', 'Focus on historical/social evolution of law', 'Excludes schools emphasizing coercion, morality, or textual analysis']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[37] Solving: QUESTION38) A woman was standing in the aisle of a subway ca...\n",
            "   -> [Analysis] Constraints: ['Jurisdiction follows common law definitions of criminal offenses', \"Man took purse without owner's consent\", 'Force was used after taking possession but before fleeing']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 4, 'I': 1}\n",
            "[38] Solving: QUESTION39) A defendant met her friend at the electronics st...\n",
            "   -> [Analysis] Constraints: ['Defendant was unaware of the stolen item initially', 'Defendant planned to return the item but later changed her mind', 'Focus on post-discovery actions (decision to keep)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 5}\n",
            "[39] Solving: QUESTION40)____________ refers to a strategic process involv...\n",
            "   -> [Analysis] Constraints: ['Must involve stakeholder assessment', 'Must focus on long-term customer relationships', 'Must include environmental maintenance/support/enhancement']\n",
            "[Init] Building BM25 index for: business...\n",
            "[Init] BM25 ready for business (6285 docs)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 3, 'I': 1, 'D': 1}\n",
            "[40] Solving: QUESTION41)This question refers to the following information...\n",
            "   -> [Analysis] Constraints: ['Must relate to both The Epic of Gilgamesh (Tablet VII) and The Maxims of Ptahhotep', 'Must focus on religious context as implied by the question stem', 'Must exclude options unrelated to afterlife, morality, or divine judgment']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[41] Solving: QUESTION42) Is the recognition of foreign judgments subject ...\n",
            "   -> [Analysis] Constraints: ['Focus on legal doctrines (monism, dualism, incorporation, transformation)', 'Compare rules for foreign judgments vs. treaties', 'Exclude automatic enforcement without process (F) unless supported by evidence']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[42] Solving: QUESTION43) Some contemporary intelligence researchers like ...\n",
            "   -> [Analysis] Constraints: ['Must involve Howard Gardner and Robert Sternberg', 'Must relate to their criticism of school focus', 'Must select from given options (A-J)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 5}\n",
            "[43] Solving: QUESTION44) BobGafneyand Susan Medina invested $40,000 and $...\n",
            "   -> [Analysis] Constraints: ['Bob Gafney invested $40,000 and receives 4% of net income as manager', 'Susan Medina invested $50,000', 'Each partner receives 6% interest on their investment']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 4, 'C': 1}\n",
            "[44] Solving: QUESTION45) One objection to Singer’s theory that he conside...\n",
            "   -> [Analysis] Constraints: ['Must be an objection Singer explicitly considers', \"Must relate to Peter Singer's ethical theory\", 'Must be one of the provided options (A-J)']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 5}\n",
            "[45] Solving: QUESTION46) In 1797, John Frere made a discovery that he des...\n",
            "   -> [Analysis] Constraints: ['Must involve John Frere', 'Discovery year 1797', 'Description of the find']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 5}\n",
            "[46] Solving: QUESTION47) Pick the correct description of the following te...\n",
            "   -> [Analysis] Constraints: ['Must define utilitarianism accurately', \"Must align with core principle of 'greatest good for the greatest number'\", 'Must exclude egoistic, egalitarian, or harm-focused distortions']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[47] Solving: QUESTION48) Which of the following describes a key change in...\n",
            "   -> [Analysis] Constraints: ['Must relate to Homo erectus or later hominids', 'Must describe a change associated with larger brain size', 'Must exclude features unrelated to neurocranial development']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 5}\n",
            "[48] Solving: QUESTION49) Delia was accepted to both Harvard University an...\n",
            "   -> [Analysis] Constraints: ['Must be a psychological conflict type', 'Involves choosing between two positive options', 'No negative/undesirable elements in the choice']\n",
            "[WARN] JSON parse failed: Extra data: line 18 column 1 (char 338)\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 5}\n",
            "[49] Solving: QUESTION50) Which is the least accurate description of legal...\n",
            "   -> [Analysis] Constraints: ['Must select the option that least aligns with legal positivism principles', 'Must exclude accurate descriptions of legal positivism']\n",
            "   -> [Voting] Running 5 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 3, 'J': 2}\n",
            "저장 완료:baseline-1126.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로\n",
        "GT_PATH = \"testset.csv\"          # 정답 파일\n",
        "PRED_PATH = \"baseline-1126-llmreranker.csv\"  # 출력 파일 (현재 경로에 저장됨)\n",
        "\n",
        "# 2. 컬럼 이름\n",
        "GT_COL = \"answers\"               # testset.csv에서 정답 컬럼\n",
        "PRED_COL = \"rag_cot_answer\"      # baseline.csv에서 예측 컬럼\n",
        "\n",
        "# 3. csv 로드\n",
        "gt_df = pd.read_csv(GT_PATH)[25:]\n",
        "pred_df = pd.read_csv(PRED_PATH)\n",
        "\n",
        "# 4. Series 추출\n",
        "gt = gt_df[GT_COL].astype(str)\n",
        "pred = pred_df[PRED_COL].astype(str)\n",
        "\n",
        "# 5. 정규화 함수\n",
        "def normalize_choice(x: str) -> str:\n",
        "    x = x.strip().upper()\n",
        "    for ch in x:\n",
        "        if \"A\" <= ch <= \"Z\":\n",
        "            return ch\n",
        "    return x\n",
        "\n",
        "# 인덱스 리셋 (중요: 길이를 맞추기 위해)\n",
        "gt_norm = gt.apply(normalize_choice).reset_index(drop=True)\n",
        "pred_norm = pred.apply(normalize_choice).reset_index(drop=True)\n",
        "\n",
        "print(f\"Ground Truth 개수: {len(gt_norm)}, Prediction 개수: {len(pred_norm)}\")\n",
        "\n",
        "# 6. 정확도 계산\n",
        "correct = (gt_norm == pred_norm)\n",
        "accuracy = correct.mean()\n",
        "\n",
        "print(f\"총 문제 수: {len(gt_norm)}\")\n",
        "print(f\"정답 개수: {correct.sum()}\")\n",
        "print(f\"정확도: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "J4s43TAo8Dry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f93422b-2a9d-4bfd-f61e-49c7dc0fde74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth 개수: 25, Prediction 개수: 25\n",
            "총 문제 수: 25\n",
            "정답 개수: 20\n",
            "정확도: 80.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bNHCT1wTzgWv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}