{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WUNFUOKs7kJMqSB7AfJOo8SHvy0rGxH9",
      "authorship_tag": "ABX9TyORszZuMVmRNDKFKmWugfTW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoyen1122/solar_rag/blob/main/mmlu_pro/category_prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyH8sMMs2RD-",
        "outputId": "75d439d0-7203-4334-e8c9-ef514f8a0a71",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-upstage\n",
            "  Downloading langchain_upstage-0.7.5-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting langchain-core<2.0.0,>=1.0.3 (from langchain-upstage)\n",
            "  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langchain-openai<2.0.0,>=1.0.2 (from langchain-upstage)\n",
            "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting pypdf<5.0.0,>=4.2.0 (from langchain-upstage)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from langchain-upstage) (2.32.4)\n",
            "Collecting tokenizers<0.21.0,>=0.20.0 (from langchain-upstage)\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.31.0 (from langchain-upstage)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.43)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.11.10)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.3->langchain-upstage) (4.15.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (0.12.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->langchain-upstage) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers<0.21.0,>=0.20.0->langchain-upstage) (0.36.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (2025.3.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<0.21.0,>=0.20.0->langchain-upstage) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.3->langchain-upstage) (3.0.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai<2.0.0,>=1.0.2->langchain-upstage) (2024.11.6)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_upstage-0.7.5-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, pypdf, mypy-extensions, marshmallow, typing-inspect, tokenizers, dataclasses-json, langchain-core, langchain-text-splitters, langchain-openai, langchain-upstage, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.80\n",
            "    Uninstalling langchain-core-0.3.80:\n",
            "      Successfully uninstalled langchain-core-0.3.80\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.11\n",
            "    Uninstalling langchain-text-splitters-0.3.11:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.1.0 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\n",
            "transformers 4.57.1 requires tokenizers<=0.23.0,>=0.22.0, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.0 langchain-openai-1.0.3 langchain-text-splitters-1.0.0 langchain-upstage-0.7.5 marshmallow-3.26.1 mypy-extensions-1.1.0 pypdf-4.3.1 requests-2.32.5 tokenizers-0.20.3 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain-upstage langchain-community pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pdBgMTNwMuCm",
        "outputId": "77958723-7d9e-4320-9de9-8f9a38bbce05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from wikipedia-api) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->wikipedia-api) (2025.11.12)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=223279f86901cef1a4be7223edb238bdb62b75b201a61521c862e21b00635b74\n",
            "  Stored in directory: /root/.cache/pip/wheels/33/3c/79/b36253689d838af4a0539782853ac3cc38a83a6591ad570dde\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "C-AXD7fLRJI-",
        "outputId": "45e694df-749a-4a81-881f-f3e1c9ae773c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from typing import List, Tuple\n",
        "\n",
        "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "import wikipediaapi\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8qWw7Tq17dHw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/2025_2/nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gavGzRrztXz",
        "outputId": "977c9fce-8a8c-406d-bc5d-9ee84af8c01e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/2025_2/nlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./dataset/testset.csv\")"
      ],
      "metadata": {
        "id": "cgvozRFhCJMz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UPSTAGE_API_KEY = \"up_g7T2cQoLKZH6Oi2n4MHOW706XAdSs\""
      ],
      "metadata": {
        "id": "c-yFVp9vQ26G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_classifier = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "iK1l_XYgUPay"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solver = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.2, #좀 더 유연한 답변을 내도록\n",
        ")"
      ],
      "metadata": {
        "id": "oElUzmTxV6M-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = {\n",
        "    \"law\":        \"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/mmlu_category/law\",\n",
        "    \"psychology\": \"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/mmlu_category/psychology\",\n",
        "    \"business\":   \"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/mmlu_category/business\",\n",
        "    \"philosophy\": \"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/mmlu_category/philosophy\",\n",
        "    \"history\":    \"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/mmlu_category/history\",\n",
        "}\n",
        "categories = list(category_index.keys())"
      ],
      "metadata": {
        "id": "T6fjf7tL0E6A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large\")\n",
        "\n",
        "# 카테고리별 faiss 한번에 로드해서 캐시\n",
        "vectorstore = {}\n",
        "for cat, path in category_index.items():\n",
        "    vectorstore[cat] = FAISS.load_local(\n",
        "        folder_path=path,\n",
        "        embeddings=emb,\n",
        "        allow_dangerous_deserialization=True,\n",
        "    )\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(user_agent= \"NLP-RAG/1.0\", language = 'en')"
      ],
      "metadata": {
        "id": "wvfgJRYeP9M4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1st LLM**:\n",
        "\n",
        "- return category\n",
        "\n",
        "- return 3 keywords"
      ],
      "metadata": {
        "id": "WRn3avDKKexv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_prompt_template = \"\"\"\n",
        "You are an expert exam classifier for MMLU-Pro\n",
        "\n",
        "There are 5 possible categories:\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "\n",
        "[Task]\n",
        "Given a multiple-choice exam question (including all options),\n",
        "1. Choose one best category from the list above.\n",
        "2. Extract exactly 3 important keywords (one noun that consists of single word or short phrase)\n",
        "   that will be useful to search textbooks and Wikipedia.\n",
        "   Keywords should be as specific and accurate as possible (e.g., \"consent\",\n",
        "   \"cognitive dissonance\", \"Keynesian economics\").\n",
        "\n",
        "[Output format]\n",
        "Return a valid JSON with the following fields:\n",
        "- \"category\": one of [\"law\",\"psychology\",\"business\",\"philosophy\",\"history\"]\n",
        "- \"keywords\": a list of exactly 3 strings\n",
        "\n",
        "This is an output example:\n",
        "{{\n",
        "  \"category\": \"psychology\",\n",
        "  \"keywords\": [\"informed consent\", \"assent\", \"child counseling\"]\n",
        "}}\n",
        "\n",
        "[Question]\n",
        "{question}\n",
        "\"\"\".strip()\n",
        "\n",
        "category_prompt = ChatPromptTemplate.from_template(category_prompt_template)"
      ],
      "metadata": {
        "id": "nzr6RkbISTas"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_and_extract_keywords(question_text: str):\n",
        "    messages = category_prompt.format_messages(question=question_text)\n",
        "    resp = llm_classifier.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    if not raw:\n",
        "        # 완전 빈 응답이면 기본값으로 대충 처리 (죽지 않게)\n",
        "        print(\"[WARN] Empty LLM output for category, fallback to 'history'\")\n",
        "        return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    # 1차 시도: 전체를 JSON으로 해석\n",
        "    try:\n",
        "        data = json.loads(raw)\n",
        "    except json.JSONDecodeError:\n",
        "        # 2차 시도: 문자열 안에서 {...} 구간만 잘라서 해석\n",
        "        start = raw.find(\"{\")\n",
        "        end = raw.rfind(\"}\")\n",
        "        if start == -1 or end == -1:\n",
        "            print(\"[WARN] No JSON object found in output, fallback to 'history'\")\n",
        "            return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "        json_str = raw[start:end+1]\n",
        "        try:\n",
        "            data = json.loads(json_str)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"[WARN] JSON parse failed again:\", e)\n",
        "            return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    category = data.get(\"category\", \"history\").strip().lower()\n",
        "    keywords = data.get(\"keywords\", [])\n",
        "    keywords = [str(k).strip() for k in keywords][:3]\n",
        "\n",
        "    if not keywords:\n",
        "        keywords = [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    return category, keywords"
      ],
      "metadata": {
        "id": "93dJK7O09Jar"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wiki_context(keywords, max_chars_per_page=1200):\n",
        "    snippets = []\n",
        "    for kw in keywords:\n",
        "        try:\n",
        "            page = wiki.page(kw)\n",
        "            if not page.exists():\n",
        "                print(f\"[WARN] page for '{kw}' does not exist\")\n",
        "                continue\n",
        "            text = page.text[:max_chars_per_page]\n",
        "            snippets.append(f\"[Wikipedia: {page.title}]\\n{text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] wikipediaapi fetch failed for '{kw}': {e}\")\n",
        "            continue\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ],
      "metadata": {
        "id": "e_n3aEbhUxxX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_K_TEXTBOOK = 5\n",
        "\n",
        "def build_context_for_solver(question_text: str, category: str, keywords):\n",
        "    # 1) 카테고리별 textbook RAG\n",
        "    vs = vectorstore[category]\n",
        "    docs = vs.similarity_search(question_text, k=TOP_K_TEXTBOOK)\n",
        "    textbook_context = \"\\n\\n\".join(\n",
        "        f\"[Textbook Doc {i+1}] {d.page_content}\" for i, d in enumerate(docs)\n",
        "    )\n",
        "\n",
        "    # 2) Wikipedia context\n",
        "    wiki_context = fetch_wiki_context(keywords)\n",
        "\n",
        "    full_context = f\"\"\"\\\n",
        "=== TEXTBOOK CONTEXT ({category}) ===\n",
        "{textbook_context}\n",
        "\n",
        "=== WIKIPEDIA CONTEXT (keywords: {', '.join(keywords)}) ===\n",
        "{wiki_context}\n",
        "\"\"\"\n",
        "    return full_context"
      ],
      "metadata": {
        "id": "XlGDRESCR7Xu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2nd LLM**:\n",
        "\n",
        "- return CoT\n",
        "- return 최종 정답"
      ],
      "metadata": {
        "id": "WLuAVR6GVAwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Template"
      ],
      "metadata": {
        "id": "PkpEXzO6Bcav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_LAW_TMPL = \"\"\"\n",
        "You are an expert law exam solver. You specialize in common-law style multiple-choice questions\n",
        "MMLU-Pro (criminal law, torts, contracts, property, evidence, constitutional law, etc.).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "Use the CONTEXT as textbook + Wikipedia support, but ALWAYS follow these principles:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION FACT PATTERN\n",
        "- First, read the QUESTION (including facts and answer options) very carefully.\n",
        "- Treat the facts and wording in the QUESTION as the primary authority.\n",
        "- Do NOT contradict the facts as stated in the QUESTION.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY LEGAL CLUES FROM THE QUESTION\n",
        "Before judging the options, silently identify 3–5 essential legal clues from the QUESTION itself, such as:\n",
        "- relevant area of law (e.g., common-law robbery, larceny, attempt, accomplice liability, defenses),\n",
        "- key facts about timing, knowledge, intent (mens rea), consent, force, or possession,\n",
        "- jurisdiction assumptions (assume standard U.S. common law / majority rule unless the CONTEXT clearly says otherwise).\n",
        "\n",
        "Base your reasoning on these clues.\n",
        "\n",
        "3) USE CONTEXT CAREFULLY (TEXTBOOK > WIKIPEDIA)\n",
        "- Use the CONTEXT to recall or confirm black-letter rules, elements, and standard doctrines.\n",
        "- If textbook material and Wikipedia conflict, trust the textbook-style explanation in the CONTEXT.\n",
        "- Do NOT narrow or expand a rule beyond what is normally accepted in standard common law / majority doctrine,\n",
        "  unless the CONTEXT explicitly tells you to use a specific variant.\n",
        "\n",
        "4) APPLY BLACK-LETTER LAW PRECISELY\n",
        "- Identify the relevant rule(s) (e.g., elements of common-law larceny, robbery, burglary, receiving stolen property,\n",
        "  attempt, conspiracy, self-defense, etc.).\n",
        "- Apply every element to the facts in the QUESTION.\n",
        "- Pay careful attention to:\n",
        "  - timing of force or threats,\n",
        "  - whether the defendant knew property was stolen,\n",
        "  - whether there was a trespassory taking,\n",
        "  - whether possession was obtained by fraud, trick, or without consent,\n",
        "  - whether any required mental state (intent, knowledge, recklessness, negligence) is clearly present.\n",
        "\n",
        "5) COMPARE EACH OPTION STRICTLY\n",
        "For EACH answer choice:\n",
        "- Explain briefly (in your own reasoning) why it is correct or incorrect,\n",
        "  always referencing specific facts from the QUESTION and the applicable legal rule.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the precise legal definition and all elements,\n",
        "    - correctly reflects the timing and mental state required by the rule,\n",
        "    - does NOT add extra facts not in the QUESTION,\n",
        "    - fits both the QUESTION facts and the CONTEXT.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume that the defendant “knows” something unless the QUESTION clearly states it or it is a necessary inference.\n",
        "- Do NOT invent additional conduct (e.g., extra threats, agreements, or prior plans) that are not described.\n",
        "- Do NOT change the jurisdiction, legal standard, or time period unless the CONTEXT or QUESTION explicitly tells you to.\n",
        "- If the context is incomplete, choose the MOST reasonable answer but do not contradict the given evidence.\n",
        "\n",
        "7) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences.\n",
        "- Do NOT use Markdown formatting (no bullet points, no headings, no **bold**, no code blocks).\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_law = ChatPromptTemplate.from_template(SOLVER_PROMPT_LAW_TMPL)"
      ],
      "metadata": {
        "id": "Ns8U7PfE-x4t"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_PHILOSOPHY_TMPL = \"\"\"\n",
        "You are an expert philosophy exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in ethics, meta-ethics, epistemology, metaphysics, logic,\n",
        "philosophy of mind and language, political philosophy, and the history of philosophy\n",
        "(ancient, medieval, modern, and contemporary).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any passage and all answer options) very carefully.\n",
        "- Treat the text and wording of the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY PHILOSOPHICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential philosophical clues, such as:\n",
        "   - the main concept (e.g., categorical imperative, utilitarianism, internalism vs externalism,\n",
        "     Gettier problem, a priori vs a posteriori, necessary vs sufficient conditions),\n",
        "   - the relevant philosopher or school (e.g., Kant, Mill, Hume, Plato, Aristotle, Rawls, behaviorism, logical positivism),\n",
        "   - the logical structure (e.g., what follows from what, which statement would they reject, which principle is violated).\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, distinctions, and canonical views of philosophers.\n",
        "- Do NOT invent new doctrines or attribute views to philosophers that are not well-established.\n",
        "- Apply the standard reading unless the CONTEXT explicitly specifies a different interpretation.\n",
        "\n",
        "4) APPLY PHILOSOPHICAL DOCTRINES PRECISELY\n",
        "- Identify which theory, argument, or distinction the question is really testing.\n",
        "- Pay attention to:\n",
        "  - necessary vs sufficient conditions,\n",
        "  - analytic vs synthetic, a priori vs a posteriori,\n",
        "  - validity vs soundness,\n",
        "  - deontological vs consequentialist reasoning,\n",
        "  - internal vs external justification,\n",
        "  - the exact wording of a principle or formulation (e.g., Kant’s Humanity formulation, Mill’s harm principle).\n",
        "- For “Which of the following would X most likely endorse/reject?” style questions, base your choice on\n",
        "  X’s actual doctrine, not on your own judgment of what is true.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH option:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions or doctrines from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the canonical definition or the philosopher’s standard view,\n",
        "    - captures the fundamental idea of the theory rather than a peripheral detail,\n",
        "    - does not add extra assumptions not stated in the QUESTION,\n",
        "    - uses the correct logical strength (e.g., does not turn “some” into “all,” does not confuse necessary with sufficient).\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume extra premises, background facts, or historical claims that are not stated or strongly implied.\n",
        "- Do NOT change the content of a doctrine to make an option fit better; respect standard textbook interpretations.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_philosophy = ChatPromptTemplate.from_template(SOLVER_PROMPT_PHILOSOPHY_TMPL)"
      ],
      "metadata": {
        "id": "nkGZ-p7_Bjyl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_PSYCHOLOGY_TMPL = \"\"\"\n",
        "You are an expert psychology exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in clinical psychology, cognitive psychology, social psychology,\n",
        "developmental psychology, personality, biological/physiological psychology, learning, psychometrics,\n",
        "research methods, and ethics (e.g., APA code of conduct).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any vignette, description, and all answer options) very carefully.\n",
        "- Treat the facts and wording in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY PSYCHOLOGICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential psychological clues, such as:\n",
        "   - the main construct or theory (e.g., classical conditioning, operant conditioning, working memory,\n",
        "     attachment style, Big Five traits, self-efficacy, cognitive dissonance),\n",
        "   - the relevant theorist or model (e.g., Piaget, Vygotsky, Erikson, Kohlberg, Bandura, Beck),\n",
        "   - the developmental stage or level (e.g., preconventional vs conventional, sensorimotor vs formal operational),\n",
        "   - the type of design or method (e.g., experiment vs correlational study, longitudinal vs cross-sectional),\n",
        "   - the key symptoms, behaviors, or ethical requirements described in the vignette.\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, diagnostic criteria (at a conceptual level),\n",
        "  major theories, stages, and classical experiments.\n",
        "- Do NOT invent new constructs or attribute theories to psychologists who are not associated with them.\n",
        "- Apply the standard textbook interpretation unless the CONTEXT explicitly specifies a different one.\n",
        "\n",
        "4) APPLY PSYCHOLOGICAL THEORIES PRECISELY\n",
        "- Identify which theory, construct, stage, or principle the question is really testing.\n",
        "- Pay attention to:\n",
        "  - necessary features vs incidental details of a concept,\n",
        "  - differences between similar concepts (e.g., negative reinforcement vs punishment,\n",
        "    state vs trait, reliability vs validity),\n",
        "  - differences between stages (e.g., Kohlberg’s Stage 1 vs Stage 2, Erikson’s crises),\n",
        "  - the direction of cause/effect or prediction implied by the theory.\n",
        "- For ethics questions (e.g., APA), carefully consider:\n",
        "  - informed consent, confidentiality, competence, dual relationships, and risk of harm,\n",
        "  - what the code obligates the psychologist to do in the specific situation.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions or theories from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the canonical textbook definition or theory,\n",
        "    - directly fits ALL key facts given in the QUESTION (age, setting, behavior, stated intentions),\n",
        "    - does not rely on extra assumptions not stated in the QUESTION,\n",
        "    - has the correct level of generality (not too narrow, not too broad) for the construct or stage.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume additional symptoms, diagnoses, or background history that are not clearly stated.\n",
        "- Do NOT assume the person has specific knowledge or intentions beyond what the QUESTION describes.\n",
        "- Do NOT guess rare or exotic explanations when a standard, well-known theory clearly fits better.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_psychology = ChatPromptTemplate.from_template(SOLVER_PROMPT_PSYCHOLOGY_TMPL)"
      ],
      "metadata": {
        "id": "9Tie6gVEBtdf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_BUSINESS_TMPL = \"\"\"\n",
        "You are an expert business and economics exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and MBA level) in microeconomics, macroeconomics, finance, accounting, management,\n",
        "organizational behavior, marketing, operations, business ethics, and quantitative methods.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any tables, numbers, and all answer options) very carefully.\n",
        "- Treat the facts, numerical data, and wording in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY BUSINESS / ECON CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential clues, such as:\n",
        "   - the main domain (e.g., microeconomics, macroeconomics, corporate finance, accounting, management, marketing),\n",
        "   - key concepts (e.g., opportunity cost, elasticity, present value, NPV, CAPM, break-even point,\n",
        "     comparative advantage, marginal cost/benefit, principal–agent problem, game theory, externalities),\n",
        "   - relevant formulas or relationships (e.g., PV = CF/(1+r)^t, profit = TR – TC, elasticity definitions,\n",
        "     accounting identities, basic statistics),\n",
        "   - organizational/management concepts (e.g., leadership style, motivation theory, decision-making biases),\n",
        "   - business ethics or corporate governance principles.\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS AND FORMULAS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, formulas, and conceptual relationships.\n",
        "- Do NOT invent new theories or assume non-standard definitions.\n",
        "- Apply the standard textbook interpretation unless the CONTEXT explicitly specifies a different one.\n",
        "\n",
        "4) APPLY BUSINESS / ECONOMIC LOGIC PRECISELY\n",
        "- Identify which concept, model, or calculation the question is really testing.\n",
        "- Pay careful attention to:\n",
        "  - the difference between average vs marginal, stock vs flow, nominal vs real, short run vs long run,\n",
        "  - risk vs return, cost of capital, discounting vs compounding,\n",
        "  - accounting distinctions (asset/liability/equity, revenue vs profit, cash vs accrual),\n",
        "  - supply–demand shifts vs movement along a curve,\n",
        "  - game-theoretic reasoning (dominant strategies, Nash equilibrium),\n",
        "  - basic statistical reasoning (mean, variance, correlation vs causation).\n",
        "- When numbers are given, use them logically and consistently.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions, models, or formulas from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the exact definitions and standard formulas,\n",
        "    - correctly uses all given information in the QUESTION (including signs, units, and constraints),\n",
        "    - does not rely on extra assumptions not stated in the QUESTION,\n",
        "    - has the correct economic or managerial interpretation (no confusion of cause and effect, or average vs marginal).\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume additional data (e.g., extra numbers, extra constraints) that are not given.\n",
        "- Do NOT assume a different market structure, time period, or financial environment unless clearly stated.\n",
        "- Do NOT change definitions (e.g., of elasticity, NPV, beta, ROI) to force an option to fit.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_business = ChatPromptTemplate.from_template(SOLVER_PROMPT_BUSINESS_TMPL)"
      ],
      "metadata": {
        "id": "_BnpjXSCB1fX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_HISTORY_TMPL = \"\"\"\n",
        "You are an expert history exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in world history, U.S. history, European history, Asian history,\n",
        "Latin American and African history, intellectual and cultural history, political history,\n",
        "economic history, and questions based on primary-source excerpts.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any passage, quotation, data, and all answer options) very carefully.\n",
        "- Treat the facts, wording, and time/place cues in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY HISTORICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential historical clues, such as:\n",
        "   - time period or approximate dates (e.g., “late 18th century,” “interwar period,” “Post–World War II”),\n",
        "   - geographic region or polity (e.g., Tang China, Mughal India, Weimar Germany, Cold War United States),\n",
        "   - type of source (e.g., political speech, treaty, law code, memoir, propaganda, religious text),\n",
        "   - key themes (e.g., imperialism, industrialization, nationalism, revolution, reform, decolonization, globalization),\n",
        "   - actors and relationships (e.g., state vs. frontier peoples, colonizer vs. colonized, elite vs. peasantry).\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL HISTORY, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard chronology, major events, and characteristic policies or ideas\n",
        "  of states, movements, and historical figures.\n",
        "- Do NOT overwrite or ignore specific details given in the QUESTION (e.g., who is speaking, to whom, and in what setting).\n",
        "- Apply widely accepted historical interpretations unless the CONTEXT or QUESTION clearly specifies a particular viewpoint.\n",
        "\n",
        "4) INTERPRET SOURCES AND CAUSALITY CAREFULLY\n",
        "- For questions based on a passage or source:\n",
        "  - Focus on what the author explicitly states and what is strongly implied by the text.\n",
        "  - Distinguish between what the author approves of and what they criticize.\n",
        "  - Note the tone, audience, and purpose (e.g., justify a policy, criticize a ruler, mobilize support).\n",
        "- Pay careful attention to:\n",
        "  - cause vs. effect (do not confuse consequences with causes),\n",
        "  - continuity vs. change over time,\n",
        "  - similarities vs. differences between regions or periods,\n",
        "  - whether the question is asking for context, consequence, motivation, or historical significance.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - relevant facts or patterns from the CONTEXT (chronology, policies, institutions, conflicts).\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the specific time, place, and actors indicated in the QUESTION,\n",
        "    - fits the main theme or process the QUESTION is testing,\n",
        "    - does not rely on anachronistic assumptions or events from a different period,\n",
        "    - avoids overgeneralization or mixing different regions or eras.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT introduce additional events, dates, or policies that are not supported by the QUESTION or reliable CONTEXT.\n",
        "- Do NOT move events to different centuries or regions just to make an option fit.\n",
        "- Do NOT attribute quotes or ideas to the wrong person or regime.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_history = ChatPromptTemplate.from_template(SOLVER_PROMPT_HISTORY_TMPL)"
      ],
      "metadata": {
        "id": "GRIwaKk7B8hy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_with_rag_and_wiki(question_text: str):\n",
        "    # 1) 1단계 LLM: 카테고리 + 키워드\n",
        "    category, keywords = classify_and_extract_keywords(question_text)\n",
        "    if category not in vectorstore:\n",
        "        print(f\"[WARN] Unknown category '{category}', fallback to 'business'\")\n",
        "        category = \"business\"\n",
        "\n",
        "    # 2) 컨텍스트 구성 (FAISS + Wikipedia)\n",
        "    context = build_context_for_solver(question_text, category, keywords)\n",
        "\n",
        "    # 3) 2단계 LLM: CoT로 정답 도출\n",
        "    if category == \"law\":\n",
        "      messages = solver_prompt_law.format_messages(\n",
        "          context=context,\n",
        "          question=question_text\n",
        "      )\n",
        "    elif category == \"philosophy\":\n",
        "      messages = solver_prompt_philosophy.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"psychology\":\n",
        "      messages = solver_prompt_psychology.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"business\":\n",
        "      messages = solver_prompt_business.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"history\":\n",
        "        messages = solver_prompt_history.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "\n",
        "    resp = llm_solver.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # (1) 아래쪽 줄부터 \"FINAL ANSWER\"가 들어간 줄 찾기 (마크다운 포함 허용)\n",
        "    for line in raw.splitlines()[::-1]:  # 아래에서부터 검색\n",
        "        s = line.strip()\n",
        "\n",
        "        # '**Final Answer: A**' 같이 생긴 것도 잡기 위해 'in' 사용\n",
        "        if \"FINAL ANSWER\" in s.upper():\n",
        "            # 마크다운 볼드 제거\n",
        "            s = s.replace(\"**\", \"\").strip()\n",
        "            # 정규식으로 'Final Answer: X'에서 X만 뽑기\n",
        "            m = re.search(r\"FINAL ANSWER\\s*:\\s*([A-Z])\", s, re.IGNORECASE)\n",
        "            if m:\n",
        "                final_letter = m.group(1).upper()\n",
        "                break\n",
        "\n",
        "    # 그래도 못 찾으면, 전체 텍스트에서 대문자 한 글자 검색\n",
        "    if final_letter is None:\n",
        "        for ch in raw:\n",
        "            if \"A\" <= ch <= \"Z\":\n",
        "                final_letter = ch\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"category\": category,\n",
        "        \"keywords\": keywords,\n",
        "        \"raw_reasoning\": raw,       # 디버깅/분석용\n",
        "        \"final_answer\": final_letter,\n",
        "    }"
      ],
      "metadata": {
        "id": "aynzekilVXjc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**testset 실행 예시**:\n",
        "- baseline.csv"
      ],
      "metadata": {
        "id": "VyGvmOy6VdUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzXXaUdpIrGv",
        "outputId": "ebd13bf7-7cef-4f92-94a5-2b832daae791"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'result'\n",
            "/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/result\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/dataset/testset.csv\")[26:]  # 질문, 선택지 다 합쳐진 컬럼 가정\n",
        "QUESTION_COL = \"prompts\"\n",
        "\n",
        "results = []\n",
        "for i, row in df.iterrows():\n",
        "    q = row[QUESTION_COL]\n",
        "    print(f\"[{i}] Solving: {q[:60]}...\")\n",
        "    out = solve_mmlu_with_rag_and_wiki(q)\n",
        "    results.append(out[\"final_answer\"])\n",
        "    df.loc[i, \"pred_category\"] = out[\"category\"]\n",
        "    df.loc[i, \"kw1\"] = out[\"keywords\"][0] if len(out[\"keywords\"]) > 0 else \"\"\n",
        "    df.loc[i, \"kw2\"] = out[\"keywords\"][1] if len(out[\"keywords\"]) > 1 else \"\"\n",
        "    df.loc[i, \"kw3\"] = out[\"keywords\"][2] if len(out[\"keywords\"]) > 2 else \"\"\n",
        "    df.loc[i, \"rag_cot_answer\"] = out[\"final_answer\"]\n",
        "    df.loc[i, \"cot_full\"] = out[\"raw_reasoning\"]\n",
        "\n",
        "df.to_csv(\"testset_100_answer2.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2PG9zsVVbEQ",
        "outputId": "ca8d7f33-a130-407c-d4e7-de21b5c602f2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[26] Solving: QUESTION27) A man is at home in his apartment, alone, late a...\n",
            "[27] Solving: QUESTION28) What do Homo sapiens and Australopithecus afaren...\n",
            "[28] Solving: QUESTION29)This question refers to the following information...\n",
            "[WARN] page for 'Tang relations' does not exist\n",
            "[WARN] page for 'frontier peoples' does not exist\n",
            "[29] Solving: QUESTION30)Homo erectus differed from Homo habilis in which ...\n",
            "[30] Solving: QUESTION31)During the manic phase of a bipolar disorder, ind...\n",
            "[WARN] page for 'manic phase' does not exist\n",
            "[WARN] page for 'high self-esteem' does not exist\n",
            "[31] Solving: QUESTION32) This question refers to the following informatio...\n",
            "[32] Solving: QUESTION33) You receive a phone call from Hermann H., age 28...\n",
            "[WARN] page for 'ethical psychologist' does not exist\n",
            "[WARN] page for 'referrals' does not exist\n",
            "[33] Solving: QUESTION34) During the second stage of Kohlberg’s preconvent...\n",
            "[WARN] page for 'Kohlberg’s theory' does not exist\n",
            "[WARN] page for 'preconventional level' does not exist\n",
            "[34] Solving: QUESTION35)  In satisfying Kant's Humanity formulation of th...\n",
            "[WARN] page for 'Kant's Humanity formulation' does not exist\n",
            "[WARN] page for 'morally permissible ends' does not exist\n",
            "[35] Solving: QUESTION36) Aristotle says  that what makes things be what t...\n",
            "[36] Solving: QUESTION37) The ________ School of jurisprudence believes th...\n",
            "[WARN] page for 'social traditions' does not exist\n",
            "[37] Solving: QUESTION38) A woman was standing in the aisle of a subway ca...\n",
            "[38] Solving: QUESTION39) A defendant met her friend at the electronics st...\n",
            "[39] Solving: QUESTION40)____________ refers to a strategic process involv...\n",
            "[WARN] page for 'stakeholder assessment' does not exist\n",
            "[40] Solving: QUESTION41)This question refers to the following information...\n",
            "[WARN] page for 'moral norms' does not exist\n",
            "[WARN] page for 'ancient wisdom literature' does not exist\n",
            "[41] Solving: QUESTION42) Is the recognition of foreign judgments subject ...\n",
            "[WARN] page for 'doctrine of dualism' does not exist\n",
            "[WARN] page for 'bilateral treaties' does not exist\n",
            "[42] Solving: QUESTION43) Some contemporary intelligence researchers like ...\n",
            "[43] Solving: QUESTION44) BobGafneyand Susan Medina invested $40,000 and $...\n",
            "[WARN] page for 'partnership income distribution' does not exist\n",
            "[WARN] page for 'interest on investment' does not exist\n",
            "[WARN] page for 'net income allocation' does not exist\n",
            "[44] Solving: QUESTION45) One objection to Singer’s theory that he conside...\n",
            "[WARN] page for 'Singer’s theory' does not exist\n",
            "[45] Solving: QUESTION46) In 1797, John Frere made a discovery that he des...\n",
            "[46] Solving: QUESTION47) Pick the correct description of the following te...\n",
            "[47] Solving: QUESTION48) Which of the following describes a key change in...\n",
            "[48] Solving: QUESTION49) Delia was accepted to both Harvard University an...\n",
            "[WARN] page for 'approach-approach' does not exist\n",
            "[WARN] page for 'cognitive-dissonance' does not exist\n",
            "[49] Solving: QUESTION50) Which is the least accurate description of legal...\n",
            "[WARN] page for 'morality and law' does not exist\n",
            "[WARN] page for 'closed logical system' does not exist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정확도**"
      ],
      "metadata": {
        "id": "R3J993zAevoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. 파일 경로\n",
        "GT_PATH = \"/content/drive/MyDrive/Colab Notebooks/2025_2/nlp/dataset/testset.csv\"# 정답 파일\n",
        "PRED_PATH = \"testset_100_answer2.csv\"       # 출력 파일\n",
        "\n",
        "# 2. 컬럼 이름\n",
        "GT_COL = \"answers\"               # testset.csv에서 정답 컬럼\n",
        "PRED_COL = \"rag_cot_answer\"      # baseline.csv에서 예측 컬럼\n",
        "\n",
        "# 3. csv 로드\n",
        "gt_df = pd.read_csv(GT_PATH)[26:]   # 26번 문제부터라고 가정\n",
        "pred_df = pd.read_csv(PRED_PATH)\n",
        "\n",
        "# 4. Series 추출\n",
        "gt = gt_df[GT_COL].astype(str)\n",
        "pred = pred_df[PRED_COL].astype(str)\n",
        "\n",
        "# 5. 정규화 함수\n",
        "def normalize_choice(x: str) -> str:\n",
        "    x = x.strip().upper()\n",
        "    for ch in x:\n",
        "        if \"A\" <= ch <= \"Z\":\n",
        "            return ch\n",
        "    return x\n",
        "\n",
        "# 인덱스 리셋이 포인트\n",
        "gt_norm = gt.apply(normalize_choice).reset_index(drop=True)\n",
        "pred_norm = pred.apply(normalize_choice).reset_index(drop=True)\n",
        "\n",
        "print(len(gt_norm), len(pred_norm))  # 둘 다 25 나오는지 체크 한번 해보고\n",
        "\n",
        "# 6. 정확도 계산\n",
        "correct = (gt_norm == pred_norm)\n",
        "accuracy = correct.mean()\n",
        "\n",
        "print(f\"총 문제 수: {len(gt_norm)}\")\n",
        "print(f\"정답 개수: {correct.sum()}\")\n",
        "print(f\"정확도: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhvOdmVFVtvI",
        "outputId": "fc167d29-63da-4c7c-f2a5-5d8cc62c4a2e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24 24\n",
            "총 문제 수: 24\n",
            "정답 개수: 18\n",
            "정확도: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rhR9aYWWNh65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}