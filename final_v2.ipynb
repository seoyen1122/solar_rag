{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seoyen1122/solar_rag/blob/main/final_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1s12M0bW7rh",
        "outputId": "acef06cf-8f9e-40ec-e219-9782f26e3260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -qU python-dotenv langchain langchain-community langchain-core langchain-text-splitters langchain_upstage oracledb faiss-cpu langchain-classic openai pandas camelot-py[cv] PyMuPDF wikipedia_api sentence-transformers rank_bm25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-M0HMFSXPfX",
        "outputId": "ee98f781-26ef-44b7-bb05-adf5ea4b5536"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/91.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: camelot-py 1.0.9 does not provide the extra 'cv'\u001b[0m\u001b[33m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.2/40.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.0/475.0 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m144.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m133.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.7/343.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for wikipedia_api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall -y transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbRQC1Ibix4N",
        "outputId": "48566be4-9299-4cf1-d1c9-93c652a8a291"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.46.3\n",
            "Uninstalling transformers-4.46.3:\n",
            "  Successfully uninstalled transformers-4.46.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --no-cache-dir \"transformers>=4.45.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huQ3hUMyi3Pw",
        "outputId": "72db2cee-4fc1-4e24-9f19-fdd61406edda"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers>=4.45.0\n",
            "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (2.32.5)\n",
            "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.45.0)\n",
            "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.45.0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.0) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.0) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.45.0) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.45.0) (2025.11.12)\n",
            "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m340.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m366.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-upstage 0.7.5 requires tokenizers<0.21.0,>=0.20.0, but you have tokenizers 0.22.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.22.1 transformers-4.57.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from collections import Counter\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "import pandas as pd\n",
        "import wikipediaapi\n",
        "\n",
        "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain_classic.chains import RetrievalQA\n",
        "from langchain_classic.retrievers import EnsembleRetriever\n",
        "from openai import OpenAI\n",
        "\n",
        "import camelot\n",
        "import fitz\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_upstage import UpstageDocumentParseLoader\n",
        "\n",
        "import uuid\n",
        "from langchain_classic.retrievers import ParentDocumentRetriever\n",
        "from langchain_core.stores import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "\n",
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "c-_Mnzd18MR3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RuntimeError: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
        "No module named 'transformers.modeling_layers'\n",
        "이런 에러뜨면 밑에 트랜스포머 지우고 다시깔기"
      ],
      "metadata": {
        "id": "3tAJipE4jAiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/assignment/25-2/NLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mIe_4RTAUbQ",
        "outputId": "0c9b2975-1b1a-4ea9-f9a3-367038749815"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/assignment/25-2/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TESTSET_PATH = \"./dataset/testset.csv\"\n",
        "\n",
        "UPSTAGE_API_KEY = \"up_g7T2cQoLKZH6Oi2n4MHOW706XAdSs\""
      ],
      "metadata": {
        "id": "q8LGYcrtBVwO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EWHA 학칙"
      ],
      "metadata": {
        "id": "-uQ2U4M2LZo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EWHA_PDF_PATH = \"./ewha.pdf\""
      ],
      "metadata": {
        "id": "EAdUtZa_gSfg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VYtEEEQpZAvo"
      },
      "outputs": [],
      "source": [
        "upstage_embeddings = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = UpstageDocumentParseLoader(\n",
        "    EWHA_PDF_PATH,\n",
        "    api_key=UPSTAGE_API_KEY\n",
        ")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "nSjmR03bLQbc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_texts = []\n",
        "\n",
        "for doc in docs:\n",
        "    text = doc.page_content\n",
        "\n",
        "    text = text.strip()\n",
        "    clean_texts.append(text)\n",
        "\n",
        "\n",
        "full_text = \"\\n\".join(clean_texts)"
      ],
      "metadata": {
        "id": "efG9CsIdLnQp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match = re.search(r\"부칙\", full_text)\n",
        "\n",
        "if not match:\n",
        "        raise ValueError(\"부칙 문구를 찾을 수 없습니다.\")\n",
        "\n",
        "addendum_start = match.start()\n",
        "\n",
        "main_text = text[:addendum_start]\n",
        "extra_text = text[addendum_start:]"
      ],
      "metadata": {
        "id": "I3Z1L0bpLrcc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_main_text(html_text):\n",
        "    # 테이블 삭제\n",
        "    cleaned = re.sub(r'<table.*?>.*?</table>', '', html_text, flags=re.DOTALL)\n",
        "    return cleaned\n",
        "\n",
        "cleaned_extra_text = extract_main_text(extra_text)"
      ],
      "metadata": {
        "id": "kcgGy-Q3LtsP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    base_url=\"https://api.upstage.ai/v1\"\n",
        ")"
      ],
      "metadata": {
        "id": "f6mAmJaTLxLH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "You are an expert in Korean legal document analysis and Markdown formatting.\n",
        "\n",
        "Your task:\n",
        "Convert the given Ewha University regulation texts (in HTML text) into a clean Markdown document with correctly assigned heading levels.\n",
        "You are given a main text:\n",
        "1) MAIN TEXT: the main university regulations\n",
        "\n",
        "Process BOTH texts together and apply the same rules.\n",
        "\n",
        "=================================================================\n",
        "MARKDOWN HEADING RULES\n",
        "=================================================================\n",
        "\n",
        "**Main Body Chapters (e.g., “제1장 총칙”)**:\n",
        "- Top-level header: `# [Chapter Title]`\n",
        "- Articles within chapters: `## [Article Title]`\n",
        "\n",
        "=================================================================\n",
        "ADDITIONAL RULES\n",
        "=================================================================\n",
        "- Remove ALL page numbers (e.g., “2-2-1”).\n",
        "- Remove HTML tags, styles, tables, or formatting artifacts from the PDF conversion.\n",
        "- Preserve all meaningful text content, but organize it strictly under the specified Markdown headings.\n",
        "- Do NOT hallucinate any content not present in the text.\n",
        "- Do NOT output explanations or any text outside the markdown.\n",
        "- Output MUST be clean markdown and ONLY markdown.\n",
        "\n",
        "Below are the two raw texts:\n",
        "\n",
        "---------------- MAIN TEXT START ----------------\n",
        "{main_text}\n",
        "---------------- MAIN TEXT END ----------------\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert in hierarchical legal information extraction and Markdown document structuring.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt.format(main_text=main_text)\n",
        "    }\n",
        "]\n",
        "\n",
        "md_response = client.chat.completions.create(\n",
        "    model=\"solar-pro2\",\n",
        "    messages=messages\n",
        "    # response_format=response_format\n",
        ")"
      ],
      "metadata": {
        "id": "SlWkV5iOL0AG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_prompt = \"\"\"\n",
        "You are an expert in Korean legal document analysis and Markdown formatting.\n",
        "\n",
        "Your task:\n",
        "Convert the given text into a clean Markdown document with correctly assigned heading levels.\n",
        "\n",
        "=================================================================\n",
        "MARKDOWN HEADING RULES\n",
        "=================================================================\n",
        "\n",
        "**Main Body Chapters (e.g., “제1장 총칙”)**:\n",
        "- Top-level header: `# [Chapter Title]`\n",
        "- Articles within chapters: `## [Article Title]`\n",
        "\n",
        "=================================================================\n",
        "SPECIFIC INSTRUCTIONS FOR THIS TEXT\n",
        "=================================================================\n",
        "- The overall title for this section should be `# 이화여자대학교 학칙`. This should be the first line of the output.\n",
        "- Every instance of '부칙' that introduces a new addendum should be formatted as a second-level Markdown header, '## 부칙'. Ensure its associated content follows immediately under this header.\n",
        "- Remove ALL page numbers (e.g., “2-2-1”).\n",
        "- Remove HTML tags, styles, tables, or formatting artifacts from the PDF conversion.\n",
        "- Preserve all meaningful text content, but organize it strictly under the specified Markdown headings.\n",
        "- Do NOT hallucinate any content not present in the text.\n",
        "- Do NOT output explanations or any text outside the markdown.\n",
        "- Output MUST be clean markdown and ONLY markdown.\n",
        "\n",
        "Below is the raw text:\n",
        "\n",
        "---------------- ADDENDUM TEXT START ----------------\n",
        "{extra_text}\n",
        "---------------- ADDENDUM TEXT END ----------------\n",
        "\"\"\"\n",
        "\n",
        "extra_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert in hierarchical legal information extraction and Markdown document structuring.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": extra_prompt.format(extra_text=cleaned_extra_text)\n",
        "    }\n",
        "]\n",
        "\n",
        "md_extra_response = client.chat.completions.create(\n",
        "    model=\"solar-pro2\",\n",
        "    messages=extra_messages\n",
        ")\n",
        "\n",
        "print(md_extra_response.choices[0].message.content[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uYrglxscMCiD",
        "outputId": "b8472202-8561-4c68-d681-a96811416435"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 이화여자대학교 학칙\n",
            "\n",
            "## 부칙(1946. 8. 15 제정)\n",
            "본 학칙은 1946년 3월 1일부터 시행한다.\n",
            "\n",
            "## 부칙\n",
            "① 본 학칙은 1961년 3월 1일부터 시행한다.  \n",
            "② 본 학칙 시행에 관한 세칙은 총장이 정한다.\n",
            "\n",
            "## 부칙(문관행 1040.1-1549, 1963. 12. 16 개정)\n",
            "본 학칙은 1964년 3월 1일부터 시행한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-16, 1965. 1. 5 개정)\n",
            "① 이 학칙은 1965년 1월 10일부터 시행한다.  \n",
            "② 이 학칙 시행 당시 문리과대학에 소속하는 가정학과와 사범대학에 소속하는 가정학과는  \n",
            "폐과하되 그 재적 학생의 졸업년도까지 존치한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-89, 1966. 2. 1 개정)\n",
            "본 학칙은 1966년 2월 1일부터 시행한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-89, 1966. 2. 1 개정)\n",
            "본 학칙은 1966년 2월 1일부터 시행한다.\n",
            "\n",
            "## 부칙(문고대 1041.3-171, 1967. 1. 24 개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers_to_split_on = [(\"##\", \"Header 2\")]\n",
        "\n",
        "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
        "\n",
        "md_header_splits = markdown_splitter.split_text(md_response.choices[0].message.content)\n",
        "extra_splits = markdown_splitter.split_text(md_extra_response.choices[0].message.content)\n",
        "md_header_splits.extend(extra_splits)"
      ],
      "metadata": {
        "id": "98pdsyl8MErt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_headers_to_split_on = [\n",
        "    (\"##\", \"Header 2\"),\n",
        "     (\"###\", \"Header 3\")\n",
        "]\n",
        "small_md_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=small_headers_to_split_on, strip_headers=False)\n",
        "small_headers_splits = small_md_splitter.split_text(md_response.choices[0].message.content)\n",
        "small_headers_splits.extend(small_md_splitter.split_text(md_extra_response.choices[0].message.content))"
      ],
      "metadata": {
        "id": "xEeooDJmMIcM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = EWHA_PDF_PATH\n",
        "\n",
        "# Step 1: lattice 모드로 테이블 bbox만 추출\n",
        "lattice_tables = camelot.read_pdf(pdf_path, pages=\"all\", flavor=\"lattice\")\n",
        "\n",
        "final_tables = []\n",
        "\n",
        "for tbl in lattice_tables:\n",
        "    page_num = tbl.page\n",
        "    bbox = tbl._bbox  # (x1, y1, x2, y2)\n",
        "\n",
        "    # Step 2: PyMuPDF로 페이지 crop\n",
        "    doc = fitz.open(pdf_path)\n",
        "    page = doc[page_num - 1]\n",
        "\n",
        "    rect = fitz.Rect(bbox)\n",
        "    clipped = page.get_pixmap(clip=rect)\n",
        "    tmp_img = f\"tmp_page_{page_num}.png\"\n",
        "    clipped.save(tmp_img)\n",
        "\n",
        "    # Step 3: stream 모드로 crop된 이미지 분석\n",
        "    stream_tbls = camelot.read_pdf(\n",
        "        pdf_path,\n",
        "        pages=str(page_num),\n",
        "        flavor=\"stream\",\n",
        "        table_areas=[\",\".join(map(str, bbox))]  # bbox로 영역 제한\n",
        "    )\n",
        "\n",
        "    # Step 4: 이 테이블들만 최종 저장\n",
        "    for s in stream_tbls:\n",
        "        final_tables.append(s.df)\n",
        "\n",
        "# 출력 예시\n",
        "for i, df in enumerate(final_tables):\n",
        "    # print(f\"=== Final Table {i+1} ===\")\n",
        "    # print(df.to_markdown(index=False))\n",
        "    df.to_csv(f'table{i}.csv', index=False)\n",
        "    print(f'Table {i} extracted')\n",
        "\n",
        "cleaned_df = []\n",
        "\n",
        "for _, df in enumerate(final_tables):\n",
        "  headers_raw = [str(item).strip().replace(' ', '').replace('\\n', '').replace('\\u3000', '') for item in df.iloc[1]]\n",
        "\n",
        "  for col in df.columns:\n",
        "      df[col] = df[col].astype(str).str.strip().str.replace(' ', '').str.replace('\\n', '').str.replace('\\u3000', '')\n",
        "      df[col] = df[col].replace('', np.nan)\n",
        "\n",
        "  cleaned_df.append(df)\n",
        "\n",
        "for df in cleaned_df[:3]:\n",
        "  print(df)\n",
        "  print('==========================')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V68pDICEXLm_",
        "outputId": "03478a91-02ab-4330-98c3-6b998a963078"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Table 0 extracted\n",
            "Table 1 extracted\n",
            "Table 2 extracted\n",
            "Table 3 extracted\n",
            "Table 4 extracted\n",
            "Table 5 extracted\n",
            "Table 6 extracted\n",
            "Table 7 extracted\n",
            "Table 8 extracted\n",
            "Table 9 extracted\n",
            "Table 10 extracted\n",
            "Table 11 extracted\n",
            "Table 12 extracted\n",
            "Table 13 extracted\n",
            "Table 14 extracted\n",
            "Table 15 extracted\n",
            "Table 16 extracted\n",
            "Table 17 extracted\n",
            "         0      1         2\n",
            "0       대학  학위의종류    학과또는전공\n",
            "1   사회과학대학    문학사     사회복지학\n",
            "2   자연과학대학    이학사    분자생명과학\n",
            "3     공과대학    공학사      컴퓨터학\n",
            "4      NaN    NaN     정보통신학\n",
            "5      NaN    NaN  건축학(4년제)\n",
            "6      NaN   건축학사  건축학(5년제)\n",
            "7      NaN    공학사       환경학\n",
            "8     음악대학   음악학사      건반악기\n",
            "9      NaN    NaN       관현악\n",
            "10     NaN    NaN        성악\n",
            "11     NaN    NaN      교회음악\n",
            "12     NaN    NaN        작곡\n",
            "13     NaN    NaN      한국음악\n",
            "14  조형예술대학   미술학사       한국화\n",
            "15     NaN    NaN     회화․판화\n",
            "16     NaN    NaN        조소\n",
            "17     NaN    NaN     환경디자인\n",
            "18     NaN    NaN   시각정보디자인\n",
            "19     NaN    NaN     산업디자인\n",
            "20     NaN    NaN     패션디자인\n",
            "21     NaN    NaN      섬유예술\n",
            "22     NaN    NaN      도자예술\n",
            "23  체육과학대학    이학사       체육학\n",
            "24     NaN    NaN     사회체육학\n",
            "==========================\n",
            "        0      1         2\n",
            "0      대학  학위의종류    학과또는전공\n",
            "1     NaN   무용학사        무용\n",
            "2    사범대학   보건학사      보건교육\n",
            "3    경영대학    문학사       비서학\n",
            "4    의과대학    의학사        의학\n",
            "5  간호과학대학   간호학사      간호과학\n",
            "6    약학대학    약학사       제약학\n",
            "7  생활환경대학    문학사  소비자인간발달학\n",
            "8     NaN   가정학사     의류직물학\n",
            "9     NaN    이학사     식품영양학\n",
            "==========================\n",
            "       0      1       2\n",
            "0     대학  학위의종류  학과또는전공\n",
            "1   예술대학   음악학사    건반악기\n",
            "2    NaN    NaN     관현악\n",
            "3    NaN    NaN      성악\n",
            "4    NaN    NaN      작곡\n",
            "5    NaN    NaN    한국음악\n",
            "6    NaN   미술학사     동양화\n",
            "7    NaN    NaN     서양화\n",
            "8    NaN    NaN      조소\n",
            "9    NaN    NaN    섬유예술\n",
            "10   NaN    NaN    도자예술\n",
            "11   NaN    NaN   공간디자인\n",
            "12   NaN    NaN   시각디자인\n",
            "13   NaN    NaN   산업디자인\n",
            "14   NaN    NaN   패션디자인\n",
            "15   NaN    NaN   영상디자인\n",
            "16   NaN   의류학사     의류학\n",
            "17   NaN   무용학사      무용\n",
            "18  법과대학    법학사      법학\n",
            "==========================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table_documents = []\n",
        "\n",
        "for i, df in enumerate(cleaned_df):\n",
        "  table_doc = Document(page_content=df.to_markdown(index=False),\n",
        "                       metadata={'Header 2': '별표'+str(i)})\n",
        "  table_documents.append(table_doc)"
      ],
      "metadata": {
        "id": "RVfvPE9iXSV5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=150\n",
        ")\n",
        "doc = text_splitter.create_documents([full_text])\n",
        "simple_vectorstore = FAISS.from_documents(doc, upstage_embeddings)"
      ],
      "metadata": {
        "id": "CnaeVQg9XV1A"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 장 내부에 텍스트가 너무 긴 경우 (chunk size 1500 이상) 추가 split\n",
        "fine_grained_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=3000,\n",
        "    chunk_overlap=100\n",
        ")"
      ],
      "metadata": {
        "id": "ss7gYcKzXcLT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_docs = []\n",
        "\n",
        "# 메인 조항 % 부칙 필요 시 split 후 append\n",
        "for doc in md_header_splits:\n",
        "    sub_chunks_content = fine_grained_splitter.split_text(doc.page_content)\n",
        "    for chunk_content in sub_chunks_content:\n",
        "        # 기존 metadata 유지\n",
        "        new_metadata = doc.metadata.copy()\n",
        "        big_docs.append(Document(page_content=chunk_content, metadata=new_metadata))\n",
        "\n",
        "for table in table_documents:\n",
        "  big_docs.append(Document(page_content=table.page_content, metadata=table.metadata))\n",
        "\n",
        "# Now create the vector store from the fine_grained_documents\n",
        "big_vectorstore = FAISS.from_documents(big_docs, upstage_embeddings)\n",
        "\n",
        "for doc in big_docs[:3]:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)\n",
        "    print('----------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jIkrJdRiXdlZ",
        "outputId": "4663454c-3e41-48c6-dc4a-6ef20b2b9449"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# 이화여자대학교 학칙  \n",
            "## 제1장 총칙  \n",
            "### 제1조(목적)\n",
            "본교는 대한민국의 교육이념과 기독교정신을 바탕으로 하여 학술의 깊은 이론과 그 광범하고 정밀한 응용방법을 교수․연구하며, 인격을 도야하여 국가와 인류사회의 발전에 공헌할 수 있는 지도여성을 양성함을 목적으로 한다.  \n",
            "### 제2조(명칭)\n",
            "본교는 이화여자대학교라 부른다.  \n",
            "### 제3조(위치)\n",
            "본교는 서울특별시 서대문구 이화여대길 52에 둔다. (개정 2013.2.25.)\n",
            "{'Header 2': '제1장 총칙'}\n",
            "----------------------\n",
            "## 제2장 편제  \n",
            "### 제4조(대학 및 대학원)\n",
            "① 본교에는 다음 각 호의 대학을 둔다.\n",
            "1. 인문과학대학, 사회과학대학, 자연과학대학, 엘텍공과대학, 음악대학, 조형예술대학, 사범대학, 경영대학, 신산업융합대학, 의과대학, 간호대학, 약학대학, 스크랜튼대학(이하 “각 대학”이라 한다) (개정 2016.6.16.)\n",
            "2. 호크마(HOKMA)교양대학\n",
            "② 본교에는 대학원, 국제대학원, 통역번역대학원, 경영전문대학원, 법학전문대학원, 교육대학원, 디자인대학원, 사회복지대학원, 신학대학원, 정책과학대학원, 공연예술대학원, 임상보건융합대학원, 임상치의학대학원, 외국어교육특수대학원을 둔다(이하 “각 대학원”이라 한다). (개정 2016.6.16., 2017.5.15.)  \n",
            "### 제5조(학부․학과․전공 및 정원)\n",
            "① 각 대학, 학부, 학과, 전공 및 모집단위별 입학정원은 별표 1과 같다. (개정 2015.5.8., 2016.2.16., 2016.2.26., 2016.5.19., 2017.5.4., 2017.5.4.)\n",
            "② 모집단위별 입학정원의 일부는 입학전형에 따라 2개 이상의 모집단위를 통합하여 모집할 수 있다. (개정 1999.2.9., 2017.5.15.)\n",
            "③ 제2항에 따라 통합된 모집단위로 입학한 학생과 대학 또는 학부 등 광역화된 모집단위로 입학한 학생에 대하여는 일정한 학기와 학점을 이수한 후에 총장의 승인을 얻어 이수할 전공을 결정하게 하되 이에 필요한 사항은 총장이 따로 정한다. (개정 2016.2.16., 2017.5.15.)\n",
            "⑤ 전공별 선발로 입학한 학생은 전공별 신청자격 및 승인요건을 충족하면 지정한 전공으로 진입한다. (신설 2015.9.18.)\n",
            "⑥ 전공변경 또는 전과 제한이 있는 전형으로 입학한 학생은 전공변경 또는 전과할 수 없다. (신설 2015.9.18.)\n",
            "⑦ 스크랜튼학부 자유전공 입학생의 전공결정 신청 절차는 총장이 따로 정한다. (신설 2015.9.18.)  \n",
            "### 제5조의2(입학정원의 예외)\n",
            "「고등교육법 시행령」 제29조제2항 각 호(제3호 제외)에 해당하는 자의 입학의 경우에는 제5조의 규정에 불구하고 그 정원이 따로 있는 것으로 본다. (개정 1998.5.22)  \n",
            "### 제5조의3(계약학과)\n",
            "① 「산업교육진흥 및 산학연협력촉진에 관한 법률」에 의하여 국가, 지방자치단체 또는 산업체 등과 계약에 의한 학과 및 학부(이하 “계약학과”)를 설치․운영할 수 있다. (개정 2016.6.16.)\n",
            "② 제1항에 의하여 설치․운영하는 계약학과는 별표 3과 같다. (개정 2014.5.15., 2016.6.16)\n",
            "③ 계약학과에 관한 세부사항은 별도로 정한다.  \n",
            "### 제6조(대학원 학칙 등)\n",
            "각 대학원의 학칙은 따로 정한다. (개정 2000.2.1)  \n",
            "### 제6조의2(글로벌미래평생교육원)\n",
            "① 본교에 글로벌미래평생교육원을 둔다. (개정 2015.11.27.)\n",
            "② 글로벌미래평생교육원의 학칙은 따로 정한다. (개정 2015.11.27.)  \n",
            "### 제3장 부설기관  \n",
            "### 제8조(부속 및 연구기관)\n",
            "본교 부속기관 및 연구기관의 설치 및 운영에 관한 사항은 본교 직제에 따른다. (개정 2015.2.6.)\n",
            "{'Header 2': '제2장 편제'}\n",
            "----------------------\n",
            "## 제4장 학년, 학기, 수업일수, 휴업일 및 교원의 교수시간 (개정 1998.6.23)  \n",
            "### 제10조(학년, 학기)\n",
            "① 학년은 3월 1일부터 다음해 2월 말일까지로 하고 이를 제1학기와 제2학기로 나눈다.\n",
            "② 제1항의 일반학기 외에 하기방학과 동기방학중에 총장이 정하는 바에 따라 각각 계절학기를 둘 수 있다.  \n",
            "### 제11조(수업일수)\n",
            "① 수업일수는 매 학년 30주 이상(매 학기 15주 이상)으로 한다. (개정 1996.2.15)\n",
            "② 계절학기를 두는 경우 1계절학기의 수업기간은 3주 이상으로 한다. 다만, 총장이 필요하다고 인정하는 경우에는 달리 정할 수 있다. (개정 2017.2.8.)\n",
            "③ 천재지변 그 밖에 교육과정의 운영상 부득이한 사유로 수업일수를 충족할 수 없는 경우에는 「고등교육법 시행령」 제11조제2항에 따라 매 학년도 2주의 범위에서 수업일수를 감축할 수 있다. (개정 2014.11.21)  \n",
            "### 제12조(휴업일)\n",
            "① 정기휴업일은 다음과 같다.\n",
            "1. 하기방학 및 동기방학\n",
            "2. 개교기념일(5월 31일)\n",
            "3. 일요일\n",
            "4. 기타 국정공휴일\n",
            "② 하기방학 및 동기방학의 기간은 총장이 따로 정한다.\n",
            "③ 임시휴업은 필요에 따라 총장이 정한다.  \n",
            "### 제12조의2(교원의 교수시간)\n",
            "교원의 교수시간은 매 학년도 30주를 기준으로 연간 15학점에 해당하는 15시간을 원칙으로 하되, 자세한 사항은 총장이 따로 정한다. (개정 2014.11.21)\n",
            "{'Header 2': '제4장 학년, 학기, 수업일수, 휴업일 및 교원의 교수시간 (개정 1998.6.23)'}\n",
            "----------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_docs = []\n",
        "\n",
        "for doc in small_headers_splits:\n",
        "  new_metadata = doc.metadata.copy()\n",
        "  small_docs.append(Document(page_content=doc.page_content, metadata=new_metadata))\n",
        "\n",
        "for table in table_documents:\n",
        "  small_docs.append(Document(page_content=table.page_content, metadata=table.metadata))\n",
        "\n",
        "small_vectorstore = FAISS.from_documents(small_docs, upstage_embeddings)"
      ],
      "metadata": {
        "id": "pc7lOWZSXif9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatUpstage(api_key = UPSTAGE_API_KEY, model=\"solar-pro2\")"
      ],
      "metadata": {
        "id": "NAemdG4aXwK9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are a quiz taker about Ewha Womans University's regulation.\n",
        "    Please provide most correct answer for the given context in the response format below.\n",
        "\n",
        "    Response Format:\n",
        "    [Answer]: (A) answer <OR> (X) The information is not present in the context.\n",
        "    [Reason]: Brief reason for your answer\n",
        "    [Final Answer]: THE final answer to the question following your given reason. Answer in this format: (A) answer\n",
        "\n",
        "    If the answer is not present in the context, please answer as \"(X) The information is not present in the context.\"\n",
        "\n",
        "    Example:\n",
        "    QUESTION) 영어 및 정보 등에 관하여 일정한 기준의 능력이나 자격을 취득한 경우 인정 받는 학점은 몇점인가?\n",
        "    (A) 인정 안됨\n",
        "    (B) 1학점\n",
        "    (C) 2학점\n",
        "    (D) 3학점\n",
        "\n",
        "    Answer)\n",
        "    [Answer]: (D) 3학점\n",
        "    [Reason]: The context explicitly states in 제48조의2(영어 및 정보인증) ①: \"영어 및 정보 등에 관하여 일정한 기준의 능력이나 자격을 취득한 경우 이를 각 3학점으로 인정하고 인증서를 교부할 수 있다.\" This directly answers the question by specifying that 3 credits are recognized for such certifications.\n",
        "    [Final Answer]: (D) 3학점\n",
        "\n",
        "    Here is the question and context:\n",
        "    ---\n",
        "    Question: {question}\n",
        "    ---\n",
        "    Context: {context}\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "3_xmQdcxXxUF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(TESTSET_PATH)\n",
        "prompts = df['prompts']\n",
        "answers = df['answers']\n",
        "\n",
        "ewha_prompts = prompts[:25]\n",
        "ewha_answers = answers[:25]"
      ],
      "metadata": {
        "id": "VuiZAF22XzZk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(response):\n",
        "    \"\"\"\n",
        "    extracts the answer from the response using a regular expression.\n",
        "    expected format: \"[ANSWER]: (A) convolutional networks\"\n",
        "\n",
        "    if there are no answers formatted like the format, it returns None.\n",
        "    \"\"\"\n",
        "    pattern = r\"\\[Final Answer\\]:\\s\\(([A-J])\\)[^)]*\"\n",
        "\n",
        "    # Readjustment로 인해 dinal answer가 여러 번 등장할 수 있으므로 findall 사용\n",
        "    matches = re.findall(pattern, response)\n",
        "\n",
        "    if matches:\n",
        "        print(f'Matched answer: {matches}')  # debug\n",
        "        # 가장 마지막 final answer만 선택\n",
        "        return matches[-1].strip()\n",
        "    else:\n",
        "        return extract_again(response)\n",
        "\n",
        "def extract_again(response):\n",
        "    pattern = r\"\\b[A-J]\\b(?!.*\\b[A-J]\\b)\"\n",
        "    match = re.search(pattern, response)\n",
        "    if match:\n",
        "        print(f'Re-matched answer: {match}')  # debug\n",
        "        return match.group(0)\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "ARUobU--X1aZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_responses(qa, prompts):\n",
        "  responses = []\n",
        "\n",
        "  for prompt in prompts:\n",
        "  # for prompt in ewha_prompts:\n",
        "      response = qa.invoke(prompt)\n",
        "      # responses.append(response.content)\n",
        "      print(response['result'])  # debuggiing\n",
        "\n",
        "      final_answer = extract_answer(response['result'])\n",
        "      print(final_answer)\n",
        "      print('************************')\n",
        "      responses.append(final_answer)\n",
        "\n",
        "  return responses"
      ],
      "metadata": {
        "id": "yS2B6ygwYGnM"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(responses, answers):\n",
        "  cnt = 0\n",
        "\n",
        "  for answer, response in zip(answers, responses):\n",
        "      print(\"-\"*10)\n",
        "      # generated_answer = extract_answer(response)\n",
        "      # print(response)\n",
        "      # check\n",
        "      if response:\n",
        "          print(f\"generated answer: {response}, answer: {answer}\")\n",
        "      else:\n",
        "          print(f\"extraction fail, answer: {answer}\")\n",
        "\n",
        "\n",
        "      if response == None:\n",
        "          continue\n",
        "      if response in answer:\n",
        "          cnt += 1\n",
        "\n",
        "  # print()\n",
        "  # print(f\"acc: {(cnt/len(ewha_prompts))*100}%\")\n",
        "\n",
        "  accuracy = (cnt/len(answers))*100\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "2bgRsKvxYH9-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_voting(qa, prompt):\n",
        "  majority_voted_answers = []\n",
        "  num_iterations = 5\n",
        "\n",
        "  for idx, prompt in enumerate(prompt):\n",
        "      answers_for_current_prompt = []\n",
        "      for _ in range(num_iterations):\n",
        "          response = qa.invoke(prompt)\n",
        "          final_answer = extract_answer(response['result'])\n",
        "          if final_answer:\n",
        "              answers_for_current_prompt.append(final_answer)\n",
        "\n",
        "      if answers_for_current_prompt:\n",
        "          answer_counts = collections.Counter(answers_for_current_prompt)\n",
        "          most_common_answer = answer_counts.most_common(1)[0][0]\n",
        "          majority_voted_answers.append(most_common_answer)\n",
        "          print(f\"Prompt {idx+1}: Majority voted answer = {most_common_answer}\")\n",
        "      else:\n",
        "          majority_voted_answers.append(None)\n",
        "          print(f\"Prompt {idx+1}: No valid answers extracted.\")\n",
        "\n",
        "  return majority_voted_answers"
      ],
      "metadata": {
        "id": "jDhCcKwLYKQs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "big_retriever = big_vectorstore.as_retriever(search_kwargs={\"k\": 3}) #top 3 문서반환\n",
        "big_qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 retriever=big_retriever,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 chain_type_kwargs={\n",
        "                                     \"prompt\":prompt_template,\n",
        "                                     \"document_variable_name\": \"context\",\n",
        "                                 })"
      ],
      "metadata": {
        "id": "P26X5yKSNE2p"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_retriever = small_vectorstore.as_retriever(search_kwargs={\"k\": 5}) #top 5 문서반환\n",
        "small_qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 retriever=small_retriever,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 chain_type_kwargs={\n",
        "                                     \"prompt\":prompt_template,\n",
        "                                     \"document_variable_name\": \"context\",\n",
        "                                 })"
      ],
      "metadata": {
        "id": "E-QJEvuwNHO9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 retriever의 결과를 ensemble\n",
        "retriever = EnsembleRetriever(\n",
        "    retrievers=[big_retriever, small_retriever],\n",
        "    weights=[0.3, 0.7]    # small chunk의 정확도가 더 높을 때 small에 가중치↑\n",
        ")\n",
        "\n",
        "ensemble_qa = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                 retriever=retriever,\n",
        "                                 chain_type=\"stuff\",\n",
        "                                 chain_type_kwargs={\n",
        "                                     \"prompt\":prompt_template,\n",
        "                                     \"document_variable_name\": \"context\",\n",
        "                                 })"
      ],
      "metadata": {
        "id": "HE1K5aT4NIjw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMLU_Pro1"
      ],
      "metadata": {
        "id": "M_4y12K_EE3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_classifier = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "4lm64PD2ER1-"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solver = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1,\n",
        ")"
      ],
      "metadata": {
        "id": "xmYHm7TBESd-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_solar_pro = ChatUpstage(\n",
        "    api_key=UPSTAGE_API_KEY,\n",
        "    model=\"solar-pro2\",\n",
        "    temperature=0.1, #거의 항상 같은 결과, 안정적이게\n",
        ")"
      ],
      "metadata": {
        "id": "doO_rczaEUQK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = {\n",
        "    \"law\":        \"./mmlu_category/law\",\n",
        "    \"psychology\": \"./mmlu_category/psychology\",\n",
        "    \"business\":   \"./mmlu_category/business\",\n",
        "    \"philosophy\": \"./mmlu_category/philosophy\",\n",
        "    \"history\":    \"./mmlu_category/history\",\n",
        "}\n",
        "\n",
        "categories = list(category_index.keys())"
      ],
      "metadata": {
        "id": "M80hT4SJEVZD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large-passage\")\n",
        "\n",
        "# 카테고리별 faiss 한번에 로드해서 캐시\n",
        "vectorstore = {}\n",
        "for cat, path in category_index.items():\n",
        "    vectorstore[cat] = FAISS.load_local(\n",
        "        folder_path=path,\n",
        "        embeddings=emb,\n",
        "        allow_dangerous_deserialization=True,\n",
        "    )\n",
        "\n",
        "wiki = wikipediaapi.Wikipedia(user_agent= \"NLP-RAG/1.0\", language = 'en')"
      ],
      "metadata": {
        "id": "peSTOaMsEcuv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import json\n",
        "\n",
        "# 질문 분석을 위한 전용 프롬프트\n",
        "P_ANALYZE_TMPL = \"\"\"\n",
        "You are an expert Question Analyst for MMLU-Pro.\n",
        "Your task is NOT to answer the question, but to dissect it so that a researcher can find the best evidence.\n",
        "\n",
        "[Available Categories]\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "- other\n",
        "\n",
        "[Task]\n",
        "Analyze the question and options to provide a structured JSON output.\n",
        "You must differentiate between search strategies for **Textbooks** (Vector DB) and **Wikipedia** (Keyword Match).\n",
        "\n",
        "[Output Fields]\n",
        "1. \"category\": Choose ONE from the list above.\n",
        "2. \"core_intent\": Summarize what the question is asking in 1 sentence.\n",
        "3. \"constraints\": List strict conditions (time period, specific person, negation 'NOT', location).\n",
        "4. \"search_queries\": Generate 3-5 **sentence-style** queries for vector search.\n",
        "   - **CRITICAL**: Translate specific scenarios into **Professional/Legal/Academic Terminology**.\n",
        "   - Example: \"Man hit neighbor\" -> \"Tort law battery elements\"\n",
        "5. \"wiki_keywords\": Extract 3-5 **specific entities or nouns** for Wikipedia title search.\n",
        "   - Example: [\"Battery (tort)\", \"Common law\", \"Trespass\"]\n",
        "\n",
        "[Example Shot]\n",
        "Question: \"According to Jean Piaget, at which stage of cognitive development do children begin to think logically about abstract concepts and hypothetical situations?\"\n",
        "Options: (A) Sensorimotor (B) Preoperational (C) Concrete operational (D) Formal operational\n",
        "\n",
        "Output:\n",
        "{{\n",
        "  \"category\": \"psychology\",\n",
        "  \"core_intent\": \"Identify the Piagetian stage associated with abstract and hypothetical reasoning.\",\n",
        "  \"constraints\": [\"Jean Piaget's theory\", \"Abstract concepts\", \"Hypothetical situations\", \"Logic\"],\n",
        "  \"search_queries\": [\n",
        "    \"Piaget cognitive development stages abstract reasoning\",\n",
        "    \"Characteristics of formal operational stage\",\n",
        "    \"Difference between concrete and formal operational stages\"\n",
        "  ],\n",
        "  \"wiki_keywords\": [\n",
        "    \"Jean Piaget\",\n",
        "    \"Cognitive development\",\n",
        "    \"Formal operational stage\",\n",
        "    \"Theory of cognitive development\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "[Real Input]\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Options:\n",
        "{options_text}\n",
        "\n",
        "Return ONLY the valid JSON object.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_analyze_prompt = ChatPromptTemplate.from_template(P_ANALYZE_TMPL)\n",
        "\n",
        "def run_p_analyze(question_text: str, options: dict, llm=None) -> dict:\n",
        "    \"\"\"\n",
        "    질문을 분석하여 검색 쿼리와 제약 조건을 추출합니다.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        llm = llm_solver  # 기존에 정의된 llm 객체 사용\n",
        "\n",
        "    # 옵션 텍스트화\n",
        "    options_str = \"\\n\".join([f\"({k}) {v}\" for k, v in options.items()])\n",
        "\n",
        "    messages = p_analyze_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        options_text=options_str\n",
        "    )\n",
        "\n",
        "    resp = llm.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # JSON 파싱 (실패 시 기본값 반환 처리 포함)\n",
        "    try:\n",
        "        # 마크다운 코드 블록 제거 등 기본적인 정제\n",
        "        if \"```json\" in raw:\n",
        "            raw = raw.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in raw:\n",
        "            raw = raw.split(\"```\")[0].strip()\n",
        "\n",
        "        analysis = json.loads(raw)\n",
        "        return analysis\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] p_analyze failed: {e}\")\n",
        "        # 실패 시 기본값: 검색어는 질문 그대로\n",
        "        return {\n",
        "            \"core_intent\": \"Unknown\",\n",
        "            \"constraints\": [],\n",
        "            \"search_queries\": [question_text]\n",
        "        }"
      ],
      "metadata": {
        "id": "O2WxIK7YEgfX"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wiki_context(keywords, window_size=2000):\n",
        "    snippets = []\n",
        "    seen_titles = set()\n",
        "\n",
        "    for kw in keywords:\n",
        "        kw = (kw or \"\").strip()\n",
        "        if not kw: continue\n",
        "\n",
        "        candidates = [kw, kw.title()]\n",
        "        # 괄호 제거 등 추가 처리\n",
        "        if \"(\" in kw: candidates.append(kw.split(\"(\")[0].strip())\n",
        "\n",
        "        found_flag = False\n",
        "        for cand in candidates:\n",
        "            if cand in seen_titles: continue\n",
        "\n",
        "            try:\n",
        "                page = wiki.page(cand)\n",
        "                if page.exists():\n",
        "                    seen_titles.add(cand)\n",
        "                    full_text = page.text\n",
        "\n",
        "                    # [개선] 단순히 앞부분만 자르는 게 아니라, 키워드가 등장하는 위치를 찾음\n",
        "                    # 키워드가 텍스트 내에 있으면 그 주변을 가져옴. 없으면 앞부분 가져옴.\n",
        "                    lower_text = full_text.lower()\n",
        "                    lower_kw = kw.lower()\n",
        "                    start_idx = lower_text.find(lower_kw)\n",
        "\n",
        "                    if start_idx == -1:\n",
        "                        # 키워드 못 찾으면 그냥 앞부분\n",
        "                        display_text = full_text[:window_size]\n",
        "                    else:\n",
        "                        # 키워드 주변부 (앞으로 500자, 뒤로 1500자 정도)\n",
        "                        start_pos = max(0, start_idx - 500)\n",
        "                        end_pos = min(len(full_text), start_idx + window_size)\n",
        "                        display_text = full_text[start_pos:end_pos]\n",
        "\n",
        "                    clean_text = display_text.replace('\\n', ' ')\n",
        "                    snippets.append(f\"[Wikipedia: {page.title}]\\n...{clean_text}...\")\n",
        "                    found_flag = True\n",
        "                    break\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    if not snippets:\n",
        "        return \"\"\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ],
      "metadata": {
        "id": "77x_yybnEhsQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 0. 상수 & 기본 설정\n",
        "############################################\n",
        "\n",
        "TOP_K_TEXTBOOK = 5\n",
        "TOP_K_WIKI = 5"
      ],
      "metadata": {
        "id": "QXhBT4G3Ei2k"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 1. 질문 + 옵션(A~I) 파싱\n",
        "############################################\n",
        "\n",
        "# 1. 질문 + 옵션(A~J) 파싱\n",
        "def parse_question_and_options(prompt: str):\n",
        "    \"\"\"\n",
        "    prompt: QUESTION + (A) ~ (J) 옵션이 한 문자열에 들어있는 형태\n",
        "    return: question_text(str), options(dict: 'A'~'J' -> str)\n",
        "    \"\"\"\n",
        "    pattern = r\"\\(([A-J])\\)\\s*\"\n",
        "    matches = list(re.finditer(pattern, prompt))\n",
        "\n",
        "    if not matches:\n",
        "        return prompt.strip(), {}\n",
        "\n",
        "    first = matches[0]\n",
        "    question_text = prompt[:first.start()].strip()\n",
        "\n",
        "    options: Dict[str, str] = {}\n",
        "    for idx, m in enumerate(matches):\n",
        "        letter = m.group(1)  # 'A'~'J'\n",
        "        start = m.end()\n",
        "        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(prompt)\n",
        "        opt_text = prompt[start:end].strip()\n",
        "        options[letter] = opt_text\n",
        "\n",
        "    return question_text, options"
      ],
      "metadata": {
        "id": "yAfT1M4ZEssD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 2. \"Final Answer: X\" 파서\n",
        "############################################\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    p_ans 출력에서 'Final Answer: X' 의 X(A~J)를 뽑기.\n",
        "    \"\"\"\n",
        "    m = re.search(r\"Final Answer:\\s*([A-J])\\s*$\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if m:\n",
        "        return m.group(1).upper()\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "C_JNmk8yEuVA"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################\n",
        "# 3. Memory p_gen (INTERNAL 문서 생성)\n",
        "############################################\n",
        "\n",
        "P_MEM_TMPL = \"\"\"\n",
        "You are a knowledgeable expert in {category}.\n",
        "\n",
        "Task: Using ONLY your own internal knowledge (without seeing any external documents),\n",
        "generate a short document that provides accurate and relevant information to help\n",
        "answer the given exam question.\n",
        "\n",
        "If you truly do not know the answer or lack enough information, explicitly state\n",
        "\"I don't know\" rather than hallucinating facts.\n",
        "\n",
        "Exam Question:\n",
        "{question_text}\n",
        "\n",
        "Write ONE coherent document that:\n",
        "- Focuses only on concepts, definitions, and relations that are relevant to the question.\n",
        "- Is self-contained and clear enough to help another model answer the question.\n",
        "- Avoids unnecessary details.\n",
        "\n",
        "Document:\n",
        "\"\"\".strip()\n",
        "\n",
        "p_mem_prompt = ChatPromptTemplate.from_template(P_MEM_TMPL)\n",
        "\n",
        "\n",
        "def run_p_mem(category: str, question_text: str, llm=None) -> str:\n",
        "    if llm is None:\n",
        "        llm = llm_solver\n",
        "    msgs = p_mem_prompt.format_messages(\n",
        "        category=category,\n",
        "        question_text=question_text,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()"
      ],
      "metadata": {
        "id": "7_LTpOwxEzFv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_p_gen_for_docs(\n",
        "    category: str,             # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    source_type: str,          # \"TEXTBOOK\" or \"WIKIPEDIA\"\n",
        "    question_text: str,        # 사용 안 함 (호환성 위해 남겨둠)\n",
        "    raw_passages: List[str],   # 검색된 원본 텍스트 리스트\n",
        "    start_doc_idx: int = 1,\n",
        "    llm=None,                  # 사용 안 함 (호환성 위해 남겨둠)\n",
        ") -> Tuple[str, int]:\n",
        "    \"\"\"\n",
        "    [수정됨] LLM을 통한 요약/재작성을 수행하지 않습니다.\n",
        "    검색된 Raw Passage를 그대로 포맷팅하여 반환합니다.\n",
        "    이렇게 해야 정보 손실(Information Loss) 없이 p_con이나 p_ans 단계로 넘어갑니다.\n",
        "    \"\"\"\n",
        "    doc_blocks = []\n",
        "    cur_idx = start_doc_idx\n",
        "\n",
        "    for k, passage in enumerate(raw_passages, start=1):\n",
        "        # 빈 텍스트 무시\n",
        "        if not passage or not passage.strip():\n",
        "            continue\n",
        "\n",
        "        # [중요] LLM 호출(invoke) 없이 원본 텍스트를 그대로 넣습니다.\n",
        "        # 필요하다면 너무 긴 문단만 파이썬 문자열 슬라이싱으로 자르세요 (예: [:2000])\n",
        "        clean_passage = passage.strip()\n",
        "\n",
        "        block = (\n",
        "            f\"[Doc {cur_idx} | SOURCE=EXTERNAL({source_type}) | ORIG_ID={source_type}_{k}]\\n\"\n",
        "            f\"{clean_passage}\"\n",
        "        )\n",
        "        doc_blocks.append(block)\n",
        "        cur_idx += 1\n",
        "\n",
        "    return \"\\n\\n\".join(doc_blocks), cur_idx"
      ],
      "metadata": {
        "id": "OXCu16TyE0Xp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "############################################\n",
        "# 5. Retrieval helpers (Hybrid: Vector + BM25)\n",
        "############################################\n",
        "\n",
        "# 전역 캐시 (BM25 인덱스를 매번 만들지 않기 위해 저장)\n",
        "bm25_store = {}   # {category: BM25Okapi_object}\n",
        "doc_store = {}    # {category: [text_list]}\n",
        "\n",
        "def init_bm25_for_category(category: str):\n",
        "    \"\"\"\n",
        "    [초기화] 해당 카테고리의 모든 문서를 로드하여 BM25 인덱스를 생성\n",
        "    \"\"\"\n",
        "    if category in bm25_store:\n",
        "        return\n",
        "\n",
        "    if category not in vectorstore:\n",
        "        return\n",
        "\n",
        "    print(f\"[Init] Building BM25 index for: {category}...\")\n",
        "    vs = vectorstore[category]\n",
        "\n",
        "    try:\n",
        "        # FAISS 메모리에서 모든 문서 텍스트 추출\n",
        "        # (주의: FAISS 로드 시 데이터가 메모리에 있어야 함)\n",
        "        all_docs = list(vs.docstore._dict.values())\n",
        "        texts = [d.page_content for d in all_docs]\n",
        "\n",
        "        if not texts:\n",
        "            print(f\"[Warn] No texts found in docstore for {category}.\")\n",
        "            return\n",
        "\n",
        "        # 토크나이징 (단순 띄어쓰기 기준)\n",
        "        tokenized_corpus = [doc.lower().split() for doc in texts]\n",
        "\n",
        "        # 저장\n",
        "        bm25_store[category] = BM25Okapi(tokenized_corpus)\n",
        "        doc_store[category] = texts\n",
        "        print(f\"[Init] BM25 ready for {category} ({len(texts)} docs)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Warn] Failed to init BM25 for {category} (Pure Vector mode will be used): {e}\")\n",
        "\n",
        "\n",
        "def reciprocal_rank_fusion(results_list: List[List[str]], k=60) -> List[str]:\n",
        "    \"\"\"\n",
        "    [RRF 알고리즘] 여러 검색 결과의 순위를 합산하여 재정렬\n",
        "    \"\"\"\n",
        "    fused_scores = {}\n",
        "\n",
        "    for docs in results_list:\n",
        "        for rank, doc_text in enumerate(docs):\n",
        "            if doc_text not in fused_scores:\n",
        "                fused_scores[doc_text] = 0\n",
        "            # 순위가 높을수록(rank가 작을수록) 높은 점수 부여\n",
        "            fused_scores[doc_text] += 1 / (rank + k)\n",
        "\n",
        "    # 점수 높은 순 정렬\n",
        "    reranked = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [text for text, score in reranked]\n",
        "\n",
        "\n",
        "def get_textbook_passages(category: str, query: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    [수정된 함수] Hybrid Search 적용\n",
        "    1. Vector Search (의미 검색) -> 10개\n",
        "    2. BM25 Search (키워드 검색) -> 10개\n",
        "    3. RRF Fusion -> 상위 5개 반환\n",
        "    \"\"\"\n",
        "    if category not in vectorstore:\n",
        "        return []\n",
        "\n",
        "    # 0. BM25 준비\n",
        "    if category not in bm25_store:\n",
        "        init_bm25_for_category(category)\n",
        "\n",
        "    # 1. Vector Search (Semantic)\n",
        "    vs = vectorstore[category]\n",
        "    # 후보를 10개 정도 가져옴\n",
        "    vec_candidates = vs.similarity_search(query, k=10)\n",
        "    vec_results = [d.page_content for d in vec_candidates]\n",
        "\n",
        "    # 2. BM25 Search (Keyword) - 만약 준비 안됐으면 생략\n",
        "    bm25_results = []\n",
        "    if category in bm25_store:\n",
        "        bm25 = bm25_store[category]\n",
        "        docs = doc_store[category]\n",
        "\n",
        "        tokenized_query = query.lower().split()\n",
        "        # 키워드 매칭 상위 10개\n",
        "        bm25_results = bm25.get_top_n(tokenized_query, docs, n=10)\n",
        "\n",
        "    # 3. Fusion (하나만 있으면 그것만 반환)\n",
        "    if not bm25_results:\n",
        "        final_passages = vec_results\n",
        "    else:\n",
        "        # 두 결과를 섞음\n",
        "        final_passages = reciprocal_rank_fusion([vec_results, bm25_results], k=60)\n",
        "\n",
        "    # 최종 TOP_K 개수만큼 자르기\n",
        "    return final_passages[:TOP_K_TEXTBOOK]\n",
        "\n",
        "\n",
        "def get_wiki_passages(keywords: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    (기존 유지)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        raw = fetch_wiki_context(keywords)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Wikipedia retrieval failed: {e}\")\n",
        "        return []\n",
        "\n",
        "    raw = (raw or \"\").strip()\n",
        "    if not raw:\n",
        "        return []\n",
        "    return [raw]"
      ],
      "metadata": {
        "id": "P6A1usHqFCXf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "P_CON_TMPL = \"\"\"\n",
        "You are a Knowledge Integrator for MMLU-Pro dataset.\n",
        "\n",
        "Task: Consolidate information from both your own memorized documents (INTERNAL)\n",
        "and externally retrieved documents (EXTERNAL) in response to the given exam question.\n",
        "\n",
        "Guidelines:\n",
        "* For documents that provide consistent information, cluster them together and\n",
        "  summarize the key details into a single, concise document.\n",
        "* For documents with conflicting information, separate them into distinct documents,\n",
        "  ensuring each document captures the unique perspective or data.\n",
        "* Exclude any information that is irrelevant to the question.\n",
        "* For each NEW document you create, clearly indicate:\n",
        "  - Whether the source was INTERNAL(MEMORY) or EXTERNAL(TEXTBOOK/WIKIPEDIA).\n",
        "  - The original document numbers that contributed to it (e.g., FROM=1,3,4).\n",
        "\n",
        "[Examples]\n",
        "\n",
        "<Example 1: Conflict Resolution>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=INTERNAL(MEMORY)]\n",
        "The Treaty of Versailles was signed in 1918.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "The Treaty of Versailles was signed on June 28, 1919, officially ending WWI.\n",
        "\n",
        "Question: When was the Treaty of Versailles signed?\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(TEXTBOOK) | FROM=2]\n",
        "The Treaty of Versailles was signed on June 28, 1919.\n",
        "(Correction: Internal memory incorrectly stated 1918, which was the armistice year, not the treaty signing.)\n",
        "</Example 1>\n",
        "\n",
        "<Example 2: Merging Consistent Info>\n",
        "Initial Context:\n",
        "[Doc 1 | SOURCE=EXTERNAL(WIKIPEDIA)]\n",
        "Classical conditioning involves a neutral stimulus becoming a conditioned stimulus.\n",
        "[Doc 2 | SOURCE=EXTERNAL(TEXTBOOK)]\n",
        "Pavlov's dog experiment demonstrated classical conditioning by pairing a bell with food.\n",
        "\n",
        "Question: Explain the mechanism of classical conditioning.\n",
        "\n",
        "New Context:\n",
        "[Doc 1 | SOURCE=MERGED(EXTERNAL) | FROM=1,2]\n",
        "Classical conditioning is a learning process where a neutral stimulus (like a bell) becomes a conditioned stimulus after being paired with an unconditioned stimulus (like food). This was demonstrated in Pavlov's dog experiment.\n",
        "</Example 2>\n",
        "\n",
        "[Real Task]\n",
        "\n",
        "Initial Context (numbered documents):\n",
        "{context_init}\n",
        "\n",
        "Last Context (may be empty):\n",
        "{last_context}\n",
        "\n",
        "Question:\n",
        "{question_text}\n",
        "\n",
        "Now produce your New Context following the examples.\n",
        "\"\"\".strip()\n",
        "\n",
        "p_con_prompt = ChatPromptTemplate.from_template(P_CON_TMPL)\n",
        "\n",
        "def run_p_con(\n",
        "    question_text: str,\n",
        "    context_init: str,\n",
        "    last_context: str = \"\",\n",
        "    llm=None,\n",
        ") -> str:\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    msgs = p_con_prompt.format_messages(\n",
        "        question_text=question_text,\n",
        "        context_init=context_init,\n",
        "        last_context=last_context,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    return resp.content.strip()\n"
      ],
      "metadata": {
        "id": "mbYgqEqGFEfb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# 7. Knowledge Consolidation + Answer Finalization p_ans (10-Option Optimized)\n",
        "############################################\n",
        "\n",
        "import re\n",
        "\n",
        "def extract_final_answer_letter(text: str) -> str:\n",
        "    \"\"\"\n",
        "    모델이 내뱉는 다양한 형식을 모두 잡아내는 강력한 추출 함수\n",
        "    \"\"\"\n",
        "    if not text: return \"\"\n",
        "\n",
        "    # 1순위: \"Final Answer\" 뒤에 오는 첫 번째 영문자 (A-J) 찾기\n",
        "    # 예: \"**Final Answer:** (A)\", \"Final Answer: Option A\", \"Final Answer is [A]\"\n",
        "    # [^\\nA-J]* : 줄바꿈이나 A-J가 나오기 전까지의 모든 특수문자(:, *, 공백 등)를 무시\n",
        "    match = re.search(r\"Final Answer[^\\nA-J]*([A-J])\", text, flags=re.IGNORECASE | re.MULTILINE)\n",
        "    if match:\n",
        "        return match.group(1).upper()\n",
        "\n",
        "    # 2순위: <ANSWER> 태그 (프롬프트에서 지시한 경우)\n",
        "    match_tag = re.search(r\"<ANSWER>\\s*\\(?([A-J])\\)?\", text, flags=re.IGNORECASE)\n",
        "    if match_tag:\n",
        "        return match_tag.group(1).upper()\n",
        "\n",
        "    # 3순위: 최후의 수단 - 문장 맨 끝에 있는 (A) 형태 찾기\n",
        "    fallback = re.findall(r\"\\(?([A-J])\\)?\", text.split(\"\\n\")[-1])\n",
        "    if fallback:\n",
        "        return fallback[-1].upper()\n",
        "\n",
        "    return \"\" # 정말 답이 없는 경우\n"
      ],
      "metadata": {
        "id": "UzHMcemxFFuh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CATEGORY_META = {\n",
        "    \"law\": {\n",
        "        \"role\": (\n",
        "            \"You are a distinguished Law Professor and Bar Exam Grader. \"\n",
        "            \"You specialize in applying strict legal doctrines to complex fact patterns. \"\n",
        "            \"Your expertise covers Contracts, Torts, Criminal Law, Property, Constitutional Law, and Evidence.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Spot the precise legal issue (e.g., specific crime, tort, contract doctrine).\\n\"\n",
        "            \"- Apply traditional common-law elements unless a statute in the context clearly overrides them.\\n\"\n",
        "            \"- For crimes, require that ALL elements are satisfied; if one element is missing, that crime is wrong.\\n\"\n",
        "            \"- For 'best defense' or 'most likely' questions, prefer options that directly attack missing elements or raise strong procedural bars \"\n",
        "            \"(e.g., Statute of Frauds, Statute of Limitations).\"\n",
        "        ),\n",
        "    },\n",
        "    \"business\": {\n",
        "        \"role\": (\n",
        "            \"You are a CPA (Certified Public Accountant) and Economics Professor. \"\n",
        "            \"You excel at financial accounting, managerial accounting, corporate finance, and micro/macroeconomics.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Carefully extract all numerical data and relationships before computing.\\n\"\n",
        "            \"- Show each calculation step explicitly (no guessing): check signs, totals, and units.\\n\"\n",
        "            \"- For finance questions, check if time value of money (PV/FV, discounting) is implied by dates or interest rates.\\n\"\n",
        "            \"- For conceptual items, ground answers in standard models (supply/demand, elasticity, basic game theory) rather than intuition.\"\n",
        "        ),\n",
        "    },\n",
        "    \"history\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert Historian specializing in primary source analysis. \"\n",
        "            \"You handle World, U.S., European, and Asian history with a focus on chronology and causality.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- First fix the time period and region using names, events, or terminology.\\n\"\n",
        "            \"- Eliminate options that are anachronistic (wrong century, wrong ruler, wrong war).\\n\"\n",
        "            \"- Distinguish short-term triggers from long-term structural causes when evaluating explanations.\\n\"\n",
        "            \"- When reading passages, consider author, audience, and purpose to match the most plausible interpretation.\"\n",
        "        ),\n",
        "    },\n",
        "    \"philosophy\": {\n",
        "        \"role\": (\n",
        "            \"You are an expert Philosopher specializing in Ethics, Metaphysics, and Epistemology. \"\n",
        "            \"You are precise with terminology and familiar with canonical arguments (Kant, Mill, Aristotle, etc.).\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- Identify the relevant school or author first (e.g., Kantian deontology vs. Millian utilitarianism).\\n\"\n",
        "            \"- Pay close attention to technical terms (e.g., validity vs. truth, necessary vs. sufficient, a priori vs. a posteriori).\\n\"\n",
        "            \"- Reject options that contradict the core commitments of the view (e.g., utilitarianism ignoring consequences).\\n\"\n",
        "            \"- Prefer options that match the exact formulation of the principle, not just something that sounds reasonable.\"\n",
        "        ),\n",
        "    },\n",
        "    \"psychology\": {\n",
        "        \"role\": (\n",
        "            \"You are a Clinical and Research Psychologist. \"\n",
        "            \"You specialize in DSM-5 criteria, developmental stages, cognitive psychology, and experimental design.\"\n",
        "        ),\n",
        "        \"guidelines\": (\n",
        "            \"- For diagnosis, match symptoms strictly to DSM-5 criteria, especially duration, severity, and exclusion conditions.\\n\"\n",
        "            \"- For development/theory items, map behaviors to the correct named theory and precise stage (e.g., Piaget, Kohlberg, Erikson).\\n\"\n",
        "            \"- In research design questions, clearly identify IV, DV, and likely confounds; distinguish correlation from causation.\\n\"\n",
        "            \"- For ethics scenarios, prioritize APA principles such as informed consent, confidentiality, and minimizing harm.\"\n",
        "        ),\n",
        "    },\n",
        "}\n",
        "\n",
        "DEFAULT_CATEGORY_META = {\n",
        "    \"role\": (\n",
        "        \"You are an expert exam solver for MMLU-Pro. You are careful, analytical, and precise.\"\n",
        "    ),\n",
        "    \"guidelines\": (\n",
        "        \"- Read the QUESTION carefully and respect all stated constraints.\\n\"\n",
        "        \"- Use the provided Context as primary evidence and avoid unsupported assumptions.\\n\"\n",
        "        \"- Eliminate options that conflict with the facts, definitions, or chronology in the Context.\\n\"\n",
        "        \"- Choose the single best-supported option, even if other options seem partially plausible.\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "dyOzljkKFGqQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P_ANS_TMPL = \"\"\"\n",
        "You are an expert multiple-choice exam solver for MMLU-Pro, using an Astute-RAG style reasoning process.\n",
        "\n",
        "[Role]\n",
        "{category_role}\n",
        "\n",
        "[Category-Specific Guidelines]\n",
        "{category_guidelines}\n",
        "\n",
        "You are given:\n",
        "[Initial Context]  (short, noisy, or partial)\n",
        "{context_init}\n",
        "\n",
        "[Consolidated Context]  (higher-quality, filtered evidence)\n",
        "{context_con}\n",
        "\n",
        "[QUESTION]\n",
        "{question_with_options}\n",
        "\n",
        "Your job is to carefully combine your INTERNAL knowledge with the given EXTERNAL context,\n",
        "and then follow the **three-stage Astute-RAG reasoning** below.\n",
        "\n",
        "--------------------------------\n",
        "Stage 1 – Evidence Aggregation (Astute Step 1)\n",
        "--------------------------------\n",
        "1. From the QUESTION ONLY (ignore context for now), extract 3–5 key clues:\n",
        "   - important concepts, time periods, entities, relationships, or definitions.\n",
        "2. Using the CONTEXT (Initial + Consolidated), list 3–7 **relevant evidence statements**:\n",
        "   - each statement should be short (1 sentence),\n",
        "   - include only facts that help discriminate between the options.\n",
        "3. If the context contradicts itself, give higher trust to the **Consolidated Context**,\n",
        "   but never violate explicit constraints stated in the QUESTION.\n",
        "\n",
        "--------------------------------\n",
        "Stage 2 – Option-wise Diagnosis with Score & Confidence (Astute Step 2)\n",
        "--------------------------------\n",
        "For each option (A, B, C, D, ...), do the following:\n",
        "\n",
        "1. In 1–2 sentences, compare the option with the key clues + evidence:\n",
        "   - Explain how it is supported or contradicted.\n",
        "   - Check whether it satisfies all critical constraints in the QUESTION.\n",
        "\n",
        "2. Assign three evaluations to this option:\n",
        "   - A **Label**: one of\n",
        "     * \"CLEARLY SUPPORTED\"\n",
        "     * \"PARTIALLY SUPPORTED / DUBIOUS\"\n",
        "     * \"CLEARLY CONTRADICTED\"\n",
        "   - A numerical **Score** between 0 and 1:\n",
        "     * 0.0 ≈ completely wrong, 1.0 ≈ very strongly supported.\n",
        "   - A short **Confidence** phrase: one of [\"high\", \"medium\", \"low\"].\n",
        "\n",
        "Use the following format for each option:\n",
        "\n",
        "Option A:\n",
        "- Reasoning: ...\n",
        "- Label: CLEARLY SUPPORTED\n",
        "- Score: 0.82\n",
        "- Confidence: high\n",
        "\n",
        "(Repeat this exact structure for options B, C, D, ...)\n",
        "\n",
        "--------------------------------\n",
        "Stage 3 – Global Consistency Check & Final Decision (Astute Step 3)\n",
        "--------------------------------\n",
        "1. Look at ALL options, their Labels, and Scores together.\n",
        "2. Eliminate every option that is:\n",
        "   - labeled \"CLEARLY CONTRADICTED\", or\n",
        "   - has Score < 0.30 (unless every option is very low-scoring).\n",
        "3. Among the remaining options, choose **one single BEST** answer by asking:\n",
        "   - Which option is most strongly and directly supported by the evidence and key clues?\n",
        "   - Does any option rely on extra assumptions not justified by the context?\n",
        "4. If two options have similar Scores, briefly explain why the higher one\n",
        "   is still better given the QUESTION wording and constraints.\n",
        "\n",
        "Finally, on the last line of your response, output the answer in the format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "(where X is a single capital letter such as A, B, C, D, ...).\n",
        "Do NOT output anything after this line.\n",
        "\"\"\".strip()\n",
        "p_ans_prompt = ChatPromptTemplate.from_template(P_ANS_TMPL)"
      ],
      "metadata": {
        "id": "WkLpd6V4FHoY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 살짝 변경\n",
        "def run_p_ans(\n",
        "    context_init: str,\n",
        "    context_con: str,\n",
        "    full_question: str,\n",
        "    category: str,\n",
        "    llm=None,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    p_gen/p_con으로 만들어진 context를 기반으로,\n",
        "    astute-RAG 방식(INTERNAL vs EXTERNAL, Step 1~4)을 그대로 따르되,\n",
        "    category별 역할/전략 텍스트를 추가하여 특화된 solver로 동작하게 함.\n",
        "    \"\"\"\n",
        "    if llm is None:\n",
        "        try:\n",
        "            llm = llm_solar_pro\n",
        "        except NameError:\n",
        "            llm = llm_solver\n",
        "\n",
        "    meta = CATEGORY_META.get(category, DEFAULT_CATEGORY_META)\n",
        "\n",
        "    msgs = p_ans_prompt.format_messages(\n",
        "        category_role=meta[\"role\"],\n",
        "        category_guidelines=meta[\"guidelines\"],\n",
        "        context_init=context_init,\n",
        "        context_con=context_con,\n",
        "        question_with_options=full_question,\n",
        "    )\n",
        "    resp = llm.invoke(msgs)\n",
        "    raw = resp.content.strip()\n",
        "    letter = extract_final_answer_letter(raw)\n",
        "    return {\"final_answer\": letter, \"raw_reasoning\": raw}"
      ],
      "metadata": {
        "id": "J8-0wWMCFIpv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_astute_style(\n",
        "    full_prompt: str,\n",
        "    use_wiki: bool = True,\n",
        "    n_vote: int = 5\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 1. 통합 분석 (One-Shot Prompt 적용된 run_p_analyze 사용)\n",
        "    # ---------------------------------------------------------\n",
        "    question_text, options = parse_question_and_options(full_prompt)\n",
        "\n",
        "    try:\n",
        "        # [변경] 여기서 Category, Textbook Query, Wiki Keywords를 한 번에 다 가져옴\n",
        "        analysis = run_p_analyze(question_text, options, llm=llm_solver)\n",
        "    except NameError:\n",
        "        print(\"[Error] run_p_analyze not defined. Using fallback.\")\n",
        "        analysis = {}\n",
        "\n",
        "    # 결과 추출 (안전하게 get 사용)\n",
        "    # 1) 카테고리 (구버전 함수 classify_... 삭제됨)\n",
        "    category = analysis.get(\"category\", \"business\")\n",
        "\n",
        "    # 2) 제약조건\n",
        "    constraints = analysis.get(\"constraints\", [])\n",
        "\n",
        "    # 3) 검색어 분리\n",
        "    # 교과서용 (문장형)\n",
        "    textbook_queries = analysis.get(\"search_queries\", [question_text])\n",
        "    # 위키용 (명사형)\n",
        "    wiki_keywords = analysis.get(\"wiki_keywords\", [])\n",
        "\n",
        "    # [Fallback] 만약 위키 키워드가 비었으면 교과서 쿼리라도 씀\n",
        "    if not wiki_keywords:\n",
        "        wiki_keywords = textbook_queries\n",
        "\n",
        "    print(f\"   -> [Analysis] Category: {category}\")\n",
        "    print(f\"   -> [Textbook Query] {textbook_queries[:1]}...\")\n",
        "    print(f\"   -> [Wiki Keywords] {wiki_keywords}\")\n",
        "\n",
        "    # 벡터 DB 확인\n",
        "    if category not in vectorstore:\n",
        "        print(f\"   -> [Warn] Category '{category}' not found. Fallback to 'business'.\")\n",
        "        category = \"business\"\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 2. 검색 (Dual-Track: Hybrid Vector + Wiki)\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # Track A: Textbook (Vector + BM25 Hybrid)\n",
        "    # 문장형 쿼리에 제약조건을 더해서 문맥 강화\n",
        "    combined_textbook_query = \" \".join(textbook_queries) + \" \" + \" \".join(constraints)\n",
        "    tb_passages = get_textbook_passages(category, combined_textbook_query)\n",
        "\n",
        "    # Track B: Wikipedia (Entity Search)\n",
        "    # 명사형 키워드로 정확한 표제어 매칭\n",
        "    wiki_passages = []\n",
        "    if use_wiki:\n",
        "        wiki_passages = get_wiki_passages(wiki_keywords)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 3. Context 생성 (p_mem -> p_gen -> p_con)\n",
        "    # ---------------------------------------------------------\n",
        "    doc_blocks = []\n",
        "    next_doc_idx = 1\n",
        "\n",
        "    # Internal Memory\n",
        "    mem_doc_text = run_p_mem(category, question_text)\n",
        "    if mem_doc_text.strip():\n",
        "        doc_blocks.append(f\"[Doc {next_doc_idx} | SOURCE=INTERNAL(MEMORY)]\\n{mem_doc_text}\")\n",
        "        next_doc_idx += 1\n",
        "\n",
        "    # Textbook Docs (LLM 요약 없이 Pass-through)\n",
        "    if tb_passages:\n",
        "        tb_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category, \"TEXTBOOK\", question_text, tb_passages, next_doc_idx, None\n",
        "        )\n",
        "        if tb_block.strip(): doc_blocks.append(tb_block)\n",
        "\n",
        "    # Wiki Docs (LLM 요약 없이 Pass-through)\n",
        "    if wiki_passages:\n",
        "        wiki_block, next_doc_idx = run_p_gen_for_docs(\n",
        "            category, \"WIKIPEDIA\", question_text, wiki_passages, next_doc_idx, None\n",
        "        )\n",
        "        if wiki_block.strip(): doc_blocks.append(wiki_block)\n",
        "\n",
        "    context_init = \"\\n\\n\".join(doc_blocks)\n",
        "\n",
        "    # Consolidation\n",
        "    context_con = run_p_con(question_text=question_text, context_init=context_init)\n",
        "\n",
        "    # ---------------------------------------------------------\n",
        "    # 4. Voting (Self-Consistency)\n",
        "    # ---------------------------------------------------------\n",
        "\n",
        "    # Voting용 질문 구성 (제약조건 명시)\n",
        "    constraints_str = \"\\n\".join([f\"- {c}\" for c in constraints])\n",
        "    augmented_question = f\"{full_prompt}\\n\\n[CRITICAL CONSTRAINTS]\\n{constraints_str}\"\n",
        "\n",
        "    # 다양성을 위한 Temperature 설정\n",
        "    llm_voter = ChatUpstage(api_key=UPSTAGE_API_KEY, model=\"solar-pro2\", temperature=0.7)\n",
        "\n",
        "    votes = []\n",
        "    reasonings = []\n",
        "\n",
        "    print(f\"   -> [Voting] Running {n_vote} iterations...\")\n",
        "    for i in range(n_vote):\n",
        "        try:\n",
        "            ans = run_p_ans(\n",
        "                context_init=context_init,\n",
        "                context_con=context_con,\n",
        "                full_question=augmented_question,\n",
        "                category=category,\n",
        "                llm=llm_voter\n",
        "            )\n",
        "            letter = ans[\"final_answer\"]\n",
        "\n",
        "            # 유효한 답만 투표\n",
        "            if letter and letter in \"ABCDEFGHIJ\":\n",
        "                votes.append(letter)\n",
        "\n",
        "            reasonings.append(f\"[Run {i+1} Answer: {letter}]\\n{ans['raw_reasoning']}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      [Vote Error]: {e}\")\n",
        "            continue\n",
        "\n",
        "    # 최종 결과 집계\n",
        "    if not votes:\n",
        "        final_ans = \"A\" # Fallback\n",
        "        vote_summary = \"None\"\n",
        "    else:\n",
        "        # 최빈값 선택\n",
        "        count = Counter(votes)\n",
        "        final_ans = count.most_common(1)[0][0]\n",
        "        vote_summary = str(dict(count))\n",
        "        print(f\"   -> [Result] Winner: {final_ans} | Votes: {vote_summary}\")\n",
        "\n",
        "    full_log = \"\\n\" + \"=\"*40 + \"\\n\".join(reasonings)\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": category,\n",
        "        \"analysis\": analysis,\n",
        "        \"keywords\": wiki_keywords, # 변경됨: extracted_keywords -> wiki_keywords\n",
        "        \"context_init\": context_init,\n",
        "        \"context_con\": context_con,\n",
        "        \"raw_reasoning\": full_log,\n",
        "        \"vote_summary\": vote_summary\n",
        "    }"
      ],
      "metadata": {
        "id": "WA6NwCGJFJlY"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMLU_Pro2"
      ],
      "metadata": {
        "id": "wcaJzXRbGWUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "category_prompt_template = \"\"\"\n",
        "You are an expert exam question category classifier and expert at extracting essential keywords from Question that helps a QA system to retrieve the most relevant context from reference materials.\n",
        "\n",
        "\n",
        "There are 5 possible categories:\n",
        "- law\n",
        "- psychology\n",
        "- business\n",
        "- philosophy\n",
        "- history\n",
        "\n",
        "[Task]\n",
        "Given a multiple-choice exam question (including all options),\n",
        "1. Choose one best category from the list above.\n",
        "2. Extract exactly 3 important keywords (one noun that consists of single word or short phrase)\n",
        "   that will be useful to search textbooks and Wikipedia.\n",
        "   Keywords should be as specific and accurate as possible (e.g., \"consent\",\n",
        "   \"cognitive dissonance\", \"Keynesian economics\").\n",
        "\n",
        "[Output format]\n",
        "Return a valid JSON with the following fields:\n",
        "- \"category\": one of [\"law\",\"psychology\",\"business\",\"philosophy\",\"history\"]\n",
        "- \"keywords\": a list of exactly 3 strings\n",
        "\n",
        "This is an output example:\n",
        "{{\n",
        "  \"category\": \"psychology\",\n",
        "  \"keywords\": [\"informed consent\", \"assent\", \"child counseling\"]\n",
        "}}\n",
        "\n",
        "[Question]\n",
        "{question}\n",
        "\"\"\".strip()\n",
        "\n",
        "category_prompt = ChatPromptTemplate.from_template(category_prompt_template)"
      ],
      "metadata": {
        "id": "rT-pgyZJGl0P"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_and_extract_keywords(question_text: str):\n",
        "    messages = category_prompt.format_messages(question=question_text)\n",
        "    resp = llm_classifier.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    if not raw:\n",
        "        # 완전 빈 응답이면 기본값으로 대충 처리 (죽지 않게)\n",
        "        print(\"[WARN] Empty LLM output for category, fallback to 'history'\")\n",
        "        return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    # 1차 시도: 전체를 JSON으로 해석\n",
        "    try:\n",
        "        data = json.loads(raw)\n",
        "    except json.JSONDecodeError:\n",
        "        # 2차 시도: 문자열 안에서 {...} 구간만 잘라서 해석\n",
        "        start = raw.find(\"{\")\n",
        "        end = raw.rfind(\"}\")\n",
        "        if start == -1 or end == -1:\n",
        "            print(\"[WARN] No JSON object found in output, fallback to 'history'\")\n",
        "            return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "        json_str = raw[start:end+1]\n",
        "        try:\n",
        "            data = json.loads(json_str)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"[WARN] JSON parse failed again:\", e)\n",
        "            return \"history\", [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    category = data.get(\"category\", \"history\").strip().lower()\n",
        "    keywords = data.get(\"keywords\", [])\n",
        "    keywords = [str(k).strip() for k in keywords][:3]\n",
        "\n",
        "    if not keywords:\n",
        "        keywords = [\"history\", \"war\", \"europe\"]\n",
        "\n",
        "    return category, keywords"
      ],
      "metadata": {
        "id": "PgBjr99vGbTN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_wiki_context(keywords, max_chars_per_page=1200):\n",
        "    snippets = []\n",
        "    for kw in keywords:\n",
        "        try:\n",
        "            page = wiki.page(kw)\n",
        "            if not page.exists():\n",
        "                print(f\"[WARN] page for '{kw}' does not exist\")\n",
        "                continue\n",
        "            text = page.text[:max_chars_per_page]\n",
        "            snippets.append(f\"[Wikipedia: {page.title}]\\n{text}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] wikipediaapi fetch failed for '{kw}': {e}\")\n",
        "            continue\n",
        "\n",
        "    return \"\\n\\n\".join(snippets)"
      ],
      "metadata": {
        "id": "ylBEZUlNGo0o"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOP_K_TEXTBOOK = 5\n",
        "\n",
        "def build_context_for_solver(question_text: str, category: str, keywords):\n",
        "    # 1) 카테고리별 textbook RAG\n",
        "    vs = vectorstore[category]\n",
        "    docs = vs.similarity_search(question_text, k=TOP_K_TEXTBOOK)\n",
        "    textbook_context = \"\\n\\n\".join(\n",
        "        f\"[Textbook Doc {i+1}] {d.page_content}\" for i, d in enumerate(docs)\n",
        "    )\n",
        "\n",
        "    # 2) Wikipedia context\n",
        "    wiki_context = fetch_wiki_context(keywords)\n",
        "\n",
        "    full_context = f\"\"\"\\\n",
        "=== TEXTBOOK CONTEXT ({category}) ===\n",
        "{textbook_context}\n",
        "\n",
        "=== WIKIPEDIA CONTEXT (keywords: {', '.join(keywords)}) ===\n",
        "{wiki_context}\n",
        "\"\"\"\n",
        "    return full_context"
      ],
      "metadata": {
        "id": "KvjvK1llGp_0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_LAW_TMPL = \"\"\"\n",
        "You are a U.S. law professor helping a legal QA system retrieve the most relevant authority.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "Use the CONTEXT as textbook + Wikipedia support, but ALWAYS follow these principles:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION FACT PATTERN\n",
        "- First, read the QUESTION (including facts and answer options) very carefully.\n",
        "- Treat the facts and wording in the QUESTION as the primary authority.\n",
        "- Do NOT contradict the facts as stated in the QUESTION.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY LEGAL CLUES FROM THE QUESTION\n",
        "Before judging the options, silently identify 3–5 essential legal clues from the QUESTION itself, such as:\n",
        "- relevant area of law (e.g., common-law robbery, larceny, attempt, accomplice liability, defenses),\n",
        "- key facts about timing, knowledge, intent (mens rea), consent, force, or possession,\n",
        "- jurisdiction assumptions (assume standard U.S. common law / majority rule unless the CONTEXT clearly says otherwise).\n",
        "\n",
        "Base your reasoning on these clues.\n",
        "\n",
        "3) USE CONTEXT CAREFULLY (TEXTBOOK > WIKIPEDIA)\n",
        "- Use the CONTEXT to recall or confirm black-letter rules, elements, and standard doctrines.\n",
        "- If textbook material and Wikipedia conflict, trust the textbook-style explanation in the CONTEXT.\n",
        "- Do NOT narrow or expand a rule beyond what is normally accepted in standard common law / majority doctrine,\n",
        "  unless the CONTEXT explicitly tells you to use a specific variant.\n",
        "\n",
        "4) APPLY BLACK-LETTER LAW PRECISELY\n",
        "- Identify the relevant rule(s) (e.g., elements of common-law larceny, robbery, burglary, receiving stolen property,\n",
        "  attempt, conspiracy, self-defense, etc.).\n",
        "- Apply every element to the facts in the QUESTION.\n",
        "- Pay careful attention to:\n",
        "  - timing of force or threats,\n",
        "  - whether the defendant knew property was stolen,\n",
        "  - whether there was a trespassory taking,\n",
        "  - whether possession was obtained by fraud, trick, or without consent,\n",
        "  - whether any required mental state (intent, knowledge, recklessness, negligence) is clearly present.\n",
        "\n",
        "5) COMPARE EACH OPTION STRICTLY\n",
        "For EACH answer choice:\n",
        "- Explain briefly (in your own reasoning) why it is correct or incorrect,\n",
        "  always referencing specific facts from the QUESTION and the applicable legal rule.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the precise legal definition and all elements,\n",
        "    - correctly reflects the timing and mental state required by the rule,\n",
        "    - does NOT add extra facts not in the QUESTION,\n",
        "    - fits both the QUESTION facts and the CONTEXT.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume extra premises, background facts, or historical claims that are not stated or strongly implied.\n",
        "- Do NOT change the content of a doctrine to make an option fit better; respect standard textbook interpretations.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences.\n",
        "- Write the source you retrived specifically\n",
        "- Do NOT use Markdown formatting (no bullet points, no headings, no **bold**, no code blocks).\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_law = ChatPromptTemplate.from_template(SOLVER_PROMPT_LAW_TMPL)"
      ],
      "metadata": {
        "id": "Hv9VMsw2GrE4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_PHILOSOPHY_TMPL = \"\"\"\n",
        "You are an expert philosophy exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in ethics, meta-ethics, epistemology, metaphysics, logic,\n",
        "philosophy of mind and language, political philosophy, and the history of philosophy\n",
        "(ancient, medieval, modern, and contemporary).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any passage and all answer options) very carefully.\n",
        "- Treat the text and wording of the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY PHILOSOPHICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential philosophical clues, such as:\n",
        "   - the main concept (e.g., categorical imperative, utilitarianism, internalism vs externalism,\n",
        "     Gettier problem, a priori vs a posteriori, necessary vs sufficient conditions),\n",
        "   - the relevant philosopher or school (e.g., Kant, Mill, Hume, Plato, Aristotle, Rawls, behaviorism, logical positivism),\n",
        "   - the logical structure (e.g., what follows from what, which statement would they reject, which principle is violated).\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, distinctions, and canonical views of philosophers.\n",
        "- Do NOT invent new doctrines or attribute views to philosophers that are not well-established.\n",
        "- Apply the standard reading unless the CONTEXT explicitly specifies a different interpretation.\n",
        "\n",
        "4) APPLY PHILOSOPHICAL DOCTRINES PRECISELY\n",
        "- Identify which theory, argument, or distinction the question is really testing.\n",
        "- Pay attention to:\n",
        "  - necessary vs sufficient conditions,\n",
        "  - analytic vs synthetic, a priori vs a posteriori,\n",
        "  - validity vs soundness,\n",
        "  - deontological vs consequentialist reasoning,\n",
        "  - internal vs external justification,\n",
        "  - the exact wording of a principle or formulation (e.g., Kant’s Humanity formulation, Mill’s harm principle).\n",
        "- For “Which of the following would X most likely endorse/reject?” style questions, base your choice on\n",
        "  X’s actual doctrine, not on your own judgment of what is true.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH option:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions or doctrines from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the canonical definition or the philosopher’s standard view,\n",
        "    - captures the fundamental idea of the theory rather than a peripheral detail,\n",
        "    - does not add extra assumptions not stated in the QUESTION,\n",
        "    - uses the correct logical strength (e.g., does not turn “some” into “all,” does not confuse necessary with sufficient).\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume extra premises, background facts, or historical claims that are not stated or strongly implied.\n",
        "- Do NOT change the content of a doctrine to make an option fit better; respect standard textbook interpretations.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_philosophy = ChatPromptTemplate.from_template(SOLVER_PROMPT_PHILOSOPHY_TMPL)"
      ],
      "metadata": {
        "id": "N8QdzTMzGsT-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_PSYCHOLOGY_TMPL = \"\"\"\n",
        "You are an expert psychology exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in clinical psychology, cognitive psychology, social psychology,\n",
        "developmental psychology, personality, biological/physiological psychology, learning, psychometrics,\n",
        "research methods, and ethics (e.g., APA code of conduct).\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any vignette, description, and all answer options) very carefully.\n",
        "- Treat the facts and wording in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY PSYCHOLOGICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential psychological clues, such as:\n",
        "   - the main construct or theory (e.g., classical conditioning, operant conditioning, working memory,\n",
        "     attachment style, Big Five traits, self-efficacy, cognitive dissonance),\n",
        "   - the relevant theorist or model (e.g., Piaget, Vygotsky, Erikson, Kohlberg, Bandura, Beck),\n",
        "   - the developmental stage or level (e.g., preconventional vs conventional, sensorimotor vs formal operational),\n",
        "   - the type of design or method (e.g., experiment vs correlational study, longitudinal vs cross-sectional),\n",
        "   - the key symptoms, behaviors, or ethical requirements described in the vignette.\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, diagnostic criteria (at a conceptual level),\n",
        "  major theories, stages, and classical experiments.\n",
        "- Do NOT invent new constructs or attribute theories to psychologists who are not associated with them.\n",
        "- Apply the standard textbook interpretation unless the CONTEXT explicitly specifies a different one.\n",
        "\n",
        "4) APPLY PSYCHOLOGICAL THEORIES PRECISELY\n",
        "- Identify which theory, construct, stage, or principle the question is really testing.\n",
        "- Pay attention to:\n",
        "  - necessary features vs incidental details of a concept,\n",
        "  - differences between similar concepts (e.g., negative reinforcement vs punishment,\n",
        "    state vs trait, reliability vs validity),\n",
        "  - differences between stages (e.g., Kohlberg’s Stage 1 vs Stage 2, Erikson’s crises),\n",
        "  - the direction of cause/effect or prediction implied by the theory.\n",
        "- For ethics questions (e.g., APA), carefully consider:\n",
        "  - informed consent, confidentiality, competence, dual relationships, and risk of harm,\n",
        "  - what the code obligates the psychologist to do in the specific situation.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions or theories from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the canonical textbook definition or theory,\n",
        "    - directly fits ALL key facts given in the QUESTION (age, setting, behavior, stated intentions),\n",
        "    - does not rely on extra assumptions not stated in the QUESTION,\n",
        "    - has the correct level of generality (not too narrow, not too broad) for the construct or stage.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume additional symptoms, diagnoses, or background history that are not clearly stated.\n",
        "- Do NOT assume the person has specific knowledge or intentions beyond what the QUESTION describes.\n",
        "- Do NOT guess rare or exotic explanations when a standard, well-known theory clearly fits better.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_psychology = ChatPromptTemplate.from_template(SOLVER_PROMPT_PSYCHOLOGY_TMPL)"
      ],
      "metadata": {
        "id": "CfCInWkcGt9D"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_BUSINESS_TMPL = \"\"\"\n",
        "You are an expert business and economics exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and MBA level) in microeconomics, macroeconomics, finance, accounting, management,\n",
        "organizational behavior, marketing, operations, business ethics, and quantitative methods.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any tables, numbers, and all answer options) very carefully.\n",
        "- Treat the facts, numerical data, and wording in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY BUSINESS / ECON CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential clues, such as:\n",
        "   - the main domain (e.g., microeconomics, macroeconomics, corporate finance, accounting, management, marketing),\n",
        "   - key concepts (e.g., opportunity cost, elasticity, present value, NPV, CAPM, break-even point,\n",
        "     comparative advantage, marginal cost/benefit, principal–agent problem, game theory, externalities),\n",
        "   - relevant formulas or relationships (e.g., PV = CF/(1+r)^t, profit = TR – TC, elasticity definitions,\n",
        "     accounting identities, basic statistics),\n",
        "   - organizational/management concepts (e.g., leadership style, motivation theory, decision-making biases),\n",
        "   - business ethics or corporate governance principles.\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL DEFINITIONS AND FORMULAS, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard definitions, formulas, and conceptual relationships.\n",
        "- Do NOT invent new theories or assume non-standard definitions.\n",
        "- Apply the standard textbook interpretation unless the CONTEXT explicitly specifies a different one.\n",
        "\n",
        "4) APPLY BUSINESS / ECONOMIC LOGIC PRECISELY\n",
        "- Identify which concept, model, or calculation the question is really testing.\n",
        "- Pay careful attention to:\n",
        "  - the difference between average vs marginal, stock vs flow, nominal vs real, short run vs long run,\n",
        "  - risk vs return, cost of capital, discounting vs compounding,\n",
        "  - accounting distinctions (asset/liability/equity, revenue vs profit, cash vs accrual),\n",
        "  - supply–demand shifts vs movement along a curve,\n",
        "  - game-theoretic reasoning (dominant strategies, Nash equilibrium),\n",
        "  - basic statistical reasoning (mean, variance, correlation vs causation).\n",
        "- When numbers are given, use them logically and consistently.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - the relevant definitions, models, or formulas from the CONTEXT.\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the exact definitions and standard formulas,\n",
        "    - correctly uses all given information in the QUESTION (including signs, units, and constraints),\n",
        "    - does not rely on extra assumptions not stated in the QUESTION,\n",
        "    - has the correct economic or managerial interpretation (no confusion of cause and effect, or average vs marginal).\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT assume additional data (e.g., extra numbers, extra constraints) that are not given.\n",
        "- Do NOT assume a different market structure, time period, or financial environment unless clearly stated.\n",
        "- Do NOT change definitions (e.g., of elasticity, NPV, beta, ROI) to force an option to fit.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_business = ChatPromptTemplate.from_template(SOLVER_PROMPT_BUSINESS_TMPL)"
      ],
      "metadata": {
        "id": "WmUL2wWTGxsi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOLVER_PROMPT_HISTORY_TMPL = \"\"\"\n",
        "You are an expert history exam solver. You specialize in advanced multiple-choice questions\n",
        "(undergraduate and graduate level) in world history, U.S. history, European history, Asian history,\n",
        "Latin American and African history, intellectual and cultural history, political history,\n",
        "economic history, and questions based on primary-source excerpts.\n",
        "\n",
        "You are given two inputs:\n",
        "\n",
        "[CONTEXT]\n",
        "{context}\n",
        "\n",
        "[QUESTION]\n",
        "{question}\n",
        "\n",
        "The CONTEXT acts like textbook + Wikipedia support. The QUESTION is the primary source.\n",
        "Follow these rules very carefully:\n",
        "\n",
        "1) PRIORITIZE THE QUESTION TEXT\n",
        "- First, read the QUESTION (including any passage, quotation, data, and all answer options) very carefully.\n",
        "- Treat the facts, wording, and time/place cues in the QUESTION as the strongest evidence.\n",
        "- If the CONTEXT conflicts with the QUESTION, you MUST follow the QUESTION.\n",
        "\n",
        "2) EXTRACT KEY HISTORICAL CLUES FROM THE QUESTION\n",
        "When solving the problem, follow this procedure:\n",
        "1. Look only at the [QUESTION] text first and silently extract 3–5 essential historical clues, such as:\n",
        "   - time period or approximate dates (e.g., “late 18th century,” “interwar period,” “Post–World War II”),\n",
        "   - geographic region or polity (e.g., Tang China, Mughal India, Weimar Germany, Cold War United States),\n",
        "   - type of source (e.g., political speech, treaty, law code, memoir, propaganda, religious text),\n",
        "   - key themes (e.g., imperialism, industrialization, nationalism, revolution, reform, decolonization, globalization),\n",
        "   - actors and relationships (e.g., state vs. frontier peoples, colonizer vs. colonized, elite vs. peasantry).\n",
        "2. Then, look at these clues and the CONTEXT and compare them.\n",
        "   - If the logic between the QUESTION clues and the CONTEXT conflicts, trust the QUESTION clues.\n",
        "3. If the clues within textbook-style parts of the CONTEXT and Wikipedia-style parts are conflicted,\n",
        "   trust the textbook-style exposition in the CONTEXT.\n",
        "\n",
        "3) USE CONTEXT TO RECALL HISTORY, NOT TO OVERRIDE THE QUESTION\n",
        "- Use the CONTEXT to recall standard chronology, major events, and characteristic policies or ideas\n",
        "  of states, movements, and historical figures.\n",
        "- Do NOT overwrite or ignore specific details given in the QUESTION (e.g., who is speaking, to whom, and in what setting).\n",
        "- Apply widely accepted historical interpretations unless the CONTEXT or QUESTION clearly specifies a particular viewpoint.\n",
        "\n",
        "4) INTERPRET SOURCES AND CAUSALITY CAREFULLY\n",
        "- For questions based on a passage or source:\n",
        "  - Focus on what the author explicitly states and what is strongly implied by the text.\n",
        "  - Distinguish between what the author approves of and what they criticize.\n",
        "  - Note the tone, audience, and purpose (e.g., justify a policy, criticize a ruler, mobilize support).\n",
        "- Pay careful attention to:\n",
        "  - cause vs. effect (do not confuse consequences with causes),\n",
        "  - continuity vs. change over time,\n",
        "  - similarities vs. differences between regions or periods,\n",
        "  - whether the question is asking for context, consequence, motivation, or historical significance.\n",
        "\n",
        "5) COMPARE EACH OPTION CAREFULLY\n",
        "For EACH answer choice:\n",
        "- Briefly evaluate why it could be correct or incorrect, using explicit references to:\n",
        "  - the key clues you extracted from the QUESTION, and\n",
        "  - relevant facts or patterns from the CONTEXT (chronology, policies, institutions, conflicts).\n",
        "- When TWO OR MORE options seem partially correct:\n",
        "  * Prefer the option that:\n",
        "    - best matches the specific time, place, and actors indicated in the QUESTION,\n",
        "    - fits the main theme or process the QUESTION is testing,\n",
        "    - does not rely on anachronistic assumptions or events from a different period,\n",
        "    - avoids overgeneralization or mixing different regions or eras.\n",
        "\n",
        "6) AVOID HALLUCINATIONS\n",
        "- Do NOT introduce additional events, dates, or policies that are not supported by the QUESTION or reliable CONTEXT.\n",
        "- Do NOT move events to different centuries or regions just to make an option fit.\n",
        "- Do NOT attribute quotes or ideas to the wrong person or regime.\n",
        "- If the context is incomplete, choose the MOST reasonable answer that fits BOTH the QUESTION and the reliable parts of the CONTEXT,\n",
        "  and do not contradict the given evidence.\n",
        "\n",
        "7) CONSISTENCY CHECK BETWEEN REASONING AND OPTIONS\n",
        "Before you output the final answer, you MUST do a short consistency check:\n",
        "- First, clearly state in one sentence what you believe the correct answer is\n",
        "  (for numerical questions, state the exact number; for conceptual questions, state the exact statement or rule).\n",
        "- Then, choose an option ONLY if it exactly matches that stated conclusion.\n",
        "- If none of the options exactly match your stated conclusion, you MUST:\n",
        "  1) re-check your reasoning or calculation once, and\n",
        "  2) update your conclusion so that it matches a standard rule or formula from the CONTEXT,\n",
        "     and then select the option that exactly matches this corrected conclusion.\n",
        "- You are NOT allowed to pick an option just because it is “closest” to your conclusion.\n",
        "\n",
        "8) STYLE AND FINAL ANSWER FORMAT\n",
        "- Write your reasoning in plain text sentences (no bullet points, no headings, no Markdown formatting like ** or #).\n",
        "- Be concise but logically clear.\n",
        "- At the very end, on a NEW LINE, output the final answer in the exact format:\n",
        "\n",
        "Final Answer: X\n",
        "\n",
        "where X is a single capital letter (A, B, C, D, ...).\n",
        "- Do NOT wrap this line in Markdown or quotes.\n",
        "- Do NOT add any extra text before or after the 'Final Answer: X' line.\n",
        "- The 'Final Answer: X' line MUST appear only once at the very end.\n",
        "\n",
        "Now, following all of the above rules, reason step by step using the QUESTION and CONTEXT, then give the final answer.\n",
        "\"\"\".strip()\n",
        "\n",
        "solver_prompt_history = ChatPromptTemplate.from_template(SOLVER_PROMPT_HISTORY_TMPL)"
      ],
      "metadata": {
        "id": "kQGCsJ7PGzxH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_with_rag_and_wiki(question_text: str):\n",
        "    final_letter = None\n",
        "    # 1) 1단계 LLM: 카테고리 + 키워드\n",
        "    category, keywords = classify_and_extract_keywords(question_text)\n",
        "    if category not in vectorstore:\n",
        "        print(f\"[WARN] Unknown category '{category}', fallback to 'business'\")\n",
        "        category = \"business\"\n",
        "\n",
        "    # 2) 컨텍스트 구성 (FAISS + Wikipedia)\n",
        "    context = build_context_for_solver(question_text, category, keywords)\n",
        "\n",
        "    # 3) 2단계 LLM: CoT로 정답 도출\n",
        "    if category == \"law\":\n",
        "      messages = solver_prompt_law.format_messages(\n",
        "          context=context,\n",
        "          question=question_text\n",
        "      )\n",
        "    elif category == \"philosophy\":\n",
        "      messages = solver_prompt_philosophy.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"psychology\":\n",
        "      messages = solver_prompt_psychology.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"business\":\n",
        "      messages = solver_prompt_business.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "    elif category == \"history\":\n",
        "        messages = solver_prompt_history.format_messages(\n",
        "          context=context,\n",
        "          question=question_text,\n",
        "      )\n",
        "\n",
        "    resp = llm_solver.invoke(messages)\n",
        "    raw = resp.content.strip()\n",
        "\n",
        "    # (1) 아래쪽 줄부터 \"FINAL ANSWER\"가 들어간 줄 찾기 (마크다운 포함 허용)\n",
        "    for line in raw.splitlines()[::-1]:  # 아래에서부터 검색\n",
        "        s = line.strip()\n",
        "\n",
        "        # '**Final Answer: A**' 같이 생긴 것도 잡기 위해 'in' 사용\n",
        "        if \"FINAL ANSWER\" in s.upper():\n",
        "            # 마크다운 볼드 제거\n",
        "            s = s.replace(\"**\", \"\").strip()\n",
        "            # 정규식으로 'Final Answer: X'에서 X만 뽑기\n",
        "            m = re.search(r\"FINAL ANSWER\\s*:\\s*([A-Z])\", s, re.IGNORECASE)\n",
        "            if m:\n",
        "                final_letter = m.group(1).upper()\n",
        "                break\n",
        "\n",
        "    # 그래도 못 찾으면, 전체 텍스트에서 대문자 한 글자 검색\n",
        "    if final_letter is None:\n",
        "        for ch in raw:\n",
        "            if \"A\" <= ch <= \"Z\":\n",
        "                final_letter = ch\n",
        "                break\n",
        "\n",
        "    return {\n",
        "        \"category\": category,\n",
        "        \"keywords\": keywords,\n",
        "        \"raw_reasoning\": raw,       # 디버깅/분석용\n",
        "        \"final_answer\": final_letter,\n",
        "    }"
      ],
      "metadata": {
        "id": "zuM_qWD6G13B"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## mmlu용 majority voting 함수"
      ],
      "metadata": {
        "id": "yeYWPeFOlc_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from typing import Callable, Dict, Any\n",
        "\n",
        "def majority_vote_mmlu(\n",
        "    solve_once_fn: Callable[[str], Dict[str, Any]],\n",
        "    prompt: str,\n",
        "    n_vote: int = 5,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    solve_once_fn: full_prompt(str) -> {\"final_answer\": \"A\", ...} 형태로 결과를 주는 함수\n",
        "    prompt: 문제 전체 문자열 (질문 + 보기)\n",
        "    n_vote: 몇 번 반복할지 (기본 5번)\n",
        "\n",
        "    return:\n",
        "        {\n",
        "          \"final_answer\": \"A\",\n",
        "          \"all_votes\": [\"A\",\"B\",\"A\",\"A\",\"C\"],\n",
        "          \"vote_summary\": {\"A\":3, \"B\":1, \"C\":1},\n",
        "          \"winner_run\": <solve_once_fn가 반환한 dict 중에서 우승 답과 같은 걸 하나>\n",
        "        }\n",
        "    \"\"\"\n",
        "    votes = []\n",
        "    outs  = []\n",
        "\n",
        "    for _ in range(n_vote):\n",
        "        out = solve_once_fn(prompt)\n",
        "        outs.append(out)\n",
        "        ans = (out.get(\"final_answer\") or \"\").strip().upper()\n",
        "        if ans and ans in \"ABCDEFGHIJ\":\n",
        "            votes.append(ans)\n",
        "\n",
        "    if not votes:\n",
        "        # 진짜로 답을 하나도 못 뽑으면 fallback\n",
        "        return {\n",
        "            \"final_answer\": \"\",\n",
        "            \"all_votes\": [],\n",
        "            \"vote_summary\": {},\n",
        "            \"winner_run\": outs[0] if outs else {},\n",
        "        }\n",
        "\n",
        "    counter = Counter(votes)\n",
        "    final_ans, _ = counter.most_common(1)[0]\n",
        "\n",
        "    # 우승 답과 같은 run 하나 골라서 reasoning/log 같이 넘겨주기\n",
        "    winner_run = next((o for o in outs if (o.get(\"final_answer\") or \"\").upper() == final_ans), outs[0])\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"all_votes\": votes,\n",
        "        \"vote_summary\": dict(counter),\n",
        "        \"winner_run\": winner_run,\n",
        "    }"
      ],
      "metadata": {
        "id": "TU9oRQ8nlhyT"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트"
      ],
      "metadata": {
        "id": "JnboclVjj564"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_korean(text: str) -> bool:\n",
        "    \"\"\"문자열에 한글이 하나라도 들어있으면 한국어라고 간주.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return False\n",
        "    return bool(re.search(r\"[가-힣]\", text))"
      ],
      "metadata": {
        "id": "w5yL7RhNHb8D"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_ewha_single(prompt: str,\n",
        "                      qa_chain,\n",
        "                      n_vote: int = 5) -> str:\n",
        "    votes = []\n",
        "\n",
        "    for _ in range(n_vote):\n",
        "        response = qa_chain.invoke(prompt)   # {'result': '...', 'source_documents': [...]}\n",
        "        text = response[\"result\"]\n",
        "        ans = extract_answer(text)          # 네가 위에 정의한 extract_answer 사용\n",
        "        if ans:\n",
        "            votes.append(ans.strip().upper())\n",
        "\n",
        "    if not votes:\n",
        "        return \"\"   # 진짜 아무것도 못 뽑으면 빈 문자열\n",
        "\n",
        "    counter = Counter(votes)\n",
        "    final_ans, _ = counter.most_common(1)[0]\n",
        "    return final_ans"
      ],
      "metadata": {
        "id": "s3Y6uWgOlqEa"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_pro1_single(prompt: str, outer_votes: int = 5) -> Dict[str, Any]:\n",
        "    def _solve_once(q: str) -> Dict[str, Any]:\n",
        "        # 내부 self-consistency는 끄고(=1), 외부에서만 5번 투표\n",
        "        out = solve_mmlu_astute_style(\n",
        "            full_prompt=q,\n",
        "            use_wiki=True,\n",
        "            n_vote=1,\n",
        "        )\n",
        "        # solve_mmlu_astute_style이 이미 \"final_answer\" 키를 갖고 있다고 가정\n",
        "        return out\n",
        "\n",
        "    mv = majority_vote_mmlu(_solve_once, prompt, n_vote=outer_votes)\n",
        "\n",
        "    winner = mv[\"winner_run\"]\n",
        "    final_ans = mv[\"final_answer\"]\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": winner.get(\"category\", \"\"),\n",
        "        \"raw_reasoning\": winner.get(\"raw_reasoning\", \"\"),\n",
        "        \"vote_summary\": mv[\"vote_summary\"],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "XhfbdNXeHY31"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_mmlu_pro2_single(prompt: str, outer_votes: int = 5) -> Dict[str, Any]:\n",
        "    def _solve_once(q: str) -> Dict[str, Any]:\n",
        "        out = solve_mmlu_with_rag_and_wiki(q)\n",
        "        return out\n",
        "\n",
        "    mv = majority_vote_mmlu(_solve_once, prompt, n_vote=outer_votes)\n",
        "\n",
        "    winner = mv[\"winner_run\"]\n",
        "    final_ans = mv[\"final_answer\"]\n",
        "\n",
        "    return {\n",
        "        \"final_answer\": final_ans,\n",
        "        \"category\": winner.get(\"category\", \"\"),\n",
        "        \"raw_reasoning\": winner.get(\"raw_reasoning\", \"\"),\n",
        "        \"vote_summary\": mv[\"vote_summary\"],\n",
        "    }\n",
        "    # return final_ans"
      ],
      "metadata": {
        "id": "FC3tc8fAHXRu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION_COL = \"prompts\"\n",
        "df = pd.read_csv(TESTSET_PATH)\n",
        "\n",
        "pred_lang  = []   # 'ko' or 'en'\n",
        "pred_m1    = []   # (ewha + mmlu_pro1) 정답\n",
        "pred_m2    = []   # (ewha + mmlu_pro2) 정답\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    q = str(row[QUESTION_COL])\n",
        "    print(f\"[{i}] Solving: {q[:60]}...\")\n",
        "\n",
        "    if is_korean(q):\n",
        "        # =======================\n",
        "        # 한국어 → Ewha 학칙 RAG\n",
        "        # =======================\n",
        "        pred_lang.append(\"ko\")\n",
        "\n",
        "        ans_ko = solve_ewha_single(\n",
        "            prompt=q,\n",
        "            qa_chain=ensemble_qa,\n",
        "            n_vote=5,\n",
        "        )\n",
        "\n",
        "        # 한국어 문제는 두 버전 CSV 모두 Ewha 답을 사용\n",
        "        pred_m1.append(ans_ko)\n",
        "        pred_m2.append(ans_ko)\n",
        "\n",
        "    else:\n",
        "        # =======================\n",
        "        # 영어 → mmlu_pro1 / mmlu_pro2\n",
        "        # =======================\n",
        "        pred_lang.append(\"en\")\n",
        "\n",
        "        # mmlu_pro1: Astute-RAG + 5번 voting\n",
        "        out1 = solve_mmlu_pro1_single(q, outer_votes=5)\n",
        "        # final_answer만 쓰고 싶으면 이렇게:\n",
        "        ans1 = out1[\"final_answer\"] if isinstance(out1, dict) else out1\n",
        "        pred_m1.append(ans1)\n",
        "\n",
        "        # mmlu_pro2: category RAG + 5번 voting\n",
        "        out2 = solve_mmlu_pro2_single(q, outer_votes=5)\n",
        "        ans2 = out2[\"final_answer\"] if isinstance(out2, dict) else out2\n",
        "        pred_m2.append(ans2)\n",
        "\n",
        "# 길이 체크 (디버깅용)\n",
        "print(\"len(df)   =\", len(df))\n",
        "print(\"len(pred_lang) =\", len(pred_lang))\n",
        "print(\"len(pred_m1)   =\", len(pred_m1))\n",
        "print(\"len(pred_m2)   =\", len(pred_m2))\n",
        "\n",
        "# -------------------------\n",
        "# (ewha + mmlu_pro1) 정답 csv\n",
        "# -------------------------\n",
        "df_m1 = df.copy()\n",
        "df_m1[\"pred_lang\"]      = pred_lang\n",
        "df_m1[\"rag_cot_answer\"] = pred_m1\n",
        "df_m1.to_csv(\"testset_ewha_mmlu1.csv\", index=False)\n",
        "print(\"[Saved] testset_ewha_mmlu1.csv\")\n",
        "\n",
        "# -------------------------\n",
        "# (ewha + mmlu_pro2) 정답 csv\n",
        "# -------------------------\n",
        "df_m2 = df.copy()\n",
        "df_m2[\"pred_lang\"]      = pred_lang\n",
        "df_m2[\"rag_cot_answer\"] = pred_m2\n",
        "df_m2.to_csv(\"testset_ewha_mmlu2.csv\", index=False)\n",
        "print(\"[Saved] testset_ewha_mmlu2.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmmN4y0Jl_8v",
        "outputId": "79f2984e-44b6-4936-e0ce-aee943c0894a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0] Solving: QUESTION1) 재학 중인 학생이 휴학을 하려면 학기 개시일로부터 며칠 이내에 휴학을 신청하야하나요?\n",
            "(...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[1] Solving: QUESTION2) '재입학은 a회에 한하여 할 수 있다. 다만 제 28조제4호에 의하여 제적된 자는 제적된...\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['D', 'A', 'A']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D', 'D']\n",
            "Matched answer: ['D', 'A']\n",
            "[2] Solving: QUESTION3) 학생이 소속 학과 또는 전공 이외의 전공 교과목을 총장이 정하는 바에 따라 몇학점 이상 ...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[3] Solving: QUESTION4) 다음 보기의 학생들 중 제적을 당하지 않는 사람을 고르면?\n",
            "(A) 팜 : 징계에 의해 퇴...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[4] Solving: QUESTION5) 2019학년도 휴먼기계바이오공학부의 입학 정원은 몇 명인가? \n",
            "(A) 90명 \n",
            "(B) 1...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[5] Solving: QUESTION6) 1980학년도 이전 입학생에 대하여 적용하는 등급에 따른 성적점으로 잘못 연결된 것은 무...\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A', 'A']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "[6] Solving: QUESTION7) 사회체육학과 소속 학생에게 수여하는 학위는 무엇인가? \n",
            "(A) 공학사 \n",
            "(B) 문학사 \n",
            "...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[7] Solving: QUESTION8) 복수전공 신청 자격에 해당하지 않는 것은? \n",
            "(A) 1학년을 마친 학생 \n",
            "(B) 평균 평...\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "[8] Solving: QUESTION9) 이화여자대학교의 설립 정신은 무엇인가요?  (A) 공산주의 이념  (B) 불교 정신  (...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[9] Solving: QUESTION10) 이화여자대학교의 위치는 어디인가요?  (A) 강남구  (B) 서대문구  (C) 종로구 ...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[10] Solving: QUESTION11) 학점 기준에 따르면 1학점당 수업 시간은 몇 시간 이상이어야 하나요?  (A) 10시간...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[11] Solving: QUESTION12) 전공과 관련된 조항으로 올바른 것은?\n",
            "(A) 2 이상의 학부가 연계하여 제공하는 전공을...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[12] Solving: QUESTION13) 등록금에 관한 조항으로 올바르지 않은 것은?\n",
            "(A) 총장은 등록금심의위원회의 구성 및 ...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[13] Solving: QUESTION14) 전공과목은 어떻게 구분되는가?\n",
            "(A) 전공기초과목과 전공과목\n",
            "(B) 총장이 따로 정한다...\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "Matched answer: ['C']\n",
            "[14] Solving: QUESTION15) 학칙개정에 관한 설명으로 옳지 않은 것은?\n",
            "(A) 학칙 개정과 대학평의원회는 무관하다....\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "[15] Solving: QUESTION16)계절학기에 취득할 수 있는 최대 학점은 몇 점입니까?\n",
            "(A) 3학점\n",
            "(B) 6학점\n",
            "(C)...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[16] Solving: QUESTION17)졸업하기 위해 총평균 성적이 충족해야 하는 최소 기준은?\n",
            "(A) 1.60\n",
            "(B) 1.70...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[17] Solving: QUESTION18)수업의 결석이 출석으로 인정될 수 있는 사유가 아닌 것은?\n",
            "(A) 중대한 질병\n",
            "(B) 직...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[18] Solving: QUESTION19)조기 졸업을 위한 총 평균 성적 기준은?\n",
            "(A) 2.50\n",
            "(B) 3.00\n",
            "(C) 3.50...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[19] Solving: QUESTION20) 재학 연한 초과로 제적당하지 않는 경우는?\n",
            "(A) 학사 편입\n",
            "(B) 복수 전공 중\n",
            "(C...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[20] Solving: QUESTION21) 졸업이 취소될 수 있는 상황은?\n",
            "(A) 논문 미제출\n",
            "(B) 부정한 방법으로 졸업 인정\n",
            "...\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "Matched answer: ['B']\n",
            "[21] Solving: QUESTION22) 교양과목을 제외한 전공과목의 분류는 무엇입니까?\n",
            "(A) 필수/선택\n",
            "(B) 정규/특별\n",
            "(...\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "Matched answer: ['A']\n",
            "[22] Solving: QUESTION23) 다음중 옳게 짝지어진 학위를 고르세요.\n",
            "(A) 북한 학과 - 이학사\n",
            "(B) 기업가정신 ...\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "Matched answer: ['D']\n",
            "[23] Solving: QUESTION24) 다음 중 이화여자대학교 학칙에서 학점과 관련해 옳은 것을 고르세요\n",
            "(A) 교과과정이수 ...\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "Matched answer: ['D']\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='C'>\n",
            "[24] Solving: QUESTION25) 2019학년도 입학 정원에 대한 내용으로 옳은 것을 고르시오.\n",
            "(A) 휴먼기계바이오공학...\n",
            "Re-matched answer: <re.Match object; span=(349, 350), match='D'>\n",
            "Re-matched answer: <re.Match object; span=(11, 12), match='A'>\n",
            "[25] Solving: QUESTION26) QUESTION 6) A psychologist is asked to see a 10-...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for minor consent in school-based psychological counseling']...\n",
            "   -> [Wiki Keywords] ['Informed consent', \"Minors' legal rights\", 'APA Ethics Code', 'Child assent in therapy', 'Parental consent requirements']\n",
            "[Init] Building BM25 index for: psychology...\n",
            "[Init] BM25 ready for psychology (2232 docs)\n",
            "[WARN] page for 'Minors' legal rights' does not exist\n",
            "[WARN] page for 'Child assent in therapy' does not exist\n",
            "[WARN] page for 'Parental consent requirements' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for minor consent in school-based psychological counseling']...\n",
            "   -> [Wiki Keywords] ['Informed consent', 'Minor consent in psychology', 'APA Ethical Principles of Psychologists and Code of Conduct', 'Child assent in therapy', 'School-based psychological services']\n",
            "[WARN] page for 'Minor consent in psychology' does not exist\n",
            "[WARN] page for 'APA Ethical Principles of Psychologists and Code of Conduct' does not exist\n",
            "[WARN] page for 'Child assent in therapy' does not exist\n",
            "[WARN] page for 'School-based psychological services' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for minor consent in school-based psychological counseling']...\n",
            "   -> [Wiki Keywords] ['Informed consent', \"Minors' legal rights\", 'APA Ethics Code', 'Child assent in therapy', 'School-based mental health services']\n",
            "[WARN] page for 'Minors' legal rights' does not exist\n",
            "[WARN] page for 'Child assent in therapy' does not exist\n",
            "[WARN] page for 'School-based mental health services' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for minor consent in school counseling psychology']...\n",
            "   -> [Wiki Keywords] ['Informed consent', \"Minors' rights in therapy\", 'APA Ethics Code', 'Child assent in research', 'Parental consent legal standards']\n",
            "[WARN] page for 'Minors' rights in therapy' does not exist\n",
            "[WARN] page for 'Child assent in research' does not exist\n",
            "[WARN] page for 'Parental consent legal standards' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Ethical guidelines for minor consent in school-based psychological counseling']...\n",
            "   -> [Wiki Keywords] ['Informed consent', \"Minors' rights in therapy\", 'APA Ethical Principles of Psychologists and Code of Conduct', 'Child assent in psychological treatment', 'Legal guardianship in medical/psychological decision-making']\n",
            "[WARN] page for 'Minors' rights in therapy' does not exist\n",
            "[WARN] page for 'APA Ethical Principles of Psychologists and Code of Conduct' does not exist\n",
            "[WARN] page for 'Child assent in psychological treatment' does not exist\n",
            "[WARN] page for 'Legal guardianship in medical/psychological decision-making' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "[WARN] page for 'child counseling' does not exist\n",
            "[WARN] page for 'child counseling' does not exist\n",
            "[WARN] page for 'child counseling' does not exist\n",
            "[WARN] page for 'written consent' does not exist\n",
            "[WARN] page for 'child counseling' does not exist\n",
            "[WARN] page for 'child counseling' does not exist\n",
            "[26] Solving: QUESTION27) A man is at home in his apartment, alone, late a...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law elements of robbery burglary and trespassing']...\n",
            "   -> [Wiki Keywords] ['Robbery (law)', 'Burglary', 'Trespassing', 'Common law crimes', 'Aggravated assault']\n",
            "[Init] Building BM25 index for: law...\n",
            "[Init] BM25 ready for law (91859 docs)\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law elements of robbery burglary and trespassing']...\n",
            "   -> [Wiki Keywords] ['Robbery (law)', 'Burglary', 'Trespassing', 'Common law crimes', 'Aggravated assault']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law elements of robbery burglary and trespassing']...\n",
            "   -> [Wiki Keywords] ['Robbery (law)', 'Burglary', 'Trespassing', 'Common law crimes', 'Aggravated assault']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law elements of robbery burglary and trespassing']...\n",
            "   -> [Wiki Keywords] ['Robbery (law)', 'Burglary', 'Trespassing', 'Common law crimes', 'Aggravated assault']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law elements of robbery burglary and trespassing']...\n",
            "   -> [Wiki Keywords] ['Robbery (law)', 'Burglary', 'Trespassing', 'Common law crimes', 'Aggravated assault']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: A | Votes: {'A': 1}\n",
            "[27] Solving: QUESTION28) What do Homo sapiens and Australopithecus afaren...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative evolutionary traits between Homo sapiens and Australopithecus afarensis']...\n",
            "   -> [Wiki Keywords] ['Homo sapiens', 'Australopithecus afarensis', 'Bipedalism', 'Human evolution', 'Australopithecine locomotion']\n",
            "[Init] Building BM25 index for: history...\n",
            "[Init] BM25 ready for history (17941 docs)\n",
            "[WARN] page for 'Australopithecine locomotion' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative evolutionary traits between Homo sapiens and Australopithecus afarensis']...\n",
            "   -> [Wiki Keywords] ['Homo sapiens', 'Australopithecus afarensis', 'Bipedalism', 'Human evolution', 'Australopithecine locomotion']\n",
            "[WARN] page for 'Australopithecine locomotion' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative evolutionary traits between Homo sapiens and Australopithecus afarensis']...\n",
            "   -> [Wiki Keywords] ['Homo sapiens', 'Australopithecus afarensis', 'Bipedalism', 'Human evolution', 'Australopithecine locomotion']\n",
            "[WARN] page for 'Australopithecine locomotion' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative evolutionary traits between Homo sapiens and Australopithecus afarensis']...\n",
            "   -> [Wiki Keywords] ['Homo sapiens', 'Australopithecus afarensis', 'Bipedalism', 'Human evolution', 'Australopithecine locomotion']\n",
            "[WARN] page for 'Australopithecine locomotion' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative evolutionary traits Homo sapiens Australopithecus afarensis']...\n",
            "   -> [Wiki Keywords] ['Homo sapiens', 'Australopithecus afarensis', 'Bipedalism', 'Hominin evolution', 'Locomotion in early humans']\n",
            "[WARN] page for 'Hominin evolution' does not exist\n",
            "[WARN] page for 'Locomotion in early humans' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "[WARN] page for 'mode of locomotion' does not exist\n",
            "[28] Solving: QUESTION29)This question refers to the following information...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Tang dynasty frontier policy with nomadic tribes']...\n",
            "   -> [Wiki Keywords] ['Tang dynasty foreign relations', 'Tang dynasty military policy', 'Tang dynasty nomadic relations', 'Du Fu Ballad of the Army Carts', 'Tang-Sogdiana relations']\n",
            "[WARN] page for 'Tang dynasty foreign relations' does not exist\n",
            "[WARN] page for 'Tang dynasty military policy' does not exist\n",
            "[WARN] page for 'Tang dynasty nomadic relations' does not exist\n",
            "[WARN] page for 'Du Fu Ballad of the Army Carts' does not exist\n",
            "[WARN] page for 'Tang-Sogdiana relations' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Tang dynasty frontier policy with nomadic tribes']...\n",
            "   -> [Wiki Keywords] ['Tang dynasty foreign relations', 'Tang dynasty military policy', 'Tang dynasty nomadic tribes', 'Du Fu Ballad of the Army Carts', 'Tang-Sogdiana relations']\n",
            "[WARN] page for 'Tang dynasty foreign relations' does not exist\n",
            "[WARN] page for 'Tang dynasty military policy' does not exist\n",
            "[WARN] page for 'Tang dynasty nomadic tribes' does not exist\n",
            "[WARN] page for 'Du Fu Ballad of the Army Carts' does not exist\n",
            "[WARN] page for 'Tang-Sogdiana relations' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Tang dynasty frontier policy with nomadic tribes']...\n",
            "   -> [Wiki Keywords] ['Tang dynasty foreign relations', 'Tang dynasty military policy', 'Tang dynasty nomadic relations', 'Du Fu Ballad of the Army Carts', 'Tang dynasty frontier administration']\n",
            "[WARN] page for 'Tang dynasty foreign relations' does not exist\n",
            "[WARN] page for 'Tang dynasty military policy' does not exist\n",
            "[WARN] page for 'Tang dynasty nomadic relations' does not exist\n",
            "[WARN] page for 'Du Fu Ballad of the Army Carts' does not exist\n",
            "[WARN] page for 'Tang dynasty frontier administration' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Tang dynasty frontier policy with nomadic tribes']...\n",
            "   -> [Wiki Keywords] ['Tang dynasty foreign relations', 'Tang dynasty military policy', 'Tang dynasty nomadic tribes', 'Du Fu Ballad of the Army Carts', 'Tang-Sogdiana relations']\n",
            "[WARN] page for 'Tang dynasty foreign relations' does not exist\n",
            "[WARN] page for 'Tang dynasty military policy' does not exist\n",
            "[WARN] page for 'Tang dynasty nomadic tribes' does not exist\n",
            "[WARN] page for 'Du Fu Ballad of the Army Carts' does not exist\n",
            "[WARN] page for 'Tang-Sogdiana relations' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Tang dynasty frontier policy with nomadic tribes']...\n",
            "   -> [Wiki Keywords] ['Tang dynasty foreign relations', 'Tang dynasty military policy', 'Tang dynasty nomadic tribes', 'Du Fu Ballad of the Army Carts', 'Tang-Sogdiana relations']\n",
            "[WARN] page for 'Tang dynasty foreign relations' does not exist\n",
            "[WARN] page for 'Tang dynasty military policy' does not exist\n",
            "[WARN] page for 'Tang dynasty nomadic tribes' does not exist\n",
            "[WARN] page for 'Du Fu Ballad of the Army Carts' does not exist\n",
            "[WARN] page for 'Tang-Sogdiana relations' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "[WARN] page for 'Tang relations' does not exist\n",
            "[WARN] page for 'frontier peoples' does not exist\n",
            "[WARN] page for 'Tang relations' does not exist\n",
            "[WARN] page for 'frontier peoples' does not exist\n",
            "[WARN] page for 'Tang relations' does not exist\n",
            "[WARN] page for 'western nomadic peoples' does not exist\n",
            "[WARN] page for 'frontier peoples' does not exist\n",
            "[WARN] page for 'Tang relations' does not exist\n",
            "[WARN] page for 'western nomadic peoples' does not exist\n",
            "[WARN] page for 'frontier peoples' does not exist\n",
            "[WARN] page for 'Tang relations' does not exist\n",
            "[WARN] page for 'frontier peoples' does not exist\n",
            "[29] Solving: QUESTION30)Homo erectus differed from Homo habilis in which ...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative cranial capacity Homo erectus Homo habilis']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Homo habilis', 'Human evolution', 'Paleoanthropology', 'Homo (genus)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative cranial capacity Homo erectus Homo habilis']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Homo habilis', 'Human evolution', 'Paleoanthropology', 'Homo (genus)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Anatomical differences between Homo erectus and Homo habilis']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Homo habilis', 'Human evolution', 'Paleoanthropology', 'Hominin brain evolution']\n",
            "[WARN] page for 'Hominin brain evolution' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Comparative cranial capacity Homo erectus Homo habilis']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Homo habilis', 'Human evolution', 'Paleoanthropology', 'Homo (genus)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Anatomical differences between Homo erectus and Homo habilis']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Homo habilis', 'Human evolution', 'Paleoanthropology', 'Homo (genus)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "[30] Solving: QUESTION31)During the manic phase of a bipolar disorder, ind...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Diagnostic criteria for manic episode in bipolar disorder']...\n",
            "   -> [Wiki Keywords] ['Bipolar disorder', 'Manic episode', 'DSM-5 diagnostic criteria', 'Bipolar I disorder', 'Mood disorders']\n",
            "[WARN] page for 'DSM-5 diagnostic criteria' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Diagnostic criteria for bipolar disorder manic episode DSM-5']...\n",
            "   -> [Wiki Keywords] ['Bipolar disorder', 'Manic episode', 'DSM-5 diagnostic criteria', 'Bipolar I disorder', 'Mood disorder']\n",
            "[WARN] page for 'DSM-5 diagnostic criteria' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Diagnostic criteria for manic episode in bipolar disorder']...\n",
            "   -> [Wiki Keywords] ['Bipolar disorder', 'Manic episode', 'DSM-5 diagnostic criteria', 'Bipolar I disorder', 'Mood disorder symptoms']\n",
            "[WARN] page for 'DSM-5 diagnostic criteria' does not exist\n",
            "[WARN] page for 'Mood disorder symptoms' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Diagnostic criteria for bipolar disorder manic episode DSM-5']...\n",
            "   -> [Wiki Keywords] ['Bipolar disorder', 'Manic episode', 'DSM-5 criteria', 'Bipolar I disorder', 'Mood disorder']\n",
            "[WARN] page for 'DSM-5 criteria' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Diagnostic criteria for bipolar disorder manic episode DSM-5']...\n",
            "   -> [Wiki Keywords] ['Bipolar disorder', 'Manic episode', 'DSM-5 diagnostic criteria', 'Bipolar I disorder', 'Mood disorder']\n",
            "[WARN] page for 'DSM-5 diagnostic criteria' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "[WARN] page for 'manic phase' does not exist\n",
            "[WARN] page for 'high self-esteem' does not exist\n",
            "[WARN] page for 'manic phase' does not exist\n",
            "[WARN] page for 'high self-esteem' does not exist\n",
            "[WARN] page for 'manic phase' does not exist\n",
            "[WARN] page for 'high self-esteem' does not exist\n",
            "[WARN] page for 'manic phase' does not exist\n",
            "[WARN] page for 'high self-esteem' does not exist\n",
            "[WARN] page for 'manic phase' does not exist\n",
            "[WARN] page for 'high self-esteem' does not exist\n",
            "[31] Solving: QUESTION32) This question refers to the following informatio...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Clemenceau's attribution of WWI responsibility to Germany\"]...\n",
            "   -> [Wiki Keywords] ['Georges Clemenceau', 'Grandeur and Misery of Victory', 'Deutschland über alles', 'World War I responsibility', 'German nationalism']\n",
            "[WARN] page for 'Grandeur and Misery of Victory' does not exist\n",
            "[WARN] page for 'World War I responsibility' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Clemenceau's analysis of German responsibility for World War I\"]...\n",
            "   -> [Wiki Keywords] ['Georges Clemenceau', 'Grandeur and Misery of Victory', 'Deutschland über alles', 'World War I causes', 'German nationalism']\n",
            "[WARN] page for 'Grandeur and Misery of Victory' does not exist\n",
            "[WARN] page for 'World War I causes' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Clemenceau's analysis of German responsibility in World War I\"]...\n",
            "   -> [Wiki Keywords] ['Georges Clemenceau', 'Grandeur and Misery of Victory', 'Deutschland über alles', 'World War I causes', 'German nationalism']\n",
            "[WARN] page for 'Grandeur and Misery of Victory' does not exist\n",
            "[WARN] page for 'World War I causes' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Clemenceau's analysis of German responsibility for World War I\"]...\n",
            "   -> [Wiki Keywords] ['Georges Clemenceau', 'World War I causes', 'Deutschland über alles', 'Grandeur and Misery of Victory', 'German nationalism']\n",
            "[WARN] page for 'World War I causes' does not exist\n",
            "[WARN] page for 'Grandeur and Misery of Victory' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] [\"Clemenceau's analysis of German responsibility in World War I\"]...\n",
            "   -> [Wiki Keywords] ['Georges Clemenceau', 'Grandeur and Misery of Victory', 'Deutschland über alles', 'World War I causes', 'German nationalism']\n",
            "[WARN] page for 'Grandeur and Misery of Victory' does not exist\n",
            "[WARN] page for 'World War I causes' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "[WARN] page for 'catastrophe of 1914' does not exist\n",
            "[WARN] page for 'catastrophe of 1914' does not exist\n",
            "[WARN] page for 'catastrophe of 1914' does not exist\n",
            "[WARN] page for 'catastrophe of 1914' does not exist\n",
            "[WARN] page for 'catastrophe of 1914' does not exist\n",
            "[32] Solving: QUESTION33) You receive a phone call from Hermann H., age 28...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['APA ethical guidelines for therapist-client value conflicts']...\n",
            "   -> [Wiki Keywords] ['American Psychological Association Ethics Code', 'Therapist-client value conflicts', 'Ethical referral in psychology', 'Professional boundaries in psychotherapy']\n",
            "[WARN] page for 'American Psychological Association Ethics Code' does not exist\n",
            "[WARN] page for 'Therapist-client value conflicts' does not exist\n",
            "[WARN] page for 'Ethical referral in psychology' does not exist\n",
            "[WARN] page for 'Professional boundaries in psychotherapy' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['APA ethical guidelines for therapist-client value conflicts']...\n",
            "   -> [Wiki Keywords] ['American Psychological Association Ethics Code', 'Therapist-client relationship ethics', 'Professional boundaries in psychology', 'Ethical referral in psychotherapy']\n",
            "[WARN] page for 'American Psychological Association Ethics Code' does not exist\n",
            "[WARN] page for 'Therapist-client relationship ethics' does not exist\n",
            "[WARN] page for 'Professional boundaries in psychology' does not exist\n",
            "[WARN] page for 'Ethical referral in psychotherapy' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['APA ethical guidelines for therapist-client value conflicts']...\n",
            "   -> [Wiki Keywords] ['American Psychological Association Ethics Code', 'Therapist-client value conflicts', 'Ethical referral in psychology', 'Professional boundaries in psychotherapy']\n",
            "[WARN] page for 'American Psychological Association Ethics Code' does not exist\n",
            "[WARN] page for 'Therapist-client value conflicts' does not exist\n",
            "[WARN] page for 'Ethical referral in psychology' does not exist\n",
            "[WARN] page for 'Professional boundaries in psychotherapy' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['APA ethical guidelines for therapist-client value conflicts']...\n",
            "   -> [Wiki Keywords] ['American Psychological Association Ethics Code', 'Countertransference', 'Therapist-client relationship', 'Ethical referral in psychology', 'Professional boundaries']\n",
            "[WARN] page for 'American Psychological Association Ethics Code' does not exist\n",
            "[WARN] page for 'Therapist-client relationship' does not exist\n",
            "[WARN] page for 'Ethical referral in psychology' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['APA ethical guidelines for therapist-client value conflicts']...\n",
            "   -> [Wiki Keywords] ['American Psychological Association Ethics Code', 'Countertransference', 'Therapist-client boundaries', 'Ethical referral in psychology']\n",
            "[WARN] page for 'American Psychological Association Ethics Code' does not exist\n",
            "[WARN] page for 'Therapist-client boundaries' does not exist\n",
            "[WARN] page for 'Ethical referral in psychology' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "[WARN] page for 'ethical psychologist' does not exist\n",
            "[WARN] page for 'ethical psychologist' does not exist\n",
            "[WARN] page for 'referrals' does not exist\n",
            "[WARN] page for 'ethical psychologist' does not exist\n",
            "[WARN] page for 'ethical psychologist' does not exist\n",
            "[33] Solving: QUESTION34) During the second stage of Kohlberg’s preconvent...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Kohlberg preconventional stage 2 punishment and reward orientation']...\n",
            "   -> [Wiki Keywords] ['Lawrence Kohlberg', 'Stages of moral development', 'Preconventional morality', 'Instrumental relativism orientation']\n",
            "[WARN] page for 'Stages of moral development' does not exist\n",
            "[WARN] page for 'Instrumental relativism orientation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Kohlberg preconventional stage 2 punishment and reward orientation']...\n",
            "   -> [Wiki Keywords] ['Lawrence Kohlberg', 'Moral development', 'Preconventional morality', 'Instrumental relativism', 'Punishment-obedience orientation']\n",
            "[WARN] page for 'Instrumental relativism' does not exist\n",
            "[WARN] page for 'Punishment-obedience orientation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Kohlberg preconventional stage 2 punishment and reward orientation']...\n",
            "   -> [Wiki Keywords] ['Lawrence Kohlberg', 'Moral development', 'Preconventional morality', 'Instrumental purpose orientation', 'Stages of moral development']\n",
            "[WARN] page for 'Instrumental purpose orientation' does not exist\n",
            "[WARN] page for 'Stages of moral development' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Kohlberg preconventional stage 2 punishment and reward orientation']...\n",
            "   -> [Wiki Keywords] [\"Lawrence Kohlberg's stages of moral development\", 'Preconventional morality', 'Instrumental purpose orientation', 'Moral development theory']\n",
            "[WARN] page for 'Instrumental purpose orientation' does not exist\n",
            "[WARN] page for 'Moral development theory' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Kohlberg preconventional stage 2 punishment and reward orientation']...\n",
            "   -> [Wiki Keywords] ['Lawrence Kohlberg', 'Moral development', 'Preconventional morality', 'Instrumental relativism', 'Punishment-obedience orientation']\n",
            "[WARN] page for 'Instrumental relativism' does not exist\n",
            "[WARN] page for 'Punishment-obedience orientation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "[WARN] page for 'Kohlberg’s preconventional level' does not exist\n",
            "[WARN] page for 'Kohlberg’s theory' does not exist\n",
            "[WARN] page for 'preconventional level' does not exist\n",
            "[WARN] page for 'Kohlberg’s theory' does not exist\n",
            "[WARN] page for 'preconventional level' does not exist\n",
            "[WARN] page for 'Kohlberg’s preconventional level' does not exist\n",
            "[WARN] page for 'Kohlberg’s theory' does not exist\n",
            "[WARN] page for 'preconventional level' does not exist\n",
            "[34] Solving: QUESTION35)  In satisfying Kant's Humanity formulation of th...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Kant's categorical imperative humanity formulation obligations\"]...\n",
            "   -> [Wiki Keywords] ['Categorical Imperative', 'Immanuel Kant', 'Humanity formulation', 'Kantian ethics', 'Moral philosophy']\n",
            "[Init] Building BM25 index for: philosophy...\n",
            "[Init] BM25 ready for philosophy (54977 docs)\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Kant's categorical imperative humanity formulation obligations\"]...\n",
            "   -> [Wiki Keywords] ['Categorical Imperative', 'Immanuel Kant', 'Humanity formulation', 'Kantian ethics', 'Moral philosophy']\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Kant's categorical imperative humanity formulation obligations\"]...\n",
            "   -> [Wiki Keywords] ['Categorical imperative', 'Humanity formulation', 'Immanuel Kant', 'Moral philosophy', 'Kantian ethics']\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Kant's categorical imperative humanity formulation obligations\"]...\n",
            "   -> [Wiki Keywords] ['Categorical Imperative', 'Immanuel Kant', 'Humanity formulation', 'Kantian ethics', 'Moral philosophy']\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Kant's categorical imperative humanity formulation obligations\"]...\n",
            "   -> [Wiki Keywords] ['Categorical Imperative', 'Immanuel Kant', 'Humanity formulation', 'Moral philosophy', 'Kantian ethics']\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "[WARN] page for 'Kant's categorical imperative' does not exist\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "[WARN] page for 'morally permissible ends' does not exist\n",
            "[WARN] page for 'Kant's categorical imperative' does not exist\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "[WARN] page for 'morally permissible ends' does not exist\n",
            "[WARN] page for 'Kant's categorical imperative' does not exist\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "[WARN] page for 'morally permissible ends' does not exist\n",
            "[WARN] page for 'Kant's categorical imperative' does not exist\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "[WARN] page for 'morally permissible ends' does not exist\n",
            "[WARN] page for 'Kant's categorical imperative' does not exist\n",
            "[WARN] page for 'Humanity formulation' does not exist\n",
            "[WARN] page for 'morally permissible ends' does not exist\n",
            "[35] Solving: QUESTION36) Aristotle says  that what makes things be what t...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Aristotelian essence dependence on individual existence']...\n",
            "   -> [Wiki Keywords] ['Aristotelianism', 'Hylomorphism', 'Platonic realism', 'Metaphysics (Aristotle)', 'Universal (philosophy)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Aristotelian essence dependence on individual instances']...\n",
            "   -> [Wiki Keywords] ['Aristotelianism', 'Hylomorphism', 'Platonic realism', 'Metaphysics (Aristotle)', 'Universal (philosophy)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Aristotelian essence dependence on particulars']...\n",
            "   -> [Wiki Keywords] [\"Aristotle's metaphysics\", 'Hylomorphism', 'Platonic realism', 'Universal (philosophy)', 'Essence and accident']\n",
            "[WARN] page for 'Aristotle's metaphysics' does not exist\n",
            "[WARN] page for 'Essence and accident' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Aristotelian essence dependence on particulars']...\n",
            "   -> [Wiki Keywords] ['Aristotelianism', 'Hylomorphism', 'Platonic realism', 'Metaphysics (Aristotle)', 'Theory of forms']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Aristotelian essence dependence on particulars']...\n",
            "   -> [Wiki Keywords] ['Aristotelianism', 'Hylomorphism', 'Platonic realism', 'Metaphysics (Aristotle)', 'Universal (philosophy)']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "[36] Solving: QUESTION37) The ________ School of jurisprudence believes th...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Jurisprudence schools defining law as historical social traditions']...\n",
            "   -> [Wiki Keywords] ['Historical School (law)', 'Schools of jurisprudence', 'Legal positivism', 'Customary law', 'Friedrich Karl von Savigny']\n",
            "[WARN] page for 'Historical School (law)' does not exist\n",
            "[WARN] page for 'Schools of jurisprudence' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Jurisprudence schools defining law as historical social traditions']...\n",
            "   -> [Wiki Keywords] ['Historical school of jurisprudence', 'Legal positivism', 'Sociological school of law', 'Jurisprudence schools comparison']\n",
            "[WARN] page for 'Historical school of jurisprudence' does not exist\n",
            "[WARN] page for 'Sociological school of law' does not exist\n",
            "[WARN] page for 'Jurisprudence schools comparison' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Jurisprudence schools defining law as historical social customs']...\n",
            "   -> [Wiki Keywords] ['Historical School (law)', 'Jurisprudence schools', 'Legal positivism', 'Sociological School of Law', 'Friedrich Carl von Savigny']\n",
            "[WARN] page for 'Historical School (law)' does not exist\n",
            "[WARN] page for 'Jurisprudence schools' does not exist\n",
            "[WARN] page for 'Sociological School of Law' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Jurisprudence school defining law as historical social traditions']...\n",
            "   -> [Wiki Keywords] ['Historical school of jurisprudence', 'Legal positivism', 'Sociological school of law', 'Jurisprudence schools comparison']\n",
            "[WARN] page for 'Historical school of jurisprudence' does not exist\n",
            "[WARN] page for 'Sociological school of law' does not exist\n",
            "[WARN] page for 'Jurisprudence schools comparison' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Jurisprudence schools defining law as historical social traditions']...\n",
            "   -> [Wiki Keywords] ['Historical School (law)', 'Jurisprudence schools', 'Legal positivism', 'Sociological School of Law', 'Customary law']\n",
            "[WARN] page for 'Historical School (law)' does not exist\n",
            "[WARN] page for 'Jurisprudence schools' does not exist\n",
            "[WARN] page for 'Sociological School of Law' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "[WARN] page for 'social traditions' does not exist\n",
            "[WARN] page for 'social traditions' does not exist\n",
            "[WARN] page for 'social traditions' does not exist\n",
            "[WARN] page for 'social traditions' does not exist\n",
            "[WARN] page for 'social traditions' does not exist\n",
            "[37] Solving: QUESTION38) A woman was standing in the aisle of a subway ca...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law distinctions between larceny robbery and burglary']...\n",
            "   -> [Wiki Keywords] ['Common law crimes', 'Larceny', 'Robbery', 'Burglary', 'Criminal law elements']\n",
            "[WARN] page for 'Criminal law elements' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law distinction between larceny and robbery when force is used post-taking']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Robbery (law)', 'Common law crimes', 'Criminal law elements', 'Theft act definitions']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "[WARN] page for 'Criminal law elements' does not exist\n",
            "[WARN] page for 'Theft act definitions' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law distinction between larceny and robbery']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Robbery (law)', 'Common law crimes', 'Criminal law elements', 'Theft act definitions']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "[WARN] page for 'Criminal law elements' does not exist\n",
            "[WARN] page for 'Theft act definitions' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law distinction between larceny and robbery when force is used post-taking']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Robbery (law)', 'Common law crimes', 'Criminal law elements', 'Theft act']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "[WARN] page for 'Criminal law elements' does not exist\n",
            "[WARN] page for 'Theft act' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: D | Votes: {'D': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Common law distinction between larceny and robbery with post-taking force']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Robbery (law)', 'Common law crimes', 'Criminal law elements', 'Theft act definitions']\n",
            "[WARN] page for 'Robbery (law)' does not exist\n",
            "[WARN] page for 'Criminal law elements' does not exist\n",
            "[WARN] page for 'Theft act definitions' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "[38] Solving: QUESTION39) A defendant met her friend at the electronics st...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Criminal liability for knowingly retaining stolen property after discovery']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Receiving stolen property', 'Theft', 'Criminal law', 'Possession of stolen property']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Criminal liability for unintentional possession of stolen goods']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Receiving stolen property', 'Theft (crime)', 'Criminal law', 'Mens rea']\n",
            "[WARN] page for 'Theft (crime)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Criminal liability for unintentional possession of stolen goods']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Receiving stolen property', 'Theft (crime)', 'Criminal law', 'Mens rea']\n",
            "[WARN] page for 'Theft (crime)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Criminal liability for unintentional possession of stolen goods']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Receiving stolen property', 'Theft', 'Criminal law', 'Mens rea']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Criminal liability for unintentional possession of stolen goods']...\n",
            "   -> [Wiki Keywords] ['Larceny', 'Receiving stolen property', 'Criminal law', 'Theft', 'Mens rea']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "[WARN] page for 'stolen property' does not exist\n",
            "[WARN] page for 'stolen property' does not exist\n",
            "[WARN] page for 'stolen property' does not exist\n",
            "[WARN] page for 'stolen property' does not exist\n",
            "[39] Solving: QUESTION40)____________ refers to a strategic process involv...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Strategic stakeholder engagement for sustainable customer relationships']...\n",
            "   -> [Wiki Keywords] ['Sustainable Development', 'Environmental Stewardship', 'Green Marketing', 'Eco-branding', 'Stakeholder Theory']\n",
            "[Init] Building BM25 index for: business...\n",
            "[Init] BM25 ready for business (6285 docs)\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Strategic stakeholder engagement for sustainable customer relationships']...\n",
            "   -> [Wiki Keywords] ['Sustainable Development', 'Environmental Stewardship', 'Green Marketing', 'Eco-branding', 'Stakeholder theory']\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Strategic stakeholder engagement for sustainable customer relationships']...\n",
            "   -> [Wiki Keywords] ['Environmental Stewardship', 'Sustainable Development', 'Green Marketing', 'Eco-branding', 'Stakeholder Theory']\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Strategic stakeholder engagement for sustainable customer relationships']...\n",
            "   -> [Wiki Keywords] ['Green Marketing', 'Environmental Stewardship', 'Sustainable Development', 'Eco-branding', 'Stakeholder Theory']\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Strategic stakeholder engagement for sustainable customer relationships']...\n",
            "   -> [Wiki Keywords] ['Sustainable Development', 'Environmental Stewardship', 'Green Marketing', 'Eco-branding', 'Corporate Social Responsibility']\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "[WARN] page for 'Stakeholder Assessment' does not exist\n",
            "[WARN] page for 'stakeholder assessment' does not exist\n",
            "[WARN] page for 'long-term relationships' does not exist\n",
            "[WARN] page for 'Eco-branding' does not exist\n",
            "[WARN] page for 'Stakeholder Assessment' does not exist\n",
            "[WARN] page for 'stakeholder assessment' does not exist\n",
            "[WARN] page for 'long-term relationships' does not exist\n",
            "[40] Solving: QUESTION41)This question refers to the following information...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ancient Mesopotamian and Egyptian literary themes on morality and afterlife']...\n",
            "   -> [Wiki Keywords] ['The Epic of Gilgamesh', 'The Maxims of Ptahhotep', 'Ancient Near Eastern religion', 'Afterlife in ancient Mesopotamia', 'Divine justice in ancient Egypt']\n",
            "[WARN] page for 'Afterlife in ancient Mesopotamia' does not exist\n",
            "[WARN] page for 'Divine justice in ancient Egypt' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ancient Mesopotamian and Egyptian religious texts on morality and afterlife']...\n",
            "   -> [Wiki Keywords] ['The Epic of Gilgamesh', 'Maxims of Ptahhotep', 'Ancient Near Eastern religion', 'Afterlife in ancient Mesopotamia', 'Ethical teachings in ancient Egypt']\n",
            "[WARN] page for 'Afterlife in ancient Mesopotamia' does not exist\n",
            "[WARN] page for 'Ethical teachings in ancient Egypt' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ancient Mesopotamian and Egyptian religious conceptions of the afterlife and divine justice']...\n",
            "   -> [Wiki Keywords] ['The Epic of Gilgamesh', 'Maxims of Ptahhotep', 'Ancient Near Eastern religion', 'Afterlife in ancient Mesopotamia', 'Divine justice in ancient Egypt']\n",
            "[WARN] page for 'Afterlife in ancient Mesopotamia' does not exist\n",
            "[WARN] page for 'Divine justice in ancient Egypt' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ancient Mesopotamian and Egyptian literary themes on death and morality']...\n",
            "   -> [Wiki Keywords] ['The Epic of Gilgamesh', 'Maxims of Ptahhotep', 'Ancient Near Eastern religion', 'Afterlife in ancient Mesopotamia', 'Divine justice in ancient Egypt']\n",
            "[WARN] page for 'Afterlife in ancient Mesopotamia' does not exist\n",
            "[WARN] page for 'Divine justice in ancient Egypt' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Ancient Mesopotamian and Egyptian religious conceptions of the afterlife and morality']...\n",
            "   -> [Wiki Keywords] ['The Epic of Gilgamesh', 'Maxims of Ptahhotep', 'Ancient Near Eastern religion', 'Afterlife in Mesopotamian religion', 'Divine justice in ancient Egypt']\n",
            "[WARN] page for 'Afterlife in Mesopotamian religion' does not exist\n",
            "[WARN] page for 'Divine justice in ancient Egypt' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "[WARN] page for 'divine guidance' does not exist\n",
            "[WARN] page for 'moral ordinances' does not exist\n",
            "[WARN] page for 'ancient wisdom literature' does not exist\n",
            "[WARN] page for 'ancient wisdom literature' does not exist\n",
            "[WARN] page for 'moral ordinances' does not exist\n",
            "[41] Solving: QUESTION42) Is the recognition of foreign judgments subject ...\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Private International Law', 'Monism (international relations)', 'Dualism (international law)', 'Recognition of foreign judgments', 'Vienna Convention on the Law of Treaties']\n",
            "[WARN] page for 'Monism (international relations)' does not exist\n",
            "[WARN] page for 'Dualism (international law)' does not exist\n",
            "[WARN] page for 'Recognition of foreign judgments' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Recognition of foreign judgments', 'Monism (international relations)', 'Private international law', 'Vienna Convention on the Law of Treaties', 'Doctrine of reciprocity']\n",
            "[WARN] page for 'Recognition of foreign judgments' does not exist\n",
            "[WARN] page for 'Monism (international relations)' does not exist\n",
            "[WARN] page for 'Doctrine of reciprocity' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Recognition of foreign judgments', 'Monism-dualism debate in international law', 'Treaty incorporation doctrine', 'Private international law', 'Conflict of laws']\n",
            "[WARN] page for 'Recognition of foreign judgments' does not exist\n",
            "[WARN] page for 'Monism-dualism debate in international law' does not exist\n",
            "[WARN] page for 'Treaty incorporation doctrine' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Recognition of foreign judgments', 'Monism and dualism in international law', 'Private international law', 'Treaty incorporation doctrine', 'Rule of reciprocity (law)']\n",
            "[WARN] page for 'Recognition of foreign judgments' does not exist\n",
            "[WARN] page for 'Treaty incorporation doctrine' does not exist\n",
            "[WARN] page for 'Rule of reciprocity (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: law\n",
            "   -> [Textbook Query] ['Legal principles governing recognition of foreign judgments vs treaty incorporation']...\n",
            "   -> [Wiki Keywords] ['Recognition of foreign judgments', 'Monism (international relations)', 'Dualism (international law)', 'Conflict of laws', 'Vienna Convention on the Law of Treaties']\n",
            "[WARN] page for 'Recognition of foreign judgments' does not exist\n",
            "[WARN] page for 'Monism (international relations)' does not exist\n",
            "[WARN] page for 'Dualism (international law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "[WARN] page for 'doctrine of dualism' does not exist\n",
            "[WARN] page for 'bilateral treaties' does not exist\n",
            "[WARN] page for 'doctrine of dualism' does not exist\n",
            "[WARN] page for 'bilateral treaties' does not exist\n",
            "[WARN] page for 'doctrine of dualism' does not exist\n",
            "[WARN] page for 'bilateral treaties' does not exist\n",
            "[WARN] page for 'doctrine of dualism' does not exist\n",
            "[WARN] page for 'bilateral treaties' does not exist\n",
            "[WARN] page for 'doctrine of dualism' does not exist\n",
            "[WARN] page for 'bilateral treaties' does not exist\n",
            "[42] Solving: QUESTION43) Some contemporary intelligence researchers like ...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "[WARN] page for 'Triarchic Theory of Intelligence' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "[WARN] page for 'Triarchic Theory of Intelligence' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "[WARN] page for 'Triarchic Theory of Intelligence' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "[WARN] page for 'Triarchic Theory of Intelligence' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Gardner Sternberg critique of traditional educational focus']...\n",
            "   -> [Wiki Keywords] ['Howard Gardner', 'Robert Sternberg', 'Multiple Intelligences', 'Triarchic Theory of Intelligence', 'Educational Psychology']\n",
            "[WARN] page for 'Triarchic Theory of Intelligence' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: C | Votes: {'C': 1}\n",
            "[WARN] page for 'traditional subjects' does not exist\n",
            "[WARN] page for 'traditional subjects' does not exist\n",
            "[43] Solving: QUESTION44) BobGafneyand Susan Medina invested $40,000 and $...\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership income allocation with management fee and interest on capital']...\n",
            "   -> [Wiki Keywords] ['Partnership accounting', 'Profit allocation', 'Partnership agreement terms', 'Interest on capital', 'Management fee']\n",
            "[WARN] page for 'Profit allocation' does not exist\n",
            "[WARN] page for 'Partnership agreement terms' does not exist\n",
            "[WARN] page for 'Interest on capital' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership income allocation with managerial salary and interest on capital']...\n",
            "   -> [Wiki Keywords] ['Partnership accounting', 'Income allocation methods', 'Partnership agreement terms', 'Residual profit sharing']\n",
            "[WARN] page for 'Income allocation methods' does not exist\n",
            "[WARN] page for 'Partnership agreement terms' does not exist\n",
            "[WARN] page for 'Residual profit sharing' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership income allocation with managerial salary and interest on capital']...\n",
            "   -> [Wiki Keywords] ['Partnership accounting', 'Income allocation methods', 'Partnership agreement terms', 'Residual profit sharing']\n",
            "[WARN] page for 'Income allocation methods' does not exist\n",
            "[WARN] page for 'Partnership agreement terms' does not exist\n",
            "[WARN] page for 'Residual profit sharing' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership income distribution with interest on investments and management fee']...\n",
            "   -> [Wiki Keywords] ['Partnership (accounting)', 'Profit sharing', 'Capital contribution (business)', 'Partnership agreement', 'Net income allocation']\n",
            "[WARN] page for 'Partnership (accounting)' does not exist\n",
            "[WARN] page for 'Capital contribution (business)' does not exist\n",
            "[WARN] page for 'Net income allocation' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 1}\n",
            "   -> [Analysis] Category: business\n",
            "   -> [Textbook Query] ['Partnership income distribution with interest on investments and management fee']...\n",
            "   -> [Wiki Keywords] ['Partnership (accounting)', 'Income distribution in partnerships', 'Capital contribution in business partnerships']\n",
            "[WARN] page for 'Partnership (accounting)' does not exist\n",
            "[WARN] page for 'Income distribution in partnerships' does not exist\n",
            "[WARN] page for 'Capital contribution in business partnerships' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: F | Votes: {'F': 1}\n",
            "[WARN] page for 'interest on investment' does not exist\n",
            "[WARN] page for 'interest on investment' does not exist\n",
            "[WARN] page for 'net income division' does not exist\n",
            "[WARN] page for 'interest on investment' does not exist\n",
            "[WARN] page for 'net income division' does not exist\n",
            "[WARN] page for 'partnership income' does not exist\n",
            "[WARN] page for 'interest on investment' does not exist\n",
            "[WARN] page for 'managerial compensation' does not exist\n",
            "[WARN] page for 'partnership income' does not exist\n",
            "[WARN] page for 'interest on investment' does not exist\n",
            "[WARN] page for 'managerial compensation' does not exist\n",
            "[44] Solving: QUESTION45) One objection to Singer’s theory that he conside...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections about proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', 'Famine, Affluence, and Morality', \"Singer's theory of global ethics\", 'Moral partiality', 'Acting on behalf of strangers']\n",
            "[WARN] page for 'Singer's theory of global ethics' does not exist\n",
            "[WARN] page for 'Moral partiality' does not exist\n",
            "[WARN] page for 'Acting on behalf of strangers' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections about proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', 'Famine, Affluence, and Morality', \"Singer's theory of moral obligations\", 'Ethical objections to utilitarianism', 'Moral proximity argument']\n",
            "[WARN] page for 'Singer's theory of moral obligations' does not exist\n",
            "[WARN] page for 'Ethical objections to utilitarianism' does not exist\n",
            "[WARN] page for 'Moral proximity argument' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections regarding proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', 'Famine, Affluence, and Morality', \"Singer's theory of moral obligations\", 'Ethics of proximity', 'Moral partiality']\n",
            "[WARN] page for 'Singer's theory of moral obligations' does not exist\n",
            "[WARN] page for 'Ethics of proximity' does not exist\n",
            "[WARN] page for 'Moral partiality' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections regarding proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', \"Singer's theory of altruism\", 'Famine, Affluence, and Morality', 'Ethics of proximity', 'Moral obligations to strangers']\n",
            "[WARN] page for 'Singer's theory of altruism' does not exist\n",
            "[WARN] page for 'Ethics of proximity' does not exist\n",
            "[WARN] page for 'Moral obligations to strangers' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] [\"Peter Singer's response to objections about proximity in moral obligations\"]...\n",
            "   -> [Wiki Keywords] ['Peter Singer', \"Singer's Pond\", 'Famine, Affluence, and Morality', 'Ethics of proximity', 'Moral partiality']\n",
            "[WARN] page for 'Singer's Pond' does not exist\n",
            "[WARN] page for 'Ethics of proximity' does not exist\n",
            "[WARN] page for 'Moral partiality' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: J | Votes: {'J': 1}\n",
            "[WARN] page for 'Singer’s theory' does not exist\n",
            "[WARN] page for 'stricter obligations to loved ones' does not exist\n",
            "[WARN] page for 'Singer’s theory' does not exist\n",
            "[WARN] page for 'stricter obligations' does not exist\n",
            "[WARN] page for 'Singer’s theory' does not exist\n",
            "[WARN] page for 'stricter obligations to loved ones' does not exist\n",
            "[WARN] JSON parse failed again: Extra data: line 5 column 1 (char 105)\n",
            "[WARN] page for 'Singer’s theory' does not exist\n",
            "[WARN] page for 'stricter obligations to loved ones' does not exist\n",
            "[45] Solving: QUESTION46) In 1797, John Frere made a discovery that he des...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne Palaeolithic site', 'Paleolithic archaeology', 'Stone Age tools discovery', 'Prehistoric archaeology']\n",
            "[WARN] page for 'Hoxne Palaeolithic site' does not exist\n",
            "[WARN] page for 'Stone Age tools discovery' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne flint tools', 'Paleolithic archaeology', 'Stone Age tool discovery', 'Hoxne (archaeological site)']\n",
            "[WARN] page for 'Hoxne flint tools' does not exist\n",
            "[WARN] page for 'Stone Age tool discovery' does not exist\n",
            "[WARN] page for 'Hoxne (archaeological site)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne Palaeolithic site', 'Stone Age archaeology', 'Paleoanthropology discoveries', 'Prehistoric tool classification']\n",
            "[WARN] page for 'Hoxne Palaeolithic site' does not exist\n",
            "[WARN] page for 'Stone Age archaeology' does not exist\n",
            "[WARN] page for 'Paleoanthropology discoveries' does not exist\n",
            "[WARN] page for 'Prehistoric tool classification' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne Palaeolithic site', 'Paleolithic archaeology', 'Stone Age tools discovery', 'Prehistoric archaeology history']\n",
            "[WARN] page for 'Hoxne Palaeolithic site' does not exist\n",
            "[WARN] page for 'Stone Age tools discovery' does not exist\n",
            "[WARN] page for 'Prehistoric archaeology history' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['John Frere 1797 archaeological discovery description']...\n",
            "   -> [Wiki Keywords] ['John Frere', 'Hoxne Palaeolithic site', 'Acheulean handaxe', 'Paleoanthropology history', 'Deep stratigraphy archaeology']\n",
            "[WARN] page for 'Hoxne Palaeolithic site' does not exist\n",
            "[WARN] page for 'Paleoanthropology history' does not exist\n",
            "[WARN] page for 'Deep stratigraphy archaeology' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: I | Votes: {'I': 1}\n",
            "[WARN] page for 'primitive stone tools' does not exist\n",
            "[WARN] page for 'primitive stone tools' does not exist\n",
            "[WARN] page for 'primitive stone tools' does not exist\n",
            "[WARN] page for 'primitive stone tools' does not exist\n",
            "[46] Solving: QUESTION47) Pick the correct description of the following te...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Utilitarianism definition greatest good for the greatest number']...\n",
            "   -> [Wiki Keywords] ['Utilitarianism', 'Jeremy Bentham', 'Greatest happiness principle', 'Consequentialism']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Utilitarianism definition greatest good for the greatest number']...\n",
            "   -> [Wiki Keywords] ['Utilitarianism', 'Jeremy Bentham', 'Greatest happiness principle', 'Consequentialism']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Utilitarianism definition greatest good for the greatest number']...\n",
            "   -> [Wiki Keywords] ['Utilitarianism', 'Jeremy Bentham', 'Greatest happiness principle', 'Consequentialism']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Utilitarianism core principle greatest good for the greatest number']...\n",
            "   -> [Wiki Keywords] ['Utilitarianism', 'Consequentialism', 'Jeremy Bentham', 'John Stuart Mill', 'Greatest happiness principle']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Utilitarianism definition greatest good for the greatest number']...\n",
            "   -> [Wiki Keywords] ['Utilitarianism', 'Jeremy Bentham', 'Greatest happiness principle', 'Consequentialism']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "[47] Solving: QUESTION48) Which of the following describes a key change in...\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Evolutionary changes in Homo erectus brain development']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Encephalization', 'Human evolution', 'Hominid brain evolution', 'Paleoanthropology']\n",
            "[WARN] page for 'Hominid brain evolution' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Evolutionary changes in Homo erectus brain development']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Encephalization quotient', 'Human evolution', 'Hominin brain evolution', 'Paleoanthropology']\n",
            "[WARN] page for 'Hominin brain evolution' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Evolutionary changes in Homo erectus brain development']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Encephalization quotient', 'Human evolution', 'Hominin brain evolution', 'Paleoanthropology']\n",
            "[WARN] page for 'Hominin brain evolution' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Evolutionary changes in Homo erectus brain development']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Encephalization quotient', 'Human evolution', 'Paleoanthropology', 'Brain evolution']\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "   -> [Analysis] Category: history\n",
            "   -> [Textbook Query] ['Evolutionary changes in Homo erectus brain development']...\n",
            "   -> [Wiki Keywords] ['Homo erectus', 'Encephalization quotient', 'Human evolution', 'Hominin brain evolution', 'Paleoanthropology']\n",
            "[WARN] page for 'Hominin brain evolution' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: E | Votes: {'E': 1}\n",
            "[48] Solving: QUESTION49) Delia was accepted to both Harvard University an...\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychological conflict types approach-approach definition']...\n",
            "   -> [Wiki Keywords] ['Approach-approach conflict', 'Cognitive dissonance', 'Psychological conflict types', 'Decision-making psychology']\n",
            "[WARN] page for 'Approach-approach conflict' does not exist\n",
            "[WARN] page for 'Psychological conflict types' does not exist\n",
            "[WARN] page for 'Decision-making psychology' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychological conflict types approach-approach definition']...\n",
            "   -> [Wiki Keywords] ['Approach-approach conflict', 'Cognitive dissonance', 'Psychological conflict types', 'Decision-making psychology']\n",
            "[WARN] page for 'Approach-approach conflict' does not exist\n",
            "[WARN] page for 'Psychological conflict types' does not exist\n",
            "[WARN] page for 'Decision-making psychology' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychological conflict types approach-approach definition']...\n",
            "   -> [Wiki Keywords] ['Approach-approach conflict', 'Cognitive dissonance', 'Psychological conflict types', 'Decision-making theories']\n",
            "[WARN] page for 'Approach-approach conflict' does not exist\n",
            "[WARN] page for 'Psychological conflict types' does not exist\n",
            "[WARN] page for 'Decision-making theories' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychological conflict types approach-approach definition']...\n",
            "   -> [Wiki Keywords] ['Approach-approach conflict', 'Cognitive dissonance', 'Psychological conflict types', 'Decision-making psychology']\n",
            "[WARN] page for 'Approach-approach conflict' does not exist\n",
            "[WARN] page for 'Psychological conflict types' does not exist\n",
            "[WARN] page for 'Decision-making psychology' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "   -> [Analysis] Category: psychology\n",
            "   -> [Textbook Query] ['Psychological conflict between two desirable alternatives']...\n",
            "   -> [Wiki Keywords] ['Approach-approach conflict', 'Cognitive dissonance', 'Psychological conflict theory', 'Decision-making conflicts']\n",
            "[WARN] page for 'Approach-approach conflict' does not exist\n",
            "[WARN] page for 'Psychological conflict theory' does not exist\n",
            "[WARN] page for 'Decision-making conflicts' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: G | Votes: {'G': 1}\n",
            "[WARN] page for 'approach-approach conflict' does not exist\n",
            "[WARN] page for 'decision-making conflict' does not exist\n",
            "[WARN] page for 'approach-approach conflict' does not exist\n",
            "[WARN] page for 'decision-making conflict' does not exist\n",
            "[WARN] page for 'approach-approach conflict' does not exist\n",
            "[WARN] page for 'decision-making conflict' does not exist\n",
            "[WARN] page for 'approach-approach conflict' does not exist\n",
            "[WARN] page for 'decision-making conflict' does not exist\n",
            "[WARN] page for 'approach-approach conflict' does not exist\n",
            "[WARN] page for 'decision-making conflict' does not exist\n",
            "[49] Solving: QUESTION50) Which is the least accurate description of legal...\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Core tenets of legal positivism in jurisprudence']...\n",
            "   -> [Wiki Keywords] ['Legal positivism', 'Separation Thesis', 'Jurisprudence', 'H.L.A. Hart', 'John Austin (legal philosopher)']\n",
            "[WARN] page for 'Separation Thesis' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Core tenets of legal positivism and common misconceptions']...\n",
            "   -> [Wiki Keywords] ['Legal positivism', 'H.L.A. Hart', 'Philosophy of law', 'Separation thesis', 'John Austin (legal philosopher)']\n",
            "[WARN] page for 'Separation thesis' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Core tenets of legal positivism and common misconceptions']...\n",
            "   -> [Wiki Keywords] ['Legal positivism', 'Separation thesis (law)', 'Jurisprudence', 'H.L.A. Hart', 'John Austin (legal philosopher)']\n",
            "[WARN] page for 'Separation thesis (law)' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Core tenets of legal positivism in jurisprudence']...\n",
            "   -> [Wiki Keywords] ['Legal positivism', 'Jurisprudence', 'Separation thesis', 'H.L.A. Hart', 'John Austin (legal philosopher)']\n",
            "[WARN] page for 'Separation thesis' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "   -> [Analysis] Category: philosophy\n",
            "   -> [Textbook Query] ['Core tenets of legal positivism in jurisprudence']...\n",
            "   -> [Wiki Keywords] ['Legal positivism', 'Jurisprudence', 'Separation thesis', 'H.L.A. Hart', 'John Austin (legal philosopher)']\n",
            "[WARN] page for 'Separation thesis' does not exist\n",
            "   -> [Voting] Running 1 iterations...\n",
            "   -> [Result] Winner: B | Votes: {'B': 1}\n",
            "[WARN] page for 'morality and law' does not exist\n",
            "[WARN] page for 'morality and law' does not exist\n",
            "[WARN] page for 'morality and law' does not exist\n",
            "[WARN] page for 'morality and law' does not exist\n",
            "[WARN] page for 'morality and law' does not exist\n",
            "len(df)   = 50\n",
            "len(pred_lang) = 50\n",
            "len(pred_m1)   = 50\n",
            "len(pred_m2)   = 50\n",
            "[Saved] testset_ewha_mmlu1.csv\n",
            "[Saved] testset_ewha_mmlu2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ANSWER_COL = \"answers\"\n",
        "ground_truth = df[ANSWER_COL]\n",
        "\n",
        "acc_m1 = get_accuracy(df_m1[\"rag_cot_answer\"], ground_truth)\n",
        "acc_m2 = get_accuracy(df_m2[\"rag_cot_answer\"], ground_truth)\n",
        "\n",
        "print(f\"Model 1 Accuracy: {acc_m1:.4f}\")\n",
        "print(f\"Model 2 Accuracy: {acc_m2:.4f}\")"
      ],
      "metadata": {
        "id": "uf90_SyTmM3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a272fa21-d1b2-4d09-94e8-06bf33167620"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: A, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: B, answer: (D)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (D)\n",
            "----------\n",
            "generated answer: D, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: B, answer: (I)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: I, answer: (I)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: J, answer: (J)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: B, answer: (D)\n",
            "----------\n",
            "generated answer: B, answer: (G)\n",
            "----------\n",
            "generated answer: I, answer: (I)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: E, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: F, answer: (F)\n",
            "----------\n",
            "generated answer: J, answer: (J)\n",
            "----------\n",
            "generated answer: I, answer: (I)\n",
            "----------\n",
            "generated answer: G, answer: (G)\n",
            "----------\n",
            "generated answer: E, answer: (H)\n",
            "----------\n",
            "generated answer: G, answer: (G)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: A, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: B, answer: (D)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (D)\n",
            "----------\n",
            "generated answer: D, answer: (B)\n",
            "----------\n",
            "generated answer: D, answer: (D)\n",
            "----------\n",
            "generated answer: A, answer: (A)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: I, answer: (I)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: I, answer: (I)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "----------\n",
            "generated answer: J, answer: (J)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: J, answer: (D)\n",
            "----------\n",
            "generated answer: G, answer: (G)\n",
            "----------\n",
            "generated answer: B, answer: (I)\n",
            "----------\n",
            "generated answer: E, answer: (E)\n",
            "----------\n",
            "generated answer: E, answer: (D)\n",
            "----------\n",
            "generated answer: C, answer: (C)\n",
            "----------\n",
            "generated answer: F, answer: (F)\n",
            "----------\n",
            "generated answer: E, answer: (J)\n",
            "----------\n",
            "generated answer: I, answer: (I)\n",
            "----------\n",
            "generated answer: G, answer: (G)\n",
            "----------\n",
            "generated answer: E, answer: (H)\n",
            "----------\n",
            "generated answer: G, answer: (G)\n",
            "----------\n",
            "generated answer: B, answer: (B)\n",
            "Model 1 Accuracy: 82.0000\n",
            "Model 2 Accuracy: 82.0000\n"
          ]
        }
      ]
    }
  ]
}